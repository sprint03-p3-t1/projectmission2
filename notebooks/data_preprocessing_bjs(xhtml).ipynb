{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29eb6415-939a-4600-805d-17ab586855e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "제 안 요 청 서\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<표>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2024년 04월\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<표>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<표>\n",
      "\n",
      "\n",
      "\n",
      "<표>\n",
      "\n",
      "□ 사 업 명 : 통합 정보시스템 구축 사전 컨설팅\n",
      "□ 사업기간 : 계약체결일로부터 ~ 2024년 11월 29일\n",
      "□ 사업예산 : 50,000,000(금 오천만원/VAT포함)\n",
      "□ 사업추진방식 : 제한경쟁입찰(협상에 의한 계약)\n",
      "\n",
      "\n",
      "<표>\n",
      "\n",
      " ㅇ 미술진흥법 제23조에 의거 통합미술정보시스템 구축‧운영\n",
      " ㅇ 통합미술정보시스템으로의 시스템 개편 및 고도화 전략 수립을 위한 기반 마련 필요성 대두 \n",
      " ㅇ 이용자 기반의 통합미술정보시스템 구축 방향 수립을 위한 사전 분석\n",
      "\n",
      "<표>\n",
      "\n",
      " ㅇ 환경 및 현황분석\n",
      " ㅇ 통합미술정보시스템 구축 데이터 분석 및 설계\n",
      " ㅇ 통합정보시스템 벤치마킹 사례 조사\n",
      " ㅇ 비전 및 전략 수립 \n",
      " ㅇ 통합미술정보시스템 서비스 개발\n",
      "\n",
      "<표>\n",
      "\n",
      "\n",
      "\n",
      "<표>\n",
      "\n",
      "□ 현재 시각예술정보시스템 한국미술시장정보시스템을 운영하고 있음\n",
      "\n",
      "<표>\n",
      "\n",
      "□ 한국 미술시장 정보 시스템\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', '../data/raw/files/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅.hwp'], capture_output=True, text=True)\n",
    "text = result.stdout\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5a1d66-80c6-4caa-a833-68925facacad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 기본 hwp5txt ===\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "제 안 요 청 서\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<표>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2024년 04월\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<표>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<표>\n",
      "\n",
      "\n",
      "\n",
      "<표>\n",
      "\n",
      "□ 사 업 명 : 통합 정보시스템 구축 사전 컨설팅\n",
      "□ 사업기간 : 계약체결일로부터 ~ 2024년 11월 29일\n",
      "□ 사업예산 : 50,000,000(금 오천만원/VAT포함)\n",
      "□ 사업추진방식 : 제한경쟁입찰(협상에 의한 계약)\n",
      "\n",
      "\n",
      "<표>\n",
      "\n",
      " ㅇ 미술진흥법 제23조에 의거 통합미술정보시스템 구축‧운영\n",
      " ㅇ 통합미술정보시스템으로의 시스템 개편 및 고도화 전략 수립을 위한 기반 마련 필요성 대두 \n",
      " ㅇ 이용자 기반의 통합미술정보시스템 구축 방향 수립을 위한 사전 분석\n",
      "\n",
      "<표>\n",
      "\n",
      " ㅇ 환경 및 현황분석\n",
      " ㅇ 통합미술정보시스템 구축 데이터 분석 및 설계\n",
      " ㅇ 통합정보시스템 벤치마킹 사례 조사\n",
      " ㅇ 비전 및 전략 수립 \n",
      " ㅇ 통합미술정보시스템 서비스 개발\n",
      "\n",
      "<표>\n",
      "\n",
      "\n",
      "\n",
      "<표>\n",
      "\n",
      "□ 현재 시각예술정보시스템 한국미술시장정보시스템을 운영하고 있음\n",
      "\n",
      "<표>\n",
      "\n",
      "□ 한국 미술시장 정보 시스템\n",
      "...\n",
      "\n",
      "=== hwp5txt with format ===\n",
      "\n",
      "\n",
      "\n",
      "=== hwp5proc xml ===\n",
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<HwpDoc version=\"5.1.1.0\"><HwpSummaryInfo><PropertySetStream byte-order=\"fffe\" version=\"0\" system-identifier=\"0000000d\" clsid=\"9fa2b660-1061-11d4-b4c6-006097c09d8c\"><PropertySet fmtid=\"9fa2b660-1061-11d4-b4c6-006097c09d8c\" offset=\"48\"><Property id=\"2\" offset=\"120\" id-label=\"PIDSI_TITLE\" type=\"VT_LPWSTR\" type-code=\"0x001f\" value=\"별지 제5호 서식\"></Property><Property id=\"3\" offset=\"148\" id-label=\"PIDSI_SUBJECT\" type=\"VT_LPWSTR\" type-code=\"0x001f\" value=\"\"></Proper\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# import subprocess\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# def extract_hwp_with_tables(file_path, output_path=None):\n",
    "#     \"\"\"\n",
    "#     HWP 파일에서 표를 포함한 텍스트를 추출하는 함수\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # 방법 1: hwp5txt의 다양한 옵션 시도\n",
    "#     methods = []\n",
    "    \n",
    "#     # 1-1. 기본 hwp5txt\n",
    "#     try:\n",
    "#         result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', file_path], \n",
    "#                               capture_output=True, text=True)\n",
    "#         methods.append((\"기본 hwp5txt\", result.stdout))\n",
    "#     except Exception as e:\n",
    "#         methods.append((\"기본 hwp5txt\", f\"오류: {e}\"))\n",
    "    \n",
    "#     # 1-2. hwp5txt with --formats 옵션 (가능한 경우)\n",
    "#     try:\n",
    "#         result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', '--help'], \n",
    "#                               capture_output=True, text=True)\n",
    "#         if '--format' in result.stdout or '--output' in result.stdout:\n",
    "#             result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', \n",
    "#                                    '--format', 'text', file_path], \n",
    "#                                   capture_output=True, text=True)\n",
    "#             methods.append((\"hwp5txt with format\", result.stdout))\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "#     # 1-3. hwp5html로 HTML 변환 후 텍스트 추출 시도\n",
    "#     try:\n",
    "#         result = subprocess.run(['/home/spai0323/myenv/bin/hwp5html', file_path], \n",
    "#                               capture_output=True, text=True)\n",
    "#         if result.stdout:\n",
    "#             # HTML에서 표 정보를 더 잘 추출할 수 있음\n",
    "#             methods.append((\"hwp5html\", result.stdout))\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "#     # 1-4. hwp5proc 시도 (구조화된 정보 추출)\n",
    "#     try:\n",
    "#         result = subprocess.run(['/home/spai0323/myenv/bin/hwp5proc', 'xml', file_path], \n",
    "#                               capture_output=True, text=True)\n",
    "#         methods.append((\"hwp5proc xml\", result.stdout))\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "#     # 결과 저장\n",
    "#     if output_path:\n",
    "#         with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#             f.write(\"=== HWP 파일 추출 결과 ===\\n\\n\")\n",
    "#             for method_name, content in methods:\n",
    "#                 f.write(f\"=== {method_name} ===\\n\")\n",
    "#                 f.write(content)\n",
    "#                 f.write(\"\\n\" + \"=\"*50 + \"\\n\\n\")\n",
    "    \n",
    "#     return methods\n",
    "\n",
    "# # 사용 예시\n",
    "# file_path = '../data/raw/files/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅.hwp'\n",
    "# output_path = 'hwp_extracted_text.txt'\n",
    "\n",
    "# # 추출 실행\n",
    "# results = extract_hwp_with_tables(file_path, output_path)\n",
    "\n",
    "# # 결과 확인\n",
    "# for method_name, content in results:\n",
    "#     print(f\"\\n=== {method_name} ===\")\n",
    "#     print(content[:500])\n",
    "#     print(\"...\" if len(content) > 500 else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59184ead-bc55-4328-b5cd-278042173522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 내용 저장됨: ../data/processed/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅_full_text.txt\n",
      "\n",
      "가장 많은 내용이 추출된 방법: hwp5proc xml\n",
      "추출된 텍스트 길이: 3926663 문자\n"
     ]
    }
   ],
   "source": [
    "# import subprocess\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# def extract_hwp_with_tables(file_path, output_path=None):\n",
    "#     \"\"\"\n",
    "#     HWP 파일에서 표를 포함한 텍스트를 추출하는 함수\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # 방법 1: hwp5txt의 다양한 옵션 시도\n",
    "#     methods = []\n",
    "    \n",
    "#     # 1-1. 기본 hwp5txt\n",
    "#     try:\n",
    "#         result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', file_path], \n",
    "#                               capture_output=True, text=True)\n",
    "#         methods.append((\"기본 hwp5txt\", result.stdout))\n",
    "#     except Exception as e:\n",
    "#         methods.append((\"기본 hwp5txt\", f\"오류: {e}\"))\n",
    "    \n",
    "#     # 1-2. hwp5txt with --formats 옵션 (가능한 경우)\n",
    "#     try:\n",
    "#         result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', '--help'], \n",
    "#                               capture_output=True, text=True)\n",
    "#         if '--format' in result.stdout or '--output' in result.stdout:\n",
    "#             result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', \n",
    "#                                    '--format', 'text', file_path], \n",
    "#                                   capture_output=True, text=True)\n",
    "#             methods.append((\"hwp5txt with format\", result.stdout))\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "#     # 1-3. hwp5html로 HTML 변환 후 텍스트 추출 시도\n",
    "#     try:\n",
    "#         result = subprocess.run(['/home/spai0323/myenv/bin/hwp5html', file_path], \n",
    "#                               capture_output=True, text=True)\n",
    "#         if result.stdout:\n",
    "#             # HTML에서 표 정보를 더 잘 추출할 수 있음\n",
    "#             methods.append((\"hwp5html\", result.stdout))\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "#     # 1-4. hwp5proc 시도 (구조화된 정보 추출)\n",
    "#     try:\n",
    "#         result = subprocess.run(['/home/spai0323/myenv/bin/hwp5proc', 'xml', file_path], \n",
    "#                               capture_output=True, text=True)\n",
    "#         methods.append((\"hwp5proc xml\", result.stdout))\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "#     # 결과 저장\n",
    "#     if output_path:\n",
    "#         with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#             f.write(\"=== HWP 파일 추출 결과 ===\\n\\n\")\n",
    "#             for method_name, content in methods:\n",
    "#                 f.write(f\"=== {method_name} ===\\n\")\n",
    "#                 f.write(content)\n",
    "#                 f.write(\"\\n\" + \"=\"*50 + \"\\n\\n\")\n",
    "    \n",
    "#     return methods\n",
    "\n",
    "# def parse_html_tables(html_content):\n",
    "#     \"\"\"\n",
    "#     HTML에서 표를 파싱하여 구조화된 데이터로 변환\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         from bs4 import BeautifulSoup\n",
    "#         import pandas as pd\n",
    "        \n",
    "#         soup = BeautifulSoup(html_content, 'html.parser')\n",
    "#         tables = soup.find_all('table')\n",
    "        \n",
    "#         parsed_tables = []\n",
    "#         for i, table in enumerate(tables):\n",
    "#             rows = []\n",
    "#             for tr in table.find_all('tr'):\n",
    "#                 cells = [td.get_text(strip=True) for td in tr.find_all(['td', 'th'])]\n",
    "#                 if cells:  # 빈 행 제외\n",
    "#                     rows.append(cells)\n",
    "            \n",
    "#             if rows:\n",
    "#                 parsed_tables.append({\n",
    "#                     'table_index': i,\n",
    "#                     'data': rows,\n",
    "#                     'df': pd.DataFrame(rows[1:], columns=rows[0]) if len(rows) > 1 else pd.DataFrame(rows)\n",
    "#                 })\n",
    "        \n",
    "#         return parsed_tables\n",
    "#     except ImportError:\n",
    "#         print(\"BeautifulSoup4와 pandas가 필요합니다: pip install beautifulsoup4 pandas\")\n",
    "#         return []\n",
    "#     except Exception as e:\n",
    "#         print(f\"HTML 파싱 오류: {e}\")\n",
    "#         return []\n",
    "\n",
    "# def save_structured_content(file_path, output_dir='../data/processed'):\n",
    "#     \"\"\"\n",
    "#     HWP에서 추출한 내용을 구조화하여 저장\n",
    "#     \"\"\"\n",
    "#     import os\n",
    "    \n",
    "#     # 출력 디렉토리 생성\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "#     base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "#     # 1. 텍스트 추출\n",
    "#     text_result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', file_path], \n",
    "#                                 capture_output=True, text=True)\n",
    "    \n",
    "#     # 2. HTML 추출 시도\n",
    "#     try:\n",
    "#         html_result = subprocess.run(['/home/spai0323/myenv/bin/hwp5html', file_path], \n",
    "#                                    capture_output=True, text=True)\n",
    "#         html_content = html_result.stdout\n",
    "        \n",
    "#         # HTML에서 표 파싱\n",
    "#         tables = parse_html_tables(html_content)\n",
    "        \n",
    "#         # 결과 저장\n",
    "#         with open(f'{output_dir}/{base_name}_full_text.txt', 'w', encoding='utf-8') as f:\n",
    "#             f.write(\"=== 텍스트 내용 ===\\n\")\n",
    "#             f.write(text_result.stdout)\n",
    "#             f.write(\"\\n\\n=== HTML 내용 ===\\n\")\n",
    "#             f.write(html_content)\n",
    "        \n",
    "#         # 표별로 저장\n",
    "#         for table in tables:\n",
    "#             table_file = f'{output_dir}/{base_name}_table_{table[\"table_index\"]}.csv'\n",
    "#             table['df'].to_csv(table_file, index=False, encoding='utf-8-sig')\n",
    "#             print(f\"표 {table['table_index']} 저장됨: {table_file}\")\n",
    "        \n",
    "#         print(f\"전체 내용 저장됨: {output_dir}/{base_name}_full_text.txt\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"HTML 변환 실패: {e}\")\n",
    "#         # 텍스트만 저장\n",
    "#         with open(f'{output_dir}/{base_name}_text_only.txt', 'w', encoding='utf-8') as f:\n",
    "#             f.write(text_result.stdout)\n",
    "#         print(f\"텍스트만 저장됨: {output_dir}/{base_name}_text_only.txt\")\n",
    "\n",
    "# # 사용 예시\n",
    "# file_path = '../data/raw/files/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅.hwp'\n",
    "\n",
    "# # 구조화된 추출 실행\n",
    "# save_structured_content(file_path)\n",
    "\n",
    "# # 또는 기본 추출\n",
    "# results = extract_hwp_with_tables(file_path, 'hwp_all_methods.txt')\n",
    "\n",
    "# # 가장 좋은 결과 찾기\n",
    "# best_result = max(results, key=lambda x: len(x[1]))\n",
    "# print(f\"\\n가장 많은 내용이 추출된 방법: {best_result[0]}\")\n",
    "# print(f\"추출된 텍스트 길이: {len(best_result[1])} 문자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae36d17a-3c5e-424e-aa1a-79d0c5b13a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트 저장됨: ../data/processed/datapreprocessinbjs(xhtml)/extracted_text/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅_hwp_extracted_text.txt\n",
      "HTML 및 관련 리소스 저장됨: ../data/processed/datapreprocessinbjs(xhtml)/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅\n",
      "텍스트 저장됨: ../data/processed/datapreprocessinbjs(xhtml)/extracted_text/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅_hwp_extracted_text.txt\n",
      "\n",
      "가장 많은 내용이 추출된 방법: hwp5proc xml\n",
      "추출된 텍스트 길이: 3926663 문자\n"
     ]
    }
   ],
   "source": [
    "# 경로 수정 버전\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def extract_hwp_with_tables(file_path):\n",
    "    \"\"\"\n",
    "    HWP 파일에서 표를 포함한 텍스트를 추출하고\n",
    "    processed 폴더 안으로 정리\n",
    "    \"\"\"\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    # --- 1. 텍스트 추출: processed/extracted_text ---\n",
    "    extracted_text_dir = os.path.join('../data/processed/datapreprocessinbjs(xhtml)/extracted_text')\n",
    "    os.makedirs(extracted_text_dir, exist_ok=True)\n",
    "    text_file_path = os.path.join(extracted_text_dir, f\"{base_name}_hwp_extracted_text.txt\")\n",
    "\n",
    "    methods = []\n",
    "\n",
    "    # 1-1. 기본 hwp5txt\n",
    "    try:\n",
    "        result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', file_path], \n",
    "                                capture_output=True, text=True)\n",
    "        methods.append((\"기본 hwp5txt\", result.stdout))\n",
    "        with open(text_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(result.stdout)\n",
    "        print(f\"텍스트 저장됨: {text_file_path}\")\n",
    "    except Exception as e:\n",
    "        methods.append((\"기본 hwp5txt\", f\"오류: {e}\"))\n",
    "\n",
    "    # 1-2. hwp5txt with format 옵션\n",
    "    try:\n",
    "        help_result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', '--help'], \n",
    "                                     capture_output=True, text=True)\n",
    "        if '--format' in help_result.stdout or '--output' in help_result.stdout:\n",
    "            result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', '--format', 'text', file_path],\n",
    "                                    capture_output=True, text=True)\n",
    "            methods.append((\"hwp5txt with format\", result.stdout))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 1-3. hwp5html\n",
    "    html_output_dir = os.path.join('../data/processed/datapreprocessinbjs(xhtml)', base_name)\n",
    "    os.makedirs(html_output_dir, exist_ok=True)\n",
    "    try:\n",
    "        html_result = subprocess.run(['/home/spai0323/myenv/bin/hwp5html', file_path], \n",
    "                                     capture_output=True, text=True)\n",
    "        if html_result.stdout:\n",
    "            index_path = os.path.join(html_output_dir, 'index.xhtml')\n",
    "            with open(index_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(html_result.stdout)\n",
    "            print(f\"HTML 저장됨: {index_path}\")\n",
    "            methods.append((\"hwp5html\", html_result.stdout))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 1-4. hwp5proc xml\n",
    "    try:\n",
    "        result = subprocess.run(['/home/spai0323/myenv/bin/hwp5proc', 'xml', file_path],\n",
    "                                capture_output=True, text=True)\n",
    "        methods.append((\"hwp5proc xml\", result.stdout))\n",
    "        \n",
    "        # hwp5proc xml 자체가 bindata, style.css, index.xhtml 생성\n",
    "        # 현재 작업폴더 대신 html_output_dir로 이동\n",
    "        generated_folder = os.path.join(os.getcwd(), base_name)\n",
    "        if os.path.exists(generated_folder):\n",
    "            target_folder = html_output_dir\n",
    "            # 이동\n",
    "            import shutil\n",
    "            for item in os.listdir(generated_folder):\n",
    "                s = os.path.join(generated_folder, item)\n",
    "                d = os.path.join(target_folder, item)\n",
    "                if os.path.isdir(s):\n",
    "                    shutil.move(s, d)\n",
    "                else:\n",
    "                    shutil.move(s, d)\n",
    "            os.rmdir(generated_folder)\n",
    "            print(f\"hwp5proc xml 결과 폴더 이동됨: {html_output_dir}\")\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # --- 2. 가장 많은 내용 찾기 ---\n",
    "    best_result = max(methods, key=lambda x: len(x[1]) if x[1] else 0)\n",
    "    print(f\"\\n가장 많은 내용이 추출된 방법: {best_result[0]}\")\n",
    "    print(f\"추출된 텍스트 길이: {len(best_result[1]) if best_result[1] else 0} 문자\")\n",
    "\n",
    "    return methods\n",
    "\n",
    "def parse_html_tables(html_content):\n",
    "    \"\"\"\n",
    "    HTML에서 표를 파싱하여 구조화된 데이터로 변환\n",
    "    \"\"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        tables = soup.find_all('table')\n",
    "        parsed_tables = []\n",
    "        for i, table in enumerate(tables):\n",
    "            rows = []\n",
    "            for tr in table.find_all('tr'):\n",
    "                cells = [td.get_text(strip=True) for td in tr.find_all(['td', 'th'])]\n",
    "                if cells:\n",
    "                    rows.append(cells)\n",
    "            if rows:\n",
    "                parsed_tables.append({\n",
    "                    'table_index': i,\n",
    "                    'data': rows,\n",
    "                    'df': pd.DataFrame(rows[1:], columns=rows[0]) if len(rows) > 1 else pd.DataFrame(rows)\n",
    "                })\n",
    "        return parsed_tables\n",
    "    except Exception as e:\n",
    "        print(f\"HTML 파싱 오류: {e}\")\n",
    "        return []\n",
    "\n",
    "def save_structured_content(file_path):\n",
    "    \"\"\"\n",
    "    HWP에서 추출한 내용을 구조화하여 저장\n",
    "    \"\"\"\n",
    "    # 파일 이름만 추출\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    # 1. 텍스트 추출 \n",
    "    extracted_text_dir = os.path.join('../data/processed/datapreprocessinbjs(xhtml)/extracted_text')\n",
    "    os.makedirs(extracted_text_dir, exist_ok=True)\n",
    "    text_file_path = os.path.join(extracted_text_dir, f\"{base_name}_hwp_extracted_text.txt\")\n",
    "\n",
    "    try:\n",
    "        text_result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', file_path], \n",
    "                                     capture_output=True, text=True)\n",
    "        with open(text_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(text_result.stdout)\n",
    "        print(f\"텍스트 저장됨: {text_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"HWP 텍스트 추출 실패: {e}\")\n",
    "    \n",
    "    # 2. HTML 변환 -> processed/<이름>/ 폴더\n",
    "    html_output_dir = os.path.join('../data/processed/datapreprocessinbjs(xhtml)', base_name)\n",
    "    os.makedirs(html_output_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        html_result = subprocess.run(['/home/spai0323/myenv/bin/hwp5html', file_path], \n",
    "                                     capture_output=True, text=True)\n",
    "        html_content = html_result.stdout\n",
    "\n",
    "        # HTML 저장\n",
    "        index_path = os.path.join(html_output_dir, 'index.xhtml')\n",
    "        with open(index_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "\n",
    "        # bindata, style.css도 같은 폴더에 생성 (hwp5html 자체가 처리)\n",
    "        print(f\"HTML 및 관련 리소스 저장됨: {html_output_dir}\")\n",
    "\n",
    "        # HTML에서 표 파싱 후 CSV로 저장\n",
    "        tables = parse_html_tables(html_content)\n",
    "        for table in tables:\n",
    "            table_file = os.path.join(html_output_dir, f\"{base_name}_table_{table['table_index']}.csv\")\n",
    "            table['df'].to_csv(table_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"표 {table['table_index']} 저장됨: {table_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"HTML 변환 실패: {e}\")\n",
    "\n",
    "# 사용 예시\n",
    "file_path = '../data/raw/files/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅.hwp'\n",
    "\n",
    "# 구조화된 추출 실행\n",
    "save_structured_content(file_path)\n",
    "\n",
    "# 또는 기본 추출\n",
    "results = extract_hwp_with_tables(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "354e13a0-29bb-4f8e-87d2-215dcbb16e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ hwp5txt 텍스트 저장됨: ../data/processed/datapreprocessinbjs(xhtml)/hwp5txt/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅_hwp_extracted_text.txt\n",
      "\n",
      "==================================================\n",
      "\n",
      "✅ hwp5html 결과 저장됨: ../data/processed/datapreprocessinbjs(xhtml)/hwp5html/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅\n",
      "\n",
      "==================================================\n",
      "\n",
      "❌ hwp5proc 변환 실패: Traceback (most recent call last):\n",
      "  File \"/home/spai0323/myenv/bin/hwp5proc\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('pyhwp==0.1b15', 'console_scripts', 'hwp5proc')())\n",
      "  File \"/home/spai0323/myenv/lib/python3.10/site-packages/hwp5/hwp5proc.py\", line 82, in main\n",
      "    return subcommand_fn(args)\n",
      "  File \"/home/spai0323/myenv/lib/python3.10/site-packages/hwp5/proc/xml.py\", line 73, in main\n",
      "    hwp5file = Hwp5File(args.hwp5file)\n",
      "  File \"/home/spai0323/myenv/lib/python3.10/site-packages/hwp5/filestructure.py\", line 537, in __init__\n",
      "    stg = Hwp5FileBase(stg)\n",
      "  File \"/home/spai0323/myenv/lib/python3.10/site-packages/hwp5/filestructure.py\", line 188, in __init__\n",
      "    stg = OleStorage(stg)\n",
      "  File \"/home/spai0323/myenv/lib/python3.10/site-packages/hwp5/storage/ole.py\", line 35, in __init__\n",
      "    self.impl = impl_class(*args, **kwargs)\n",
      "  File \"/home/spai0323/myenv/lib/python3.10/site-packages/hwp5/plat/olefileio.py\", line 112, in __init__\n",
      "    if not isOleFile(olefile):\n",
      "  File \"/opt/jhub-venv/lib/python3.10/site-packages/olefile/olefile.py\", line 325, in isOleFile\n",
      "    with open(filename, 'rb') as fp:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../data/raw/files/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅.hwp'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def process_hwp_with_hwp5txt(file_path, output_base_dir):\n",
    "    \"\"\"\n",
    "    hwp5txt를 사용하여 HWP 파일을 텍스트로 변환하고, \n",
    "    'hwp5txt' 폴더에 저장합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_dir = os.path.join(output_base_dir, 'hwp5txt')\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        text_file_path = os.path.join(output_dir, f\"{base_name}_hwp_extracted_text.txt\")\n",
    "        \n",
    "        result = subprocess.run(['/home/spai0323/myenv/bin/hwp5txt', file_path],\n",
    "                                capture_output=True, text=True, check=True)\n",
    "        \n",
    "        with open(text_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(result.stdout)\n",
    "        \n",
    "        print(f\"✅ hwp5txt 텍스트 저장됨: {text_file_path}\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ hwp5txt 변환 실패: {e.stderr}\")\n",
    "        return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ hwp5txt 명령어를 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "        return False\n",
    "\n",
    "def process_hwp_with_hwp5html(file_path, output_base_dir):\n",
    "    \"\"\"\n",
    "    hwp5html을 사용하여 HWP 파일을 HTML로 변환하고, \n",
    "    'hwp5html' 폴더에 저장합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_dir = os.path.join(output_base_dir, 'hwp5html', base_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        index_path = os.path.join(output_dir, 'index.xhtml')\n",
    "\n",
    "        result = subprocess.run(['/home/spai0323/myenv/bin/hwp5html', file_path],\n",
    "                                capture_output=True, text=True, check=True)\n",
    "        \n",
    "        html_content = result.stdout\n",
    "        \n",
    "        with open(index_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "        \n",
    "        print(f\"✅ hwp5html 결과 저장됨: {output_dir}\")\n",
    "        return html_content\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ hwp5html 변환 실패: {e.stderr}\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ hwp5html 명령어를 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "        return None\n",
    "\n",
    "def process_hwp_with_hwp5proc(file_path, output_base_dir):\n",
    "    \"\"\"\n",
    "    hwp5proc xml을 사용하여 HWP 파일을 HTML로 변환하고,\n",
    "    'hwp5proc' 폴더에 저장합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_dir = os.path.join(output_base_dir, 'hwp5proc', base_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        subprocess.run(['/home/spai0323/myenv/bin/hwp5proc', 'xml', file_path],\n",
    "                       cwd=output_dir, capture_output=True, text=True, check=True)\n",
    "        \n",
    "        print(f\"✅ hwp5proc 결과 저장됨: {output_dir}\")\n",
    "        # hwp5proc는 폴더를 직접 생성하므로, index.xhtml을 읽어서 반환\n",
    "        index_path = os.path.join(output_dir, 'index.xhtml')\n",
    "        with open(index_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ hwp5proc 변환 실패: {e.stderr}\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ hwp5proc 명령어를 찾을 수 없습니다. 경로를 확인하세요.\")\n",
    "        return None\n",
    "\n",
    "def parse_and_save_tables(html_content, output_dir):\n",
    "    \"\"\"\n",
    "    HTML 내용에서 표를 파싱하여 CSV로 저장합니다.\n",
    "    \"\"\"\n",
    "    if not html_content:\n",
    "        print(\"❗경고: HTML 내용이 없어 테이블을 파싱할 수 없습니다.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        tables = soup.find_all('table')\n",
    "        \n",
    "        if not tables:\n",
    "            print(\"❗경고: HTML에서 테이블을 찾을 수 없습니다.\")\n",
    "            return\n",
    "\n",
    "        for i, table in enumerate(tables):\n",
    "            rows = []\n",
    "            for tr in table.find_all('tr'):\n",
    "                cells = [td.get_text(strip=True) for td in tr.find_all(['td', 'th'])]\n",
    "                if cells:\n",
    "                    rows.append(cells)\n",
    "            \n",
    "            if rows:\n",
    "                df = pd.DataFrame(rows[1:], columns=rows[0]) if len(rows) > 1 else pd.DataFrame(rows)\n",
    "                table_file = os.path.join(output_dir, f\"table_{i}.csv\")\n",
    "                df.to_csv(table_file, index=False, encoding='utf-8-sig')\n",
    "                print(f\"✅ 표 {i} 저장됨: {table_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 테이블 파싱 및 저장 오류: {e}\")\n",
    "\n",
    "# 실행 경로 설정\n",
    "file_path = '../data/raw/files/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅.hwp'\n",
    "output_base_dir = '../data/processed/datapreprocessinbjs(xhtml)'\n",
    "\n",
    "# hwp5txt 실행 및 저장\n",
    "process_hwp_with_hwp5txt(file_path, output_base_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# hwp5html 실행 및 저장\n",
    "html_content_hwp5html = process_hwp_with_hwp5html(file_path, output_base_dir)\n",
    "if html_content_hwp5html:\n",
    "    parse_and_save_tables(html_content_hwp5html, os.path.join(output_base_dir, 'hwp5html', os.path.splitext(os.path.basename(file_path))[0]))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# hwp5proc 실행 및 저장\n",
    "html_content_hwp5proc = process_hwp_with_hwp5proc(file_path, output_base_dir)\n",
    "if html_content_hwp5proc:\n",
    "    parse_and_save_tables(html_content_hwp5proc, os.path.join(output_base_dir, 'hwp5proc', os.path.splitext(os.path.basename(file_path))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467593c0-eebf-473a-ac7b-359a4f051e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "최종 사용된 방법: hwp5proc xml\n",
      "추출된 텍스트 길이: 3926663 문자\n"
     ]
    }
   ],
   "source": [
    "# 경로 수정 및 통합버전\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "def parse_html_tables(html_content):\n",
    "    \"\"\"HTML에서 표를 파싱하여 구조화된 데이터로 변환\"\"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        tables = soup.find_all('table')\n",
    "        parsed_tables = []\n",
    "        for i, table in enumerate(tables):\n",
    "            rows = []\n",
    "            for tr in table.find_all('tr'):\n",
    "                cells = [td.get_text(strip=True) for td in tr.find_all(['td','th'])]\n",
    "                if cells:\n",
    "                    rows.append(cells)\n",
    "            if rows:\n",
    "                parsed_tables.append({\n",
    "                    'table_index': i,\n",
    "                    'data': rows,\n",
    "                    'df': pd.DataFrame(rows[1:], columns=rows[0]) if len(rows)>1 else pd.DataFrame(rows)\n",
    "                })\n",
    "        return parsed_tables\n",
    "    except Exception as e:\n",
    "        print(f\"HTML 파싱 오류: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_hwp(file_path):\n",
    "    \"\"\"\n",
    "    HWP 파일 처리 (우선순위 기반):\n",
    "    1. hwp5proc xml\n",
    "    2. hwp5html\n",
    "    3. hwp5txt\n",
    "    \"\"\"\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    # --- 출력 경로 설정 ---\n",
    "    extracted_text_dir = os.path.join('../data/processed/datapreprocessinbjs(xhtml)/extracted_text')\n",
    "    os.makedirs(extracted_text_dir, exist_ok=True)\n",
    "    text_file_path = os.path.join(extracted_text_dir, f\"{base_name}_hwp_extracted_text.txt\")\n",
    "\n",
    "    html_output_dir = os.path.join('../data/processed/datapreprocessinbjs(xhtml)/xhtml', base_name)\n",
    "    os.makedirs(html_output_dir, exist_ok=True)\n",
    "\n",
    "    result_data = None\n",
    "    method_used = None\n",
    "\n",
    "    # --- 1. hwp5proc xml ---\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['/home/spai0323/myenv/bin/hwp5proc', 'xml', file_path],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        method_used = \"hwp5proc xml\"\n",
    "        result_data = result.stdout\n",
    "\n",
    "        # 생성된 폴더 이동\n",
    "        generated_folder = os.path.join(os.getcwd(), base_name)\n",
    "        if os.path.exists(generated_folder):\n",
    "            for item in os.listdir(generated_folder):\n",
    "                s = os.path.join(generated_folder, item)\n",
    "                d = os.path.join(html_output_dir, item)\n",
    "                shutil.move(s, d)\n",
    "            os.rmdir(generated_folder)\n",
    "            print(f\"[hwp5proc xml] 결과 폴더 이동 완료: {html_output_dir}\")\n",
    "        return method_used, result_data\n",
    "    except Exception as e:\n",
    "        print(f\"[hwp5proc xml 실패] {e}\")\n",
    "\n",
    "    # --- 2. hwp5html ---\n",
    "    try:\n",
    "        html_result = subprocess.run(\n",
    "            ['/home/spai0323/myenv/bin/hwp5html', file_path],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        method_used = \"hwp5html\"\n",
    "        result_data = html_result.stdout\n",
    "\n",
    "        if result_data:\n",
    "            index_path = os.path.join(html_output_dir, 'index.xhtml')\n",
    "            with open(index_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(result_data)\n",
    "            print(f\"[hwp5html] HTML 저장 완료: {index_path}\")\n",
    "\n",
    "            # 표 파싱 & 저장\n",
    "            tables = parse_html_tables(result_data)\n",
    "            for table in tables:\n",
    "                table_file = os.path.join(html_output_dir, f\"{base_name}_table_{table['table_index']}.csv\")\n",
    "                table['df'].to_csv(table_file, index=False, encoding='utf-8-sig')\n",
    "                print(f\"[hwp5html] 표 {table['table_index']} 저장: {table_file}\")\n",
    "\n",
    "        return method_used, result_data\n",
    "    except Exception as e:\n",
    "        print(f\"[hwp5html 실패] {e}\")\n",
    "\n",
    "    # --- 3. hwp5txt ---\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['/home/spai0323/myenv/bin/hwp5txt', file_path],\n",
    "            capture_output=True, text=True, check=True\n",
    "        )\n",
    "        method_used = \"hwp5txt\"\n",
    "        result_data = result.stdout\n",
    "\n",
    "        with open(text_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(result_data)\n",
    "        print(f\"[hwp5txt] 텍스트 저장 완료: {text_file_path}\")\n",
    "\n",
    "        return method_used, result_data\n",
    "    except Exception as e:\n",
    "        print(f\"[hwp5txt 실패] {e}\")\n",
    "\n",
    "    # 모든 방법 실패\n",
    "    return None, None\n",
    "\n",
    "def process_file(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == '.hwp':\n",
    "        return process_hwp(file_path)\n",
    "    else:\n",
    "        print(f\"지원하지 않는 파일 형식: {file_path}\")\n",
    "        return None, None\n",
    "\n",
    "def process_pdf(file_path):\n",
    "    \"\"\"\n",
    "    PDF 파일을 HWP와 유사한 방식으로 처리\n",
    "    \"\"\"\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    # 출력 경로 설정\n",
    "    processed_dir = '../data/processed/datapreprocessinbjs(xhtml)/xhtml'\n",
    "    extracted_text_dir = os.path.join(processed_dir, 'extracted_text')\n",
    "    os.makedirs(extracted_text_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(processed_dir, base_name), exist_ok=True)\n",
    "\n",
    "    # 1. 텍스트 추출\n",
    "    reader = PdfReader(file_path)\n",
    "    text_content = \"\\n\".join([page.extract_text() or \"\" for page in reader.pages])\n",
    "\n",
    "    text_path = os.path.join(extracted_text_dir, f\"{base_name}_pdf_extracted_text.txt\")\n",
    "    with open(text_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text_content)\n",
    "    print(f\"PDF 텍스트 저장됨: {text_path}\")\n",
    "\n",
    "    # 2. HTML 변환 (pdf2htmlEX 설치 필요)\n",
    "    try:\n",
    "        html_path = os.path.join(processed_dir, base_name, \"index.xhtml\")\n",
    "        subprocess.run(['pdf2htmlEX', file_path, html_path], check=True)\n",
    "        print(f\"PDF HTML 저장됨: {html_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"HTML 변환 실패: {e}\")\n",
    "\n",
    "    # 3. HTML에서 표 추출 (HWP와 동일 로직 재사용)\n",
    "    try:\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            html_content = f.read()\n",
    "        tables = parse_html_tables(html_content)\n",
    "\n",
    "        for table in tables:\n",
    "            table_file = os.path.join(processed_dir, base_name, f\"table_{table['table_index']}.csv\")\n",
    "            table['df'].to_csv(table_file, index=False, encoding='utf-8-sig')\n",
    "            print(f\"표 {table['table_index']} 저장됨: {table_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"표 추출 실패: {e}\")\n",
    "\n",
    "def process_file(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    \n",
    "    if ext == '.hwp':\n",
    "        return process_hwp(file_path)\n",
    "    elif ext == '.pdf':\n",
    "        return process_pdf(file_path)\n",
    "    else:\n",
    "        print(f\"지원하지 않는 파일 형식: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "# 단일 HWP 파일\n",
    "file_path = '../data/raw/files/(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅.hwp'\n",
    "method, content = process_file(file_path)\n",
    "print(f\"\\n최종 사용된 방법: {method}\")\n",
    "print(f\"추출된 텍스트 길이: {len(content) if content else 0} 문자\")\n",
    "\n",
    "# # 단일 PDF 파일\n",
    "# file_path = '../data/raw/files/고려대학교_차세대 포털·학사 정보시스템 구축사업.pdf'\n",
    "# process_file(file_path)\n",
    "\n",
    "# # 여러 파일 처리\n",
    "# import glob\n",
    "\n",
    "# all_files = glob.glob('../data/raw/files/*')\n",
    "\n",
    "# for file_path in all_files:\n",
    "#     print(f\"=== Processing: {file_path} ===\")\n",
    "#     process_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d839709-c28c-4b71-a6af-a48749d0a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements (예시)\n",
    "%pip install beautifulsoup4 lxml langchain chromadb openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7039b46-0d2d-40fc-8a60-106b051c4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "# import os, json\n",
    "# from typing import List, Dict, Tuple\n",
    "# from langchain.schema import Document\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# import chromadb\n",
    "# from chromadb.config import Settings\n",
    "# from chromadb.utils import embedding_functions\n",
    "# import openai\n",
    "\n",
    "# ### 1) XHTML 파싱 -> 표, 셀, 색상, 텍스트 추출\n",
    "# def parse_xhtml_tables(xhtml_path: str) -> List[Dict]:\n",
    "#     with open(xhtml_path, 'r', encoding='utf-8') as f:\n",
    "#         soup = BeautifulSoup(f, 'lxml')\n",
    "#     tables = []\n",
    "#     for ti, table in enumerate(soup.find_all('table')):\n",
    "#         rows = []\n",
    "#         for ri, tr in enumerate(table.find_all('tr')):\n",
    "#             cells = []\n",
    "#             for ci, td in enumerate(tr.find_all(['td','th'])):\n",
    "#                 text = td.get_text(separator=' ', strip=True)\n",
    "#                 style = td.get('style','')\n",
    "#                 # 색상 추출 예시: background-color: #ffeb9c;\n",
    "#                 color = None\n",
    "#                 if 'background' in style or 'background-color' in style:\n",
    "#                     # 간단 파싱(복잡하면 regex 확장)\n",
    "#                     if 'background-color' in style:\n",
    "#                         seg = [s for s in style.split(';') if 'background-color' in s]\n",
    "#                     else:\n",
    "#                         seg = [s for s in style.split(';') if 'background' in s]\n",
    "#                     if seg:\n",
    "#                         color = seg[0].split(':')[1].strip()\n",
    "#                 cells.append({'text': text, 'style': style, 'color': color,\n",
    "#                               'row': ri, 'col': ci, 'raw_html': str(td)})\n",
    "#             rows.append(cells)\n",
    "#         tables.append({'file': os.path.basename(xhtml_path), 'table_id': ti, 'rows': rows})\n",
    "#     return tables\n",
    "\n",
    "# ### 2) 색상→월 매핑 (예: 첫 행이 연/월 헤더라 가정)\n",
    "# def color_to_months(table: Dict) -> List[Document]:\n",
    "#     rows = table['rows']\n",
    "#     # 가정: header row contains year/month in cols (사용 환경에 따라 커스터마이즈)\n",
    "#     header = rows[0]\n",
    "#     months = []\n",
    "#     for cell in header:\n",
    "#         txt = cell['text']\n",
    "#         # '2024' 와 '3','4',... 이런 구조라면 조합 필요. 단순 예:\n",
    "#         months.append(txt)\n",
    "#     docs = []\n",
    "#     # iterate data rows\n",
    "#     for r in rows[1:]:\n",
    "#         row_label = r[0]['text'] if r else ''\n",
    "#         for ci, cell in enumerate(r[1:], start=1):\n",
    "#             color = cell.get('color')\n",
    "#             text = cell.get('text','')\n",
    "#             if color:  # 색칠된 셀만 일정으로 간주\n",
    "#                 # 단일셀이면 start=end=ci index -> map to month via header\n",
    "#                 month_label = months[ci] if ci < len(months) else f\"col{ci}\"\n",
    "#                 meta = {\n",
    "#                     'source': table['file'],\n",
    "#                     'table_id': table['table_id'],\n",
    "#                     'row_label': row_label,\n",
    "#                     'col_index': ci,\n",
    "#                     'month_label': month_label,\n",
    "#                     'color': color\n",
    "#                 }\n",
    "#                 docs.append(Document(page_content=f\"{row_label} — {text} (표: {table['table_id']}, col:{ci})\",\n",
    "#                                      metadata=meta))\n",
    "#     return docs\n",
    "\n",
    "# ### 3) 청킹(예: langchain text splitter)\n",
    "# splitter = RecursiveCharacterTextSplitter(chunk_size=450, chunk_overlap=100)\n",
    "\n",
    "# def chunk_documents(docs: List[Document]) -> List[Document]:\n",
    "#     out = []\n",
    "#     for d in docs:\n",
    "#         pieces = splitter.split_text(d.page_content)\n",
    "#         for i,p in enumerate(pieces):\n",
    "#             m = dict(d.metadata)\n",
    "#             m.update({'chunk_index': i})\n",
    "#             out.append(Document(page_content=p, metadata=m))\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cd34e97-b986-40c7-9c8c-e4896411d772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'../(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅' 폴더와 모든 내용이 성공적으로 삭제되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# 삭제할 폴더 경로를 지정하세요.\n",
    "folder_path = '../(재)예술경영지원센터_통합 정보시스템 구축 사전 컨설팅'\n",
    "try:\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(f\"'{folder_path}' 폴더와 모든 내용이 성공적으로 삭제되었습니다.\")\n",
    "except OSError as e:\n",
    "    print(f\"오류: {e.strerror} - {e.filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7c42f-8e1f-4cdd-af8b-65ffc1932a69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
