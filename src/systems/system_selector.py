"""
RAG ì‹œìŠ¤í…œ ì„ íƒê¸°
ë‘ ì‹œìŠ¤í…œ(FAISS, ChromaDB) ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í†µí•© ì¸í„°í˜ì´ìŠ¤
"""

import logging
import sys
from typing import Dict, Any, List, Optional
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.config.unified_config import UnifiedConfig
from src.rfp_rag_main import RFPRAGSystem  # ê¸°ì¡´ ì‹œìŠ¤í…œ
from src.retrieval.hybrid_retriever import Retriever # ë¦¬íŠ¸ë¦¬ë²„ 
from src.retrieval.rerank import RerankModel # ë¦¬ë­í¬ ëª¨ë¸
from src.generation.generator import RFPGenerator

logger = logging.getLogger(__name__)

class SystemSelector:
    """RAG ì‹œìŠ¤í…œ ì„ íƒ ë° ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config: UnifiedConfig):
        self.config = config
        self._systems: Dict[str, Any] = {}
        self._current_system: Optional[str] = None
        
    def initialize_system(self, system_name: str, force_rebuild: bool = False) -> Any:
        """
        íŠ¹ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            system_name: "faiss" ë˜ëŠ” "chromadb"
            force_rebuild: ê°•ì œ ì¬êµ¬ì¶• ì—¬ë¶€
            
        Returns:
            ì´ˆê¸°í™”ëœ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
        """
        if system_name in self._systems and not force_rebuild:
            logger.info(f"âœ… {system_name} ì‹œìŠ¤í…œì´ ì´ë¯¸ ì´ˆê¸°í™”ë¨")
            return self._systems[system_name]
            
        logger.info(f"ğŸ”„ {system_name} ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        if system_name == "faiss":
            system = self._initialize_faiss_system()
        elif system_name == "chromadb":
            system = self._initialize_chromadb_system()
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œìŠ¤í…œ: {system_name}")
            
        self._systems[system_name] = system
        self._current_system = system_name
        logger.info(f"âœ… {system_name} ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        return system
    
    def _initialize_faiss_system(self) -> RFPRAGSystem:
        """ê¸°ì¡´ FAISS ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ê¸°ì¡´ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            system = RFPRAGSystem(
                json_dir=str(self.config.processed_dir / "json"),
                embedding_model=self.config.get_system_config("faiss").embedder_model,
                chunk_size=1000,
                overlap=150,
                cache_dir=str(self.config.get_system_config("faiss").cache_dir)
            )
            
            # ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤í–‰
            logger.info("ğŸ”§ FAISS ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            system.initialize()
            logger.info("âœ… FAISS ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
            return system
        except Exception as e:
            logger.error(f"âŒ FAISS ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _initialize_chromadb_system(self) -> Retriever:
        """ChromaDB ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            import pandas as pd
            from langchain_huggingface import HuggingFaceEmbeddings
            from sentence_transformers import CrossEncoder
            from src.retrieval.tokenizer_wrapper import TokenizerWrapper
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            meta_df = pd.read_csv(self.config.meta_csv_path)
            
            # ì‹œìŠ¤í…œ ì„¤ì •
            system_config = self.config.get_system_config("chromadb")
            
            # ëª¨ë¸ ì´ˆê¸°í™” (GPU ì‚¬ìš©)
            logger.info(f"ğŸ”§ ChromaDB ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”: {system_config.embedder_model} on {self.config.device}")
            embedder = HuggingFaceEmbeddings(
                model_name=system_config.embedder_model,
                model_kwargs={"device": self.config.device},
                encode_kwargs={"device": self.config.device}
            )
            
            reranker = RerankModel(
                model_name=system_config.reranker_model,
                cache_dir=system_config.rerank_cache_dir,
                device=self.config.device,
            )
            
            tokenizer = TokenizerWrapper(system_config.tokenizer_engine)
            
            # Retriever ì´ˆê¸°í™”
            persist_dir = str(system_config.persist_directory) if system_config.persist_directory else None
            logger.info(f"ğŸ”§ ChromaDB persist_directory: {persist_dir}")
            logger.info(f"ğŸ”§ system_config.persist_directory: {system_config.persist_directory}")
            retriever = Retriever(
                meta_df=meta_df,
                embedder=embedder,
                reranker=reranker,
                tokenizer=tokenizer,
                persist_directory=persist_dir,
                rerank_max_length=system_config.rerank_max_length,
                bm25_path=str(system_config.cache_dir / "bm25_index.pkl"),
                debug_mode=True
            )
            
            # ë¬¸ì„œ ë¡œë”© ë° ë²¡í„° DB êµ¬ì¶• (ì¤‘ìš”!)
            logger.info("ğŸ“š ë¬¸ì„œ ë¡œë”© ì¤‘...")
            import asyncio
            json_dir = self.config.processed_dir / "json"
            logger.info(f"ğŸ“‚ JSON ë””ë ‰í† ë¦¬: {json_dir}")
            docs = asyncio.run(retriever.load_or_cache_json_docs(
                str(json_dir), 
                cache_path=str(system_config.cache_dir / "cached_json_docs.pkl")
            ))
            
            logger.info("ğŸ”§ ë²¡í„° DB êµ¬ì¶• ì¤‘...")
            logger.info(f"ğŸ“Š ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(docs) if docs else 0}")
            retriever.set_weights(bm25_weight=0.3, rerank_weight=0.7)
            retriever.load_or_build_vector_db(docs)
            
            logger.info("âœ… ChromaDB ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return retriever
            
        except Exception as e:
            logger.error(f"âŒ ChromaDB ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def get_system(self, system_name: str = None) -> Any:
        """ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        if system_name is None:
            system_name = self.config.default_system
            
        if system_name not in self._systems:
            return self.initialize_system(system_name)
            
        return self._systems[system_name]
    
    def switch_system(self, system_name: str) -> Any:
        """ì‹œìŠ¤í…œ ì „í™˜"""
        if system_name not in self.config.get_available_systems():
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œìŠ¤í…œ: {system_name}")
            
        return self.get_system(system_name)
    
    def get_system_status(self) -> Dict[str, Any]:
        """ëª¨ë“  ì‹œìŠ¤í…œì˜ ìƒíƒœ ë°˜í™˜"""
        status = {}
        
        for system_name in self.config.get_available_systems():
            system_info = self.config.get_system_info(system_name)
            is_initialized = system_name in self._systems
            
            status[system_name] = {
                **system_info,
                "initialized": is_initialized,
                "is_current": system_name == self._current_system
            }
            
        return status
    
    def clear_cache(self, system_name: str = None):
        """ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬"""
        if system_name is None:
            # ëª¨ë“  ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬
            for sys_name in self.config.get_available_systems():
                self._clear_system_cache(sys_name)
        else:
            self._clear_system_cache(system_name)
    
    def _clear_system_cache(self, system_name: str):
        """íŠ¹ì • ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬"""
        system_config = self.config.get_system_config(system_name)
        
        if system_name == "faiss":
            # FAISS ìºì‹œ ì •ë¦¬
            cache_files = [
                system_config.cache_dir / "chunks.pkl",
                system_config.cache_dir / "embeddings.npy", 
                system_config.cache_dir / "metadata.pkl"
            ]
            
        elif system_name == "chromadb":
            # ChromaDB ìºì‹œ ì •ë¦¬
            cache_files = [
                system_config.cache_dir / "cached_json_docs.pkl",
                system_config.cache_dir / "cached_csv_docs.pkl",
                system_config.cache_dir / "bm25_index.pkl"
            ]
            
            # ChromaDB ë””ë ‰í† ë¦¬ë„ ì •ë¦¬
            if system_config.persist_directory and system_config.persist_directory.exists():
                import shutil
                shutil.rmtree(system_config.persist_directory)
                logger.info(f"ğŸ—‘ï¸ ChromaDB ë””ë ‰í† ë¦¬ ì •ë¦¬: {system_config.persist_directory}")
            
            # Rerank ìºì‹œ ë””ë ‰í† ë¦¬ë„ ì •ë¦¬   
            if system_config.rerank_cache_dir and system_config.rerank_cache_dir.exists():
                shutil.rmtree(system_config.rerank_cache_dir)
                logger.info(f"ğŸ—‘ï¸ Rerank ìºì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬: {system_config.rerank_cache_dir}")
        
        # ìºì‹œ íŒŒì¼ ì •ë¦¬
        for cache_file in cache_files:
            if cache_file.exists():
                cache_file.unlink()
                logger.info(f"ğŸ—‘ï¸ ìºì‹œ íŒŒì¼ ì‚­ì œ: {cache_file}")
        
        # ë©”ëª¨ë¦¬ì—ì„œ ì‹œìŠ¤í…œ ì œê±°
        if system_name in self._systems:
            del self._systems[system_name]
            if self._current_system == system_name:
                self._current_system = None
                
        logger.info(f"âœ… {system_name} ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")
    
    def ask(self, question: str, system_name: str = None) -> Dict[str, Any]:
        """ì„ íƒëœ ì‹œìŠ¤í…œìœ¼ë¡œ ì§ˆë¬¸ ì²˜ë¦¬ (ì§ˆë¬¸ ë¶„ë¥˜ ë‹¨ê³„ í¬í•¨)"""
        if system_name is None:
            system_name = self._current_system
            
        if not system_name:
            return {"answer": "ì‹œìŠ¤í…œì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "sources": []}
            
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™” í™•ì¸
        if system_name not in self._systems:
            return {"answer": f"{system_name} ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "sources": []}
            
        system = self._systems[system_name]
        
        # 1. ì§ˆë¬¸ ë¶„ë¥˜ ë‹¨ê³„ ì¶”ê°€
        logger.info(f"ğŸ” ì§ˆë¬¸ ë¶„ë¥˜ ì‹œì‘: {question[:50]}...")
        try:
            from src.classification.question_classifier import get_question_classifier
            classifier = get_question_classifier()
            classification_result = classifier.classify_question(question)
            
            logger.info(f"âœ… ì§ˆë¬¸ ë¶„ë¥˜ ì™„ë£Œ: {classification_result.question_type.value} (ì‹ ë¢°ë„: {classification_result.confidence:.3f})")
            logger.info(f"ğŸ“ ë¶„ë¥˜ ê·¼ê±°: {classification_result.reasoning}")
            logger.info(f"ğŸ¯ ì œì•ˆ í”„ë¡¬í”„íŠ¸ íƒ€ì…: {classification_result.suggested_prompt_type}")

            # ì¼ìƒ ì§ˆë¬¸ì¸ ê²½ìš° RFP ë¬¸ì„œ ê²€ìƒ‰ ì—†ì´ ê°„ë‹¨íˆ ì‘ë‹µ
            if classification_result.question_type.value == "ì¼ìƒ":
                logger.info("ğŸ’¬ ì¼ìƒ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë¨ - RFP ë¬¸ì„œ ê²€ìƒ‰ ìƒëµ")
                return {
                    "answer": "ì•ˆë…•í•˜ì„¸ìš”! RFP ë¬¸ì„œ ë¶„ì„ ë„êµ¬ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì‚¬ì—… ì •ë³´ë‚˜ ì…ì°° ê´€ë ¨ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                    "sources": [],
                    "total_documents": 0,
                    "total_chunks": 0,
                    "question_classification": {
                        "type": classification_result.question_type.value,
                        "confidence": classification_result.confidence,
                        "reasoning": classification_result.reasoning,
                        "prompt_type": classification_result.suggested_prompt_type
                    }
                }

        except Exception as e:
            logger.error(f"âŒ ì§ˆë¬¸ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            # ë¶„ë¥˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
            classification_result = None
        
        try:
            if system_name == "faiss":
                # FAISS ì‹œìŠ¤í…œ ì§ˆë¬¸ ì²˜ë¦¬ (ì§ˆë¬¸ ë¶„ë¥˜ ê²°ê³¼ ì ìš©)
                logger.info(f"ğŸ” FAISS ì‹œìŠ¤í…œ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: {question[:50]}...")
                
                # ì§ˆë¬¸ ë¶„ë¥˜ ê²°ê³¼ë¥¼ FAISS ì‹œìŠ¤í…œì— ì „ë‹¬
                if classification_result:
                    # RFPGeneratorì— ì§ˆë¬¸ ìœ í˜• ì„¤ì •
                    if hasattr(system, 'generator') and hasattr(system.generator, 'question_type'):
                        system.generator.question_type = classification_result.suggested_prompt_type
                        logger.info(f"ğŸ¯ FAISS Generatorì— ì§ˆë¬¸ ìœ í˜• ì ìš©: {classification_result.suggested_prompt_type}")
                
                response = system.ask_detailed(question)
                logger.info(f"âœ… FAISS ë‹µë³€ ìƒì„± ì™„ë£Œ: {response.answer[:100]}...")
                
                return {
                    "answer": response.answer,
                    "sources": [
                        {
                            "content": chunk.get("content", "N/A"),
                            "source_file": chunk.get("source_file", "N/A"),
                            "page": chunk.get("page", "N/A"),
                            "score": chunk.get("score", 0.0)
                        }
                        for chunk in response.retrieved_chunks
                    ],
                    "total_documents": len(system.documents),
                    "total_chunks": len(system.retriever.vector_store.chunks) if hasattr(system.retriever, 'vector_store') else 0,
                    "question_classification": {
                        "type": classification_result.question_type.value if classification_result else "unknown",
                        "confidence": classification_result.confidence if classification_result else 0.0,
                        "reasoning": classification_result.reasoning if classification_result else "ë¶„ë¥˜ ì‹¤íŒ¨",
                        "prompt_type": classification_result.suggested_prompt_type if classification_result else "general"
                    }
                }
            elif system_name == "chromadb":
                # ChromaDB ì‹œìŠ¤í…œ ì§ˆë¬¸ ì²˜ë¦¬
                logger.info(f"ğŸ” ChromaDB ì‹œìŠ¤í…œ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: {question[:50]}...")
                results = system.smart_search(question, top_k=5)
                logger.info(f"âœ… ChromaDB ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                
                # LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„± (í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì ìš©)
                logger.info("ğŸ¤– LLM ë‹µë³€ ìƒì„± ì‹œì‘...")
                from src.generation.generator import RFPGenerator
                generator = RFPGenerator()  # rag_config.yamlì—ì„œ ìë™ìœ¼ë¡œ ì„¤ì • ë¡œë“œ
                
                # Generator ì´ˆê¸°í™”
                logger.info("ğŸ”§ RFPGenerator ì´ˆê¸°í™” ì¤‘...")
                generator.initialize()
                logger.info("âœ… RFPGenerator ì´ˆê¸°í™” ì™„ë£Œ")
                
                # í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
                logger.info("ğŸ“ í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘...")
                from src.prompts.prompt_manager import get_prompt_manager
                prompt_manager = get_prompt_manager()
                generator.prompt_manager = prompt_manager
                logger.info(f"âœ… í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ: {prompt_manager.current_version}")
                
                # ì§ˆë¬¸ ë¶„ë¥˜ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì €ì— ì „ë‹¬
                if classification_result:
                    generator.question_type = classification_result.suggested_prompt_type
                    logger.info(f"ğŸ¯ ì§ˆë¬¸ ìœ í˜• ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ì ìš©: {classification_result.suggested_prompt_type}")
                
                # ê²€ìƒ‰ ê²°ê³¼ë¥¼ RetrievalResult í˜•íƒœë¡œ ë³€í™˜
                from src.data_processing.data_models import RetrievalResult, DocumentChunk
                retrieval_results = []
                for i, doc in enumerate(results):
                    chunk = DocumentChunk(
                        chunk_id=f"chromadb_{i}",
                        doc_id=doc.metadata.get("source_file", "unknown"),
                        content=doc.page_content,
                        chunk_type="text",
                        metadata=doc.metadata
                    )
                    score = system.last_scores.get(system.get_doc_key(doc), {}).get("combined", 0.0)
                    retrieval_results.append(RetrievalResult(chunk=chunk, score=score, rank=i+1))
                
                logger.info(f"ğŸ”„ {len(retrieval_results)}ê°œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ RetrievalResultë¡œ ë³€í™˜ ì™„ë£Œ")
                llm_response = generator.generate_response(question, retrieval_results)
                logger.info(f"âœ… LLM ë‹µë³€ ìƒì„± ì™„ë£Œ: {llm_response.answer[:100]}...")
                
                return {
                    "answer": llm_response.answer,
                    "sources": [
                        {
                            "content": doc.page_content,
                            "source_file": doc.metadata.get("source_file", "N/A"),
                            "page": doc.metadata.get("page", "N/A"),
                            "score": system.last_scores.get(system.get_doc_key(doc), {}).get("combined", 0.0)
                        }
                        for doc in results
                    ],
                    "total_documents": len(system.documents),
                    "total_chunks": len(system.documents),
                    "question_classification": {
                        "type": classification_result.question_type.value if classification_result else "unknown",
                        "confidence": classification_result.confidence if classification_result else 0.0,
                        "reasoning": classification_result.reasoning if classification_result else "ë¶„ë¥˜ ì‹¤íŒ¨",
                        "prompt_type": classification_result.suggested_prompt_type if classification_result else "general"
                    }
                }
            else:
                return {"answer": "ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.", "sources": []}
                
        except Exception as e:
            logger.error(f"âŒ {system_name} ì‹œìŠ¤í…œ ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {"answer": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "sources": []}
