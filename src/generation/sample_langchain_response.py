import os
from dotenv import load_dotenv
from typing import List, Union

from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# LangChain QA ì²´ì¸ ì´ˆê¸°í™” í•¨ìˆ˜
def get_qa_chain():
    llm = ChatOpenAI(
        openai_api_key=OPENAI_API_KEY,
        model_name="gpt-4o-mini",# gpt5ëŠ” ë„ˆë¬´ ëŠë¦¼. ì‹¬ì§€ì–´ 5ëŠ” temperature ë¬´ì¡°ê±´ 1
        temperature=1,
    )

    prompt = ChatPromptTemplate.from_template("""
    ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤:

    {context}

    ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:
    ì§ˆë¬¸: {question}
    """)

    return LLMChain(llm=llm, prompt=prompt)

# ë¬¸ì„œ ë³‘í•© í•¨ìˆ˜

def merge_docs_to_text(docs):
    """
    ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼(Document ë¦¬ìŠ¤íŠ¸)ë¥¼ ë°›ì•„ì„œ
    LLM contextë¡œ í•©ì¹˜ëŠ” í•¨ìˆ˜.
    metadata ì „ì²´ì™€ page_contentë¥¼ í•¨ê»˜ í¬í•¨ì‹œí‚´
    """
    if not docs:
        return ""

    merged = []
    for doc in docs:
        # ğŸ”¹ ë©”íƒ€ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        metadata_text = "\n".join([f"{k}: {v}" for k, v in doc.metadata.items()])
        # ğŸ”¹ ë³¸ë¬¸ ë‚´ìš©
        content = doc.page_content.strip()
        # ğŸ”¹ ë³‘í•©
        merged.append(
            f"[ì¶œì²˜: {doc.metadata.get('íŒŒì¼ëª…', 'â“')}]\n\n"
            f"{metadata_text}\n\n"
            f"ì‚¬ì—… ìš”ì•½:\n{content}"
        )

    return "\n\n---\n\n".join(merged)
