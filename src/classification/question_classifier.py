"""
ì§ˆë¬¸ ë¶„ë¥˜ê¸° ëª¨ë“ˆ
ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì§ˆë¬¸ ìœ í˜•ì„ íŒŒì•…í•˜ê³ , í•´ë‹¹ ìœ í˜•ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì œê³µ
"""

import logging
import json
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

class QuestionType(Enum):
    """ì§ˆë¬¸ ìœ í˜• ì—´ê±°í˜•"""
    EVERYDAY = "ì¼ìƒ"           # ì¼ë°˜ì ì¸ ëŒ€í™”ë‚˜ ìƒì‹ ì§ˆë¬¸
    STATISTICS = "í†µê³„"         # ìˆ˜ì¹˜, ë°ì´í„°, í†µê³„ ê´€ë ¨ ì§ˆë¬¸
    ANALYSIS = "ë¶„ì„"           # ì‹¬ì¸µ ë¶„ì„, ë¹„êµ, í‰ê°€ ìš”ì²­
    SUMMARY = "ìš”ì•½"            # ë¬¸ì„œë‚˜ ë‚´ìš© ìš”ì•½ ìš”ì²­
    SEARCH = "ê²€ìƒ‰"             # íŠ¹ì • ì •ë³´ ê²€ìƒ‰ ìš”ì²­
    COMPARISON = "ë¹„êµ"         # ì—¬ëŸ¬ í•­ëª© ë¹„êµ ìš”ì²­
    EXPLANATION = "ì„¤ëª…"        # ê°œë…ì´ë‚˜ ê³¼ì • ì„¤ëª… ìš”ì²­
    RECOMMENDATION = "ì¶”ì²œ"     # ì¶”ì²œì´ë‚˜ ì œì•ˆ ìš”ì²­

@dataclass
class ClassificationResult:
    """ì§ˆë¬¸ ë¶„ë¥˜ ê²°ê³¼"""
    question_type: QuestionType
    confidence: float
    reasoning: str
    suggested_prompt_type: str

class QuestionClassifier:
    """ì§ˆë¬¸ ë¶„ë¥˜ê¸° í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str = None, api_key: Optional[str] = None):
        self.model_name = model_name
        self.api_key = api_key
        self.client = None
        self._is_ready = False
        
        # ì§ˆë¬¸ ìœ í˜•ë³„ í‚¤ì›Œë“œ ë§¤í•‘
        self.type_keywords = {
            QuestionType.EVERYDAY: ["ì•ˆë…•", "ì–´ë–»ê²Œ", "ë­ì•¼", "ì™œ", "ì–¸ì œ", "ì–´ë””", "ëˆ„êµ¬", "ì¼ë°˜ì ", "ìƒì‹", "ë‚ ì”¨", "ë°ì´íŠ¸"],
            QuestionType.STATISTICS: ["ëª‡", "ì–¼ë§ˆ", "ìˆ˜ì¹˜", "í†µê³„", "ë¹„ìœ¨", "í¼ì„¼íŠ¸", "ê°œìˆ˜", "ê¸ˆì•¡", "ì˜ˆì‚°", "ë¹„ìš©"],
            QuestionType.ANALYSIS: ["ë¶„ì„", "ë¹„êµ", "í‰ê°€", "ê²€í† ", "ê²€ì¦", "ê³ ë ¤ì‚¬í•­", "ì¥ë‹¨ì ", "íŠ¹ì§•"],
            QuestionType.SUMMARY: ["ìš”ì•½", "ì •ë¦¬", "í•µì‹¬", "ê°œìš”", "ì¤„ê±°ë¦¬", "ê°„ë‹¨íˆ"],
            QuestionType.SEARCH: ["ì°¾ì•„", "ê²€ìƒ‰", "ì–´ë””ì—", "ë¬´ì—‡ì´", "ë¬´ì—‡ì„", "ì •ë³´"],
            QuestionType.COMPARISON: ["ë¹„êµ", "ì°¨ì´", "vs", "ëŒ€ë¹„", "ìƒëŒ€ì ", "ì–´ëŠìª½"],
            QuestionType.EXPLANATION: ["ì„¤ëª…", "ì´í•´", "ì˜ë¯¸", "ì •ì˜", "ê³¼ì •", "ë°©ë²•", "ì–´ë–»ê²Œ"],
            QuestionType.RECOMMENDATION: ["ì¶”ì²œ", "ì œì•ˆ", "ê¶Œì¥", "ì–´ë–¤", "ì„ íƒ", "ê²°ì •"]
        }
        
        # ì§ˆë¬¸ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ íƒ€ì… ë§¤í•‘
        self.prompt_type_mapping = {
            QuestionType.EVERYDAY: "general",
            QuestionType.STATISTICS: "statistical",
            QuestionType.ANALYSIS: "analytical",
            QuestionType.SUMMARY: "summarization",
            QuestionType.SEARCH: "search",
            QuestionType.COMPARISON: "comparison",
            QuestionType.EXPLANATION: "explanatory",
            QuestionType.RECOMMENDATION: "recommendation"
        }
    
    def initialize(self):
        """ë¶„ë¥˜ê¸° ì´ˆê¸°í™”"""
        try:
            from openai import OpenAI
            import yaml
            import os
            from pathlib import Path
            
            # API í‚¤ ì„¤ì •
            api_key = self.api_key
            
            # ì„¤ì • íŒŒì¼ì—ì„œ ëª¨ë¸ëª…ê³¼ API í‚¤ ì •ë³´ ë¡œë“œ
            try:
                # .env íŒŒì¼ ë¡œë“œ ì‹œë„
                try:
                    from dotenv import load_dotenv
                    load_dotenv()
                    logger.info("âœ… .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
                except ImportError:
                    logger.warning("âš ï¸ python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                except Exception as dotenv_error:
                    logger.warning(f"âš ï¸ .env íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {dotenv_error}")
                
                config_path = Path("config/rag_config.yaml")
                if config_path.exists():
                    with open(config_path, 'r', encoding='utf-8') as f:
                        config = yaml.safe_load(f)
                    
                    # ëª¨ë¸ëª… ì„¤ì • (ê¸°ë³¸ê°’: gpt-4.1-mini)
                    if not self.model_name:
                        self.model_name = config.get('llm', {}).get('model', 'gpt-4.1-mini')
                    
                    # API í‚¤ ì„¤ì •
                    if not api_key:
                        api_key_env = config.get('llm', {}).get('api_key_env', 'OPENAI_API_KEY')
                        api_key = os.getenv(api_key_env)
                        
                        if api_key:
                            logger.info(f"âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ: {api_key_env}")
                        else:
                            logger.warning(f"âš ï¸ í™˜ê²½ë³€ìˆ˜ {api_key_env}ì—ì„œ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            except Exception as config_error:
                logger.warning(f"âš ï¸ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {config_error}")
                if not self.model_name:
                    self.model_name = "gpt-3.5-turbo"  # í´ë°± ëª¨ë¸
            
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            if api_key:
                self.client = OpenAI(api_key=api_key)
            else:
                # API í‚¤ê°€ ì—†ì–´ë„ í´ë¼ì´ì–¸íŠ¸ ìƒì„± (í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ ì°¾ìŒ)
                self.client = OpenAI()
            
            self._is_ready = True
            logger.info(f"âœ… ì§ˆë¬¸ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ: {self.model_name}")
            
        except Exception as e:
            logger.error(f"âŒ ì§ˆë¬¸ ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def is_ready(self) -> bool:
        """ì´ˆê¸°í™” ìƒíƒœ í™•ì¸"""
        return self._is_ready and self.client is not None
    
    def classify_question(self, question: str) -> ClassificationResult:
        """
        ì§ˆë¬¸ì„ ë¶„ë¥˜í•˜ì—¬ ì ì ˆí•œ ì§ˆë¬¸ ìœ í˜•ì„ ê²°ì •
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            ClassificationResult: ë¶„ë¥˜ ê²°ê³¼
        """
        if not self.is_ready():
            raise RuntimeError("Classifier is not initialized. Call initialize() first.")
        
        try:
            # 1. í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ë¥˜ ì‹œë„
            quick_result = self._quick_classify(question)
            if quick_result and quick_result.confidence > 0.8:
                logger.info(f"ğŸ” í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ë¥˜: {quick_result.question_type.value}")
                return quick_result
            
            # 2. LLM ê¸°ë°˜ ì •ë°€ ë¶„ë¥˜
            llm_result = self._llm_classify(question)
            logger.info(f"ğŸ¤– LLM ê¸°ë°˜ ë¶„ë¥˜: {llm_result.question_type.value} (ì‹ ë¢°ë„: {llm_result.confidence:.3f})")
            return llm_result
            
        except Exception as e:
            logger.error(f"âŒ ì§ˆë¬¸ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return ClassificationResult(
                question_type=QuestionType.SEARCH,
                confidence=0.5,
                reasoning="ë¶„ë¥˜ ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ê°’ ì„¤ì •",
                suggested_prompt_type="search"
            )
    
    def _quick_classify(self, question: str) -> Optional[ClassificationResult]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ë¶„ë¥˜"""
        question_lower = question.lower()
        
        # íŠ¹ì • í‚¤ì›Œë“œì— ëŒ€í•œ ê°•ì œ ë¶„ë¥˜ (ë†’ì€ ìš°ì„ ìˆœìœ„)
        high_priority_keywords = {
            "ì•ˆë…•": QuestionType.EVERYDAY,
            "ë‚ ì”¨": QuestionType.EVERYDAY,
            "ë°ì´íŠ¸": QuestionType.EVERYDAY,
            "ìƒì‹": QuestionType.EVERYDAY
        }
        
        # ê³ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ í™•ì¸
        for keyword, q_type in high_priority_keywords.items():
            if keyword in question_lower:
                return ClassificationResult(
                    question_type=q_type,
                    confidence=0.9,  # ë†’ì€ ì‹ ë¢°ë„ë¡œ ì„¤ì •
                    reasoning=f"ê³ ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ë§¤ì¹­: {keyword}",
                    suggested_prompt_type=self.prompt_type_mapping[q_type]
                )
        
        # ê° ìœ í˜•ë³„ í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        type_scores = {}
        for q_type, keywords in self.type_keywords.items():
            score = 0
            matched_keywords = []
            
            for keyword in keywords:
                if keyword in question_lower:
                    score += 1
                    matched_keywords.append(keyword)
            
            if score > 0:
                type_scores[q_type] = {
                    'score': score,
                    'matched_keywords': matched_keywords,
                    'confidence': min(score / len(keywords), 1.0)
                }
        
        if type_scores:
            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ìœ í˜• ì„ íƒ
            best_type = max(type_scores.keys(), key=lambda x: type_scores[x]['score'])
            best_score = type_scores[best_type]
            
            if best_score['confidence'] > 0.3:  # ìµœì†Œ ì„ê³„ê°’
                return ClassificationResult(
                    question_type=best_type,
                    confidence=best_score['confidence'],
                    reasoning=f"í‚¤ì›Œë“œ ë§¤ì¹­: {', '.join(best_score['matched_keywords'])}",
                    suggested_prompt_type=self.prompt_type_mapping[best_type]
                )
        
        return None
    
    def _llm_classify(self, question: str) -> ClassificationResult:
        """LLMì„ ì‚¬ìš©í•œ ì •ë°€ ë¶„ë¥˜"""
        
        # ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì§ˆë¬¸ ìœ í˜•ì„ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì§ˆë¬¸ ìœ í˜• ì¤‘ì—ì„œ ê°€ì¥ ì í•©í•œ ê²ƒì„ ì„ íƒí•´ì£¼ì„¸ìš”:

1. ì¼ìƒ: ì¼ë°˜ì ì¸ ëŒ€í™”ë‚˜ ìƒì‹ ì§ˆë¬¸
2. í†µê³„: ìˆ˜ì¹˜, ë°ì´í„°, í†µê³„ ê´€ë ¨ ì§ˆë¬¸  
3. ë¶„ì„: ì‹¬ì¸µ ë¶„ì„, ë¹„êµ, í‰ê°€ ìš”ì²­
4. ìš”ì•½: ë¬¸ì„œë‚˜ ë‚´ìš© ìš”ì•½ ìš”ì²­
5. ê²€ìƒ‰: íŠ¹ì • ì •ë³´ ê²€ìƒ‰ ìš”ì²­
6. ë¹„êµ: ì—¬ëŸ¬ í•­ëª© ë¹„êµ ìš”ì²­
7. ì„¤ëª…: ê°œë…ì´ë‚˜ ê³¼ì • ì„¤ëª… ìš”ì²­
8. ì¶”ì²œ: ì¶”ì²œì´ë‚˜ ì œì•ˆ ìš”ì²­

ì‘ë‹µì€ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì œê³µí•´ì£¼ì„¸ìš”:
{
    "question_type": "ì„ íƒëœ_ìœ í˜•",
    "confidence": 0.0-1.0,
    "reasoning": "ë¶„ë¥˜ ê·¼ê±°"
}"""

        user_prompt = f"ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ë¥˜í•´ì£¼ì„¸ìš”: {question}"
        
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,
                max_tokens=200
            )
            
            # JSON ì‘ë‹µ íŒŒì‹±
            content = response.choices[0].message.content.strip()
            logger.debug(f"ë¶„ë¥˜ê¸° LLM ì‘ë‹µ: {content}")
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                result_data = json.loads(content)
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
                result_data = self._parse_non_json_response(content)
            
            # QuestionType ì—´ê±°í˜•ìœ¼ë¡œ ë³€í™˜
            question_type_str = result_data.get("question_type", "ê²€ìƒ‰")
            question_type = self._str_to_question_type(question_type_str)
            
            return ClassificationResult(
                question_type=question_type,
                confidence=float(result_data.get("confidence", 0.7)),
                reasoning=result_data.get("reasoning", "LLM ë¶„ë¥˜ ê²°ê³¼"),
                suggested_prompt_type=self.prompt_type_mapping[question_type]
            )
            
        except Exception as e:
            logger.error(f"LLM ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}")
            raise
    
    def _parse_non_json_response(self, content: str) -> Dict[str, Any]:
        """JSONì´ ì•„ë‹Œ ì‘ë‹µì—ì„œ ì •ë³´ ì¶”ì¶œ"""
        import re
        
        # ì§ˆë¬¸ ìœ í˜• ì¶”ì¶œ
        type_match = re.search(r'(ì¼ìƒ|í†µê³„|ë¶„ì„|ìš”ì•½|ê²€ìƒ‰|ë¹„êµ|ì„¤ëª…|ì¶”ì²œ)', content)
        question_type = type_match.group(1) if type_match else "ê²€ìƒ‰"
        
        # ì‹ ë¢°ë„ ì¶”ì¶œ (0.0-1.0 ë²”ìœ„ì˜ ìˆ«ì)
        confidence_match = re.search(r'(\d+\.?\d*)', content)
        confidence = float(confidence_match.group(1)) if confidence_match else 0.7
        if confidence > 1.0:
            confidence = confidence / 100.0
        
        return {
            "question_type": question_type,
            "confidence": confidence,
            "reasoning": content
        }
    
    def _str_to_question_type(self, type_str: str) -> QuestionType:
        """ë¬¸ìì—´ì„ QuestionType ì—´ê±°í˜•ìœ¼ë¡œ ë³€í™˜"""
        mapping = {
            "ì¼ìƒ": QuestionType.EVERYDAY,
            "í†µê³„": QuestionType.STATISTICS,
            "ë¶„ì„": QuestionType.ANALYSIS,
            "ìš”ì•½": QuestionType.SUMMARY,
            "ê²€ìƒ‰": QuestionType.SEARCH,
            "ë¹„êµ": QuestionType.COMPARISON,
            "ì„¤ëª…": QuestionType.EXPLANATION,
            "ì¶”ì²œ": QuestionType.RECOMMENDATION
        }
        return mapping.get(type_str, QuestionType.SEARCH)
    
    def get_prompt_type_for_question(self, question: str) -> str:
        """ì§ˆë¬¸ì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ íƒ€ì… ë°˜í™˜ (ê°„í¸ ë©”ì„œë“œ)"""
        result = self.classify_question(question)
        return result.suggested_prompt_type
    
    def get_available_question_types(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì§ˆë¬¸ ìœ í˜• ëª©ë¡ ë°˜í™˜"""
        return [q_type.value for q_type in QuestionType]
    
    def get_type_keywords(self, question_type: QuestionType) -> List[str]:
        """íŠ¹ì • ì§ˆë¬¸ ìœ í˜•ì˜ í‚¤ì›Œë“œ ëª©ë¡ ë°˜í™˜"""
        return self.type_keywords.get(question_type, [])

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_classifier_instance = None

def get_question_classifier() -> QuestionClassifier:
    """ì „ì—­ ì§ˆë¬¸ ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _classifier_instance
    if _classifier_instance is None:
        _classifier_instance = QuestionClassifier()
        _classifier_instance.initialize()
    return _classifier_instance
