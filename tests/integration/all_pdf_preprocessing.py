# projectmission2/tests/integration/all_pdf_preprocessing.py

import os
import sys
from pathlib import Path
from tqdm import tqdm

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).resolve().parents[2]  
sys.path.insert(0, str(PROJECT_ROOT))

# âœ… config import
from config.data_preprocess_config import (
    RAW_DIR, PDF_PROCESSED_DIR,
    ALL_PDF_JSON_DIR, MAX_CHUNK_SIZE
)

SRC_DIR = PROJECT_ROOT / "src"
sys.path.insert(0, str(SRC_DIR))

# PDF íŒŒì´í”„ë¼ì¸ import
from src.data_processing.pdf.pdf_pipeline import process_single_pdf
from src.data_processing.pdf.pdf_extractor import extract_text_and_tables
from src.data_processing.pdf.pdf_chunker import create_structured_chunks
from src.data_processing.pdf.pdf_analyzer import analyze_chunks
from src.data_processing.pdf.json_merger import merge_pdf_jsons

def main():
    
    # RAW_DIR ë‚´ ëª¨ë“  PDF íŒŒì¼
    pdf_files = [f for f in os.listdir(RAW_DIR) if f.lower().endswith(".pdf")]    
    print(f"ì´ {len(pdf_files)}ê°œì˜ PDF íŒŒì¼ ë°œê²¬ âœ…")

    os.makedirs(ALL_PDF_JSON_DIR, exist_ok=True)

    for pdf_file in tqdm(pdf_files, desc="ì „ì²´ PDF ì²˜ë¦¬"):
        print(f"\nğŸš€ [ì‹œì‘] {pdf_file}")
        pdf_path = os.path.join(RAW_DIR, pdf_file)
        file_base_name = os.path.splitext(pdf_file)[0]

        process_single_pdf(
            file_name=pdf_file,
            raw_dir=str(RAW_DIR),
            all_pdf_json_dir=str(ALL_PDF_JSON_DIR),
            max_chunk_size=MAX_CHUNK_SIZE
        )
        print(f"âœ… [ì™„ë£Œ] {pdf_file} \n")

    merged_output_file = os.path.join(ALL_PDF_JSON_DIR, "merged_all_pdfs.json")
    
    # ì´ì „ ë³‘í•© JSON ì‚­ì œ
    if os.path.exists(merged_output_file):
        os.remove(merged_output_file)
        
    merge_pdf_jsons(ALL_PDF_JSON_DIR, merged_output_file)

if __name__ == "__main__":
    main()