{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a651ae-8534-4ee5-a3a4-5006df064791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set, Tuple\n",
    "def minmax_scale(scores: Dict[str, float], scale_min=0.0, scale_max=10.0) -> Dict[str, float]:\n",
    "    values = list(scores.values())\n",
    "    min_val, max_val = min(values), max(values)\n",
    "    if min_val == max_val:\n",
    "        return {k: scale_min for k in scores}  # ëª¨ë“  ì ìˆ˜ê°€ ê°™ìœ¼ë©´ ìµœì†Œê°’ìœ¼ë¡œ ê³ ì •\n",
    "\n",
    "    return {\n",
    "        k: scale_min + (v - min_val) / (max_val - min_val) * (scale_max - scale_min)\n",
    "        for k, v in scores.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a1f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import hashlib\n",
    "import pickle\n",
    "from typing import List, Dict\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "class RerankModel:\n",
    "    def __init__(self, model_name: str, cache_dir: str, device: str = \"cuda\"):\n",
    "        \"\"\"ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•˜ì—¬ ì´ˆê¸°í™”\"\"\"\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.device = device\n",
    "        self.cache_dir = cache_dir\n",
    "        os.makedirs(self.cache_dir, exist_ok=True)\n",
    "\n",
    "    def _get_cache_path(self, text: str) -> str:\n",
    "        \"\"\"í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìºì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±\"\"\"\n",
    "        key = hashlib.md5(text.encode()).hexdigest()\n",
    "        return os.path.join(self.cache_dir, f\"{key}.pkl\")\n",
    "\n",
    "    def _load_embedding_from_cache(self, text: str) -> torch.Tensor:\n",
    "        \"\"\"ìºì‹œì—ì„œ ì„ë² ë”© ë¡œë“œ\"\"\"\n",
    "        path = self._get_cache_path(text)\n",
    "        if os.path.exists(path):\n",
    "            with open(path, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        return None\n",
    "\n",
    "    def _save_embedding_to_cache(self, text: str, embedding: torch.Tensor):\n",
    "        \"\"\"ì„ë² ë”©ì„ ìºì‹œì— ì €ì¥\"\"\"\n",
    "        path = self._get_cache_path(text)\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(embedding.cpu(), f)\n",
    "\n",
    "    def _embed(self, text: str) -> torch.Tensor:\n",
    "        \"\"\"í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ë²¡í„°ë¡œ ë³€í™˜\"\"\"\n",
    "        inputs = self.tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            hidden = self.model(**inputs).last_hidden_state\n",
    "            mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "            pooled = (hidden * mask).sum(dim=1) / mask.sum(dim=1)\n",
    "        return pooled[0]\n",
    "\n",
    "    def _get_embedding(self, text: str, is_query: bool = False) -> torch.Tensor:\n",
    "        \"\"\"ì„ë² ë”© ë°˜í™˜ (ë¬¸ì„œëŠ” ìºì‹±, ì¿¼ë¦¬ëŠ” ê³„ì‚°)\"\"\"\n",
    "        if is_query:\n",
    "            return self._embed(text)\n",
    "\n",
    "        cached = self._load_embedding_from_cache(text)\n",
    "        if cached is not None:\n",
    "            return cached.to(self.device)\n",
    "\n",
    "        emb = self._embed(text)\n",
    "        self._save_embedding_to_cache(text, emb)\n",
    "        return emb\n",
    "\n",
    "    def rerank(self, query: str, documents: List[str]) -> Dict[str, float]:\n",
    "        \"\"\"ì¿¼ë¦¬ì™€ ë¬¸ì„œë“¤ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•´ ì ìˆ˜ ë°˜í™˜\"\"\"\n",
    "        query_embedding = self._get_embedding(query, is_query=True).unsqueeze(0)\n",
    "        doc_embeddings = [self._get_embedding(doc).unsqueeze(0) for doc in documents]\n",
    "        doc_tensor = torch.cat(doc_embeddings, dim=0)\n",
    "\n",
    "        cos_scores = torch.nn.functional.cosine_similarity(query_embedding, doc_tensor)\n",
    "        return {doc: score.item() for doc, score in zip(documents, cos_scores)}\n",
    "\n",
    "    def cache_embeddings(self, texts: List[str], max_length: int = 512):\n",
    "        \"\"\"ì „ì²´ ë¬¸ì„œì— ëŒ€í•´ ì˜ë¯¸ ì„ë² ë”© ìºì‹±\"\"\"\n",
    "        skipped, cached = 0, 0\n",
    "        for text in texts:\n",
    "            text = text[:max_length]\n",
    "            path = self._get_cache_path(text)\n",
    "            if os.path.exists(path):\n",
    "                skipped += 1\n",
    "                continue\n",
    "            emb = self._embed(text)\n",
    "            self._save_embedding_to_cache(text, emb)\n",
    "            cached += 1\n",
    "        print(f\"âœ… ì˜ë¯¸ ì„ë² ë”© ìºì‹± ì™„ë£Œ | ìƒˆë¡œ ìºì‹±: {cached}ê°œ | ìŠ¤í‚µ: {skipped}ê°œ\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a56105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TokenizerWrapper:\n",
    "    def __init__(self, engine=\"kiwi\"):\n",
    "        if engine == \"kiwi\":\n",
    "            from kiwipiepy import Kiwi\n",
    "            self.tokenizer = Kiwi()\n",
    "            self.mode = \"kiwi\"\n",
    "        elif engine == \"okt\":\n",
    "            from konlpy.tag import Okt\n",
    "            self.tokenizer = Okt()\n",
    "            self.mode = \"okt\"\n",
    "        else:\n",
    "            raise ValueError(f\"ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¶„ì„ê¸°: {engine}\")\n",
    "\n",
    "    def tokenize_korean(self, text: str, use_bigrams: bool = True) -> List[str]:\n",
    "        # âœ… ëª…ì‚¬ë§Œ ì¶”ì¶œ\n",
    "        if self.mode == \"kiwi\":\n",
    "            tokens = [token.form for token in self.tokenizer.tokenize(text) if token.tag.startswith(\"NN\")]\n",
    "        elif self.mode == \"okt\":\n",
    "            tokens = self.tokenizer.nouns(text)\n",
    "\n",
    "        # âœ… ë¶ˆìš©ì–´ ì œê±°\n",
    "        stopwords = {\"ì—ì„œ\", \"ëŠ”\", \"ì€\", \"ì´\", \"ê°€\", \"í•˜\", \"ì–´ì•¼\", \"ì—\", \"ì„\", \"ë¥¼\", \"ë„\", \"ë¡œ\", \"ê³¼\", \"ì™€\", \"ì˜\", \"?\", \"ë‹¤\"}\n",
    "        tokens = [t for t in tokens if t not in stopwords]\n",
    "\n",
    "        # âœ… ë°”ì´ê·¸ë¨ ì¶”ê°€\n",
    "        if use_bigrams:\n",
    "            bigrams = [tokens[i] + tokens[i+1] for i in range(len(tokens) - 1)]\n",
    "            tokens += bigrams\n",
    "\n",
    "        return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8445f74-137a-40f0-a936-eb80f8bfc5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "from typing import List, Dict, Set, Tuple\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from rank_bm25 import BM25Okapi \n",
    "from more_itertools import chunked\n",
    "\n",
    "import aiofiles\n",
    "\n",
    "# ë¡œì»¬ ì„í¬íŠ¸\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "class RetrieverError(Exception):\n",
    "    \"\"\"Retrieverì—ì„œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸ë¥¼ ìœ„í•œ ê¸°ë³¸ í´ë˜ìŠ¤\"\"\"\n",
    "    pass\n",
    "\n",
    "class ChunkLoadingError(RetrieverError):\n",
    "    \"\"\"JSON ì²­í¬ ë¡œë”© ì‹¤íŒ¨ ì‹œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class Retriever:\n",
    "    def __init__(self,\n",
    "                 meta_df=None,\n",
    "                 embedder=None,\n",
    "                 reranker: RerankModel =None,\n",
    "                 tokenizer=None,\n",
    "                 persist_directory=None,\n",
    "                 rerank_max_length=512,\n",
    "                 bm25_weight=0.5,\n",
    "                 rerank_weight=0.5,\n",
    "                 bm25_path=\"bm25_index.pkl\",\n",
    "                 debug_mode=False\n",
    "                 ):\n",
    "        self.meta_df = meta_df\n",
    "        self.embedder = embedder\n",
    "        self.reranker = reranker\n",
    "        self.tokenizer = tokenizer or TokenizerWrapper(\"kiwi\")\n",
    "        self.persist_directory = persist_directory\n",
    "        self.rerank_max_length = rerank_max_length\n",
    "\n",
    "        self.bm25_weight = bm25_weight\n",
    "        self.rerank_weight = rerank_weight\n",
    "\n",
    "        self.db = None\n",
    "        self.bm25 = None\n",
    "        self.bm25_ready = False\n",
    "        self.bm25_path = bm25_path\n",
    "        self.documents = []\n",
    "        self.debug_mode = debug_mode\n",
    "\n",
    "        self.last_scores = {}\n",
    "\n",
    "    def set_weights(self, bm25_weight: float, rerank_weight: float):\n",
    "        self.bm25_weight = bm25_weight\n",
    "        self.rerank_weight = rerank_weight\n",
    "        logging.info(f\"ğŸ”§ ê°€ì¤‘ì¹˜ ì„¤ì •ë¨ | BM25: {bm25_weight} | Rerank: {rerank_weight}\")\n",
    "\n",
    "    def get_doc_key(self, doc: Document) -> str:\n",
    "        chunk_id = doc.metadata.get(\"chunk_id\")\n",
    "        if chunk_id:\n",
    "            return chunk_id\n",
    "        return str(hash(doc.page_content.strip()))\n",
    "\n",
    "    def save_bm25_index(self):\n",
    "        os.makedirs(os.path.dirname(self.bm25_path), exist_ok=True)\n",
    "        with open(self.bm25_path, \"wb\") as f:\n",
    "            pickle.dump(self.bm25, f)\n",
    "        logging.info(f\"âœ… BM25 ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {self.bm25_path}\")\n",
    "\n",
    "    def load_bm25_index(self):\n",
    "        path = self.bm25_path\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                with open(path, \"rb\") as f:\n",
    "                    self.bm25 = pickle.load(f)\n",
    "                self.bm25_ready = True\n",
    "                logging.info(f\"âœ… BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {path}\")\n",
    "            except Exception as e:\n",
    "                self.bm25_ready = False\n",
    "                logging.warning(f\"âŒ BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        else:\n",
    "            self.bm25_ready = False\n",
    "            logging.warning(f\"âŒ BM25 ì¸ë±ìŠ¤ íŒŒì¼ ì—†ìŒ: {path}\")\n",
    "\n",
    "    def deduplicate_documents(self, documents: List[Document]) -> List[Document]:\n",
    "        seen = set()\n",
    "        unique_docs = []\n",
    "        for doc in documents:\n",
    "            chunk_id = doc.metadata.get(\"chunk_id\")\n",
    "            if chunk_id and chunk_id not in seen:\n",
    "                seen.add(chunk_id)\n",
    "                unique_docs.append(doc)\n",
    "        removed = len(documents) - len(unique_docs)\n",
    "        logging.info(f\"ğŸ§¹ ì¤‘ë³µ ì œê±°: {removed}ê°œ ì œê±°ë¨\")\n",
    "        return unique_docs\n",
    "\n",
    "    \n",
    "    async def load_or_cache_json_docs(self, folder_path: str, cache_path: str) -> List[Document]:\n",
    "        # ìºì‹œ ë””ë ‰í† ë¦¬ ìë™ ìƒì„±\n",
    "        os.makedirs(os.path.dirname(cache_path), exist_ok=True)\n",
    "    \n",
    "        if os.path.exists(cache_path):\n",
    "            with open(cache_path, \"rb\") as f:\n",
    "                logging.info(\"ğŸ“¦ ìºì‹œëœ JSON ë¬¸ì„œ ë¡œë“œ ì¤‘...\")\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            logging.info(\"ğŸ“‚ JSON í´ë”ì—ì„œ ë¬¸ì„œ ë¡œë”© ì¤‘...\")\n",
    "            docs = await self.async_load_chunks_from_folder(folder_path)\n",
    "            with open(cache_path, \"wb\") as f:\n",
    "                pickle.dump(docs, f)\n",
    "            logging.info(\"âœ… JSON ìºì‹œ ì €ì¥ ì™„ë£Œ\")\n",
    "            return docs\n",
    "\n",
    "    async def async_load_chunks_from_folder(self, folder_path: str) -> List[Document]:\n",
    "        if not os.path.isdir(folder_path):\n",
    "            raise ChunkLoadingError(f\"âŒ í´ë” ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {folder_path}\")\n",
    "\n",
    "        file_list = sorted([f for f in os.listdir(folder_path) if f.endswith(\".json\")])\n",
    "        existing_sources = self.get_existing_chunk_ids()\n",
    "        logging.info(f\"ğŸ“ ê¸°ì¡´ DBì— ì €ì¥ëœ source ìˆ˜: {len(existing_sources)}\")\n",
    "\n",
    "        tasks = []\n",
    "        for filename in file_list:\n",
    "            if filename in existing_sources:\n",
    "                logging.info(f\"â© ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ ê±´ë„ˆëœ€: {filename}\")\n",
    "                continue\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            tasks.append(self._load_single_file(file_path, filename))\n",
    "\n",
    "        # âœ… ê³ ê¸‰ tqdm ì ìš©: ì‹¤ì œ ì™„ë£Œ ê¸°ì¤€ìœ¼ë¡œ ì§„í–‰ë¥  í‘œì‹œ\n",
    "        all_chunks = []\n",
    "        for coro in tqdm_asyncio.as_completed(tasks, desc=\"ğŸ“‚ íŒŒì¼ ì²˜ë¦¬ ì¤‘\", total=len(tasks)):\n",
    "            result = await coro\n",
    "            all_chunks.append(result)\n",
    "\n",
    "        documents = [doc for sublist in all_chunks for doc in sublist]\n",
    "        logging.info(f\"âœ… ìƒˆë¡œ ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(documents)}\")\n",
    "\n",
    "        documents = self.deduplicate_documents(documents)\n",
    "        logging.info(f\"ğŸ§¹ ì¤‘ë³µ ì œê±° í›„ ë¬¸ì„œ ìˆ˜: {len(documents)}\")\n",
    "        return documents\n",
    "\n",
    "    \n",
    "    async def _load_single_file(self, file_path: str, filename: str) -> list[Document]:\n",
    "        try:\n",
    "            async with aiofiles.open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = await f.read()\n",
    "                data = json.loads(content)\n",
    "    \n",
    "            metadata_base = data.get(\"csv_metadata\", {})\n",
    "            docs = []\n",
    "    \n",
    "            for idx, page in enumerate(data.get(\"pdf_data\", [])):\n",
    "                page_num = page.get(\"page\", idx)\n",
    "                text = page.get(\"text\", \"\").strip()\n",
    "    \n",
    "                if text:\n",
    "                    metadata = metadata_base.copy()\n",
    "                    metadata[\"chunk_id\"] = f\"{filename}::page::{page_num}::type::text\"\n",
    "                    metadata[\"page\"] = page_num\n",
    "    \n",
    "                    docs.append(Document(page_content=text, metadata=metadata))\n",
    "    \n",
    "            return docs\n",
    "    \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"âš ï¸ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {filename} | ì˜¤ë¥˜: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_all_documents_from_db(self) -> List[Document]:\n",
    "        if self.db is None:\n",
    "            raise ValueError(\"Vector DBê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        all_docs = []\n",
    "        collection = self.db._collection\n",
    "        count = collection.count()\n",
    "        offset = 0\n",
    "        limit = 1000\n",
    "\n",
    "        while offset < count:\n",
    "            results = collection.get(\n",
    "                limit=limit,\n",
    "                offset=offset,\n",
    "                include=[\"metadatas\", \"documents\"]\n",
    "            )\n",
    "            for doc, meta in zip(results[\"documents\"], results[\"metadatas\"]):\n",
    "                if not meta.get(\"chunk_id\"):\n",
    "                    logging.warning(\"âš ï¸ chunk_id ëˆ„ë½ëœ ë¬¸ì„œ ë°œê²¬\")\n",
    "                all_docs.append(Document(page_content=doc, metadata=meta))\n",
    "            offset += limit\n",
    "\n",
    "        return all_docs\n",
    "\n",
    "\n",
    "    def load_or_build_vector_db(self, documents: List[Document], force_rebuild: bool = False):\n",
    "        \"\"\"Vector DBì™€ BM25 ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤.\"\"\"\n",
    "        \n",
    "        # 1ë‹¨ê³„: Vector DB ì´ˆê¸°í™” (ë¡œë“œ ë˜ëŠ” ìƒì„±)\n",
    "        self._initialize_vector_db(documents, force_rebuild)\n",
    "        \n",
    "        # 2ë‹¨ê³„: ìƒˆ ë¬¸ì„œê°€ ìˆë‹¤ë©´ DBì— ì¶”ê°€\n",
    "        new_docs = self._update_db_with_new_docs(documents)\n",
    "        \n",
    "        # 3ë‹¨ê³„: BM25 ì¸ë±ìŠ¤ ë™ê¸°í™” (ìƒˆ ë¬¸ì„œ ì¶”ê°€ ì—¬ë¶€ì— ë”°ë¼ ì²˜ë¦¬)\n",
    "        self.documents = self.get_all_documents_from_db()\n",
    "        self._synchronize_bm25_index(was_db_updated=(len(new_docs) > 0))\n",
    "        \n",
    "        # 4ë‹¨ê³„: ë¦¬ë­ì»¤ ì„ë² ë”© ìºì‹±\n",
    "        self._cache_reranker_embeddings()\n",
    "        logging.info(\"ğŸš€ ëª¨ë“  DB ë° ì¸ë±ìŠ¤ ì¤€ë¹„ ì™„ë£Œ.\")\n",
    "    \n",
    "\n",
    "    def _initialize_vector_db(self, documents: List[Document], force_rebuild: bool):\n",
    "        \"\"\"Vector DBë¥¼ ìƒì„±í•˜ê±°ë‚˜ ë¡œë“œí•©ë‹ˆë‹¤.\"\"\"\n",
    "        if force_rebuild or not self._db_exists():\n",
    "            logging.info(\"ğŸ†• ë²¡í„° DB ìƒì„± ì¤‘...\")\n",
    "            wrapped_docs = list(tqdm(documents, desc=\"ğŸ”„ ë¬¸ì„œ ì„ë² ë”© ì¤‘\"))\n",
    "            self.db = Chroma.from_documents(wrapped_docs, self.embedder, persist_directory=self.persist_directory)\n",
    "            logging.info(\"âœ… ìƒˆ DB êµ¬ì¶• ì™„ë£Œ.\")\n",
    "        else:\n",
    "            logging.info(\"âœ… ê¸°ì¡´ ë²¡í„° DB ë¡œë“œ ì¤‘...\")\n",
    "            self.load_vector_db()\n",
    "    \n",
    "    def _update_db_with_new_docs(self, documents: List[Document]) -> List[Document]:\n",
    "        \"\"\"ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ í•„í„°ë§í•˜ì—¬ DBì— ì¶”ê°€í•©ë‹ˆë‹¤.\"\"\"\n",
    "        new_docs = self._filter_new_documents(documents)\n",
    "        if not new_docs:\n",
    "            logging.info(\"â© ìƒˆ ë¬¸ì„œ ì—†ìŒ, DB ì¶”ê°€ ìƒëµ\")\n",
    "            return []\n",
    "    \n",
    "        logging.info(f\"â• ìƒˆ ë¬¸ì„œ {len(new_docs)}ê°œ ì¶”ê°€ ì¤‘...\")\n",
    "        batch_size = 100\n",
    "        total_batches = (len(new_docs) + batch_size - 1) // batch_size\n",
    "        \n",
    "        for batch in tqdm(chunked(new_docs, batch_size), desc=\"ğŸ“¦ ë°°ì¹˜ ì¶”ê°€ ì¤‘\", total=total_batches):\n",
    "            self.db.add_documents(batch)\n",
    "            \n",
    "        return new_docs\n",
    "    \n",
    "    def _synchronize_bm25_index(self, was_db_updated: bool):\n",
    "        \"\"\"DB ìƒíƒœì— ë”°ë¼ BM25 ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ë¡œë“œí•©ë‹ˆë‹¤.\"\"\"\n",
    "        # ìƒˆ ë¬¸ì„œê°€ ì¶”ê°€ëë‹¤ë©´ BM25 ì¸ë±ìŠ¤ëŠ” ë¬´ì¡°ê±´ ìƒˆë¡œ ë§Œë“¤ì–´ì•¼ í•¨\n",
    "        if was_db_updated:\n",
    "            logging.info(\"ğŸ”§ ìƒˆ ë¬¸ì„œ ì¶”ê°€ë¨, BM25 ì¸ë±ìŠ¤ ì¬ìƒì„±...\")\n",
    "            self.build_bm25_index()\n",
    "            self.save_bm25_index()\n",
    "            logging.info(\"âœ… BM25 ì¸ë±ì‹± ì™„ë£Œ.\")\n",
    "            return\n",
    "    \n",
    "        # ìƒˆ ë¬¸ì„œê°€ ì—†ë‹¤ë©´, ê¸°ì¡´ ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•´ë³´ê³  ì—†ìœ¼ë©´ ìƒì„±\n",
    "        if not hasattr(self, \"bm25_ready\") or not self.bm25_ready:\n",
    "            self.load_bm25_index()\n",
    "            if not self.bm25_ready:\n",
    "                logging.info(\"ğŸ“š ê¸°ì¡´ BM25 ì¸ë±ìŠ¤ ì—†ìŒ, ìƒˆë¡œ êµ¬ì¶• ì‹œì‘...\")\n",
    "                self.build_bm25_index()\n",
    "                self.save_bm25_index()\n",
    "                logging.info(\"âœ… BM25 ì¸ë±ì‹± ì™„ë£Œ.\")\n",
    "    \n",
    "    def _cache_reranker_embeddings(self):\n",
    "        \"\"\"ë¦¬ë­ì»¤ ëª¨ë¸ì„ ìœ„í•œ ì„ë² ë”©ì„ ìºì‹±í•©ë‹ˆë‹¤.\"\"\"\n",
    "        if not self.documents:\n",
    "            logging.warning(\"âš ï¸ ìºì‹±í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "            \n",
    "        logging.info(\"ğŸ’¡ ë¦¬ë­ì»¤ ì„ë² ë”© ìºì‹± ì¤‘...\")\n",
    "        texts = [doc.page_content[:self.rerank_max_length] for doc in self.documents]\n",
    "        self.reranker.cache_embeddings(texts, max_length=self.rerank_max_length)\n",
    "        logging.info(\"âœ… ë¦¬ë­ì»¤ ìºì‹± ì™„ë£Œ.\")\n",
    "\n",
    "    def load_vector_db(self):\n",
    "        if not self.persist_directory or not os.path.exists(self.persist_directory):\n",
    "            raise ValueError(\"ì €ì¥ëœ DBê°€ ì—†ê±°ë‚˜ persist_directoryê°€ ì˜ëª» ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        self.db = Chroma(persist_directory=self.persist_directory, embedding_function=self.embedder)\n",
    "\n",
    "    def _db_exists(self) -> bool:\n",
    "        if not self.persist_directory:\n",
    "            return False\n",
    "        required_files = [\"chroma.sqlite3\"]\n",
    "        return all(os.path.exists(os.path.join(self.persist_directory, f)) for f in required_files)\n",
    "\n",
    "    def get_existing_chunk_ids(self) -> Set[str]:\n",
    "        if self.db is None:\n",
    "            try:\n",
    "                self.load_vector_db()\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"âš ï¸ DB ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "                self.db = None\n",
    "                return set()\n",
    "\n",
    "        try:\n",
    "            result = self.db.get(include=[\"metadatas\"])\n",
    "            chunk_ids = set()\n",
    "            for i, meta in enumerate(result.get(\"metadatas\", [])):\n",
    "                cid = meta.get(\"chunk_id\")\n",
    "                if not cid:\n",
    "                    logging.warning(f\"âš ï¸ chunk_id ëˆ„ë½ëœ ë¬¸ì„œ ë°œê²¬ (index={i})\")\n",
    "                    continue\n",
    "                chunk_ids.add(cid)\n",
    "            return chunk_ids\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"âš ï¸ chunk_id ëª©ë¡ ì¶”ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "            return set()\n",
    "\n",
    "\n",
    "    def _filter_new_documents(self, documents: List[Document]) -> List[Document]:\n",
    "        existing_chunk_ids  = self.get_existing_chunk_ids()\n",
    "        new_docs = []\n",
    "        for doc in documents:\n",
    "            chunk_id  = doc.metadata.get(\"chunk_id\")\n",
    "            if chunk_id  and chunk_id  not in existing_chunk_ids :\n",
    "                new_docs.append(doc)\n",
    "        return new_docs\n",
    "\n",
    "    # âœ… BM25 ê´€ë ¨ í•¨ìˆ˜ ì¶”ê°€\n",
    "    def build_bm25_index(self):\n",
    "        if self.bm25 is not None:\n",
    "            logging.info(\"â© BM25 ì¸ë±ìŠ¤ ì´ë¯¸ ì¡´ì¬í•¨, ì¬ìƒì„± ìƒëµ\")\n",
    "            return\n",
    "        if not self.documents:\n",
    "            raise ValueError(\"BM25 ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        tokenized_corpus = [self.tokenizer.tokenize_korean(doc.page_content) \n",
    "                            for doc in tqdm(self.documents, desc=\"ğŸ§  ë¬¸ì„œ í† í°í™” ì¤‘\")]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        self.bm25_ready = True\n",
    "        logging.info(\"âœ… BM25 ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "    def _debug_print_bm25_scores(self, top_docs: List[Tuple[float, Document]]):\n",
    "        \"\"\"BM25 ì ìˆ˜ ë””ë²„ê·¸ ì¶œë ¥ ì „ìš© í•¨ìˆ˜\"\"\"\n",
    "        print(\"\\nğŸ“ˆ BM25 ìƒìœ„ ë¬¸ì„œ ë° ì ìˆ˜:\")\n",
    "        for i, (score, doc) in enumerate(top_docs):\n",
    "            print(f\"BM25 ë¬¸ì„œ {i+1} | ì ìˆ˜: {score:.4f} | ì¶œì²˜: {doc.metadata.get('íŒŒì¼ëª…')}\")\n",
    "            print(doc.page_content[:300])\n",
    "            print(\"-\" * 40)\n",
    "        \n",
    "    def bm25_search(self, query: str, k: int = 5, filter: Dict = None, debug: bool = False) -> List[Tuple[float, Document]]:\n",
    "        if not self.bm25_ready:\n",
    "            raise ValueError(\"BM25 ì¸ë±ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "        tokenized_query = self.tokenizer.tokenize_korean(query)\n",
    "        doc_scores = self.bm25.get_scores(tokenized_query)\n",
    "           \n",
    "        # âœ… í•„í„°ë§ ì ìš©\n",
    "        filtered_docs = []\n",
    "        for score, doc in zip(doc_scores, self.documents):\n",
    "            if filter:\n",
    "                match = all(doc.metadata.get(k) == v for k, v in filter.items())\n",
    "                if not match:\n",
    "                    continue\n",
    "            filtered_docs.append((score, doc))\n",
    "\n",
    "        top_docs = sorted(filtered_docs, key=lambda x: x[0], reverse=True)[:k]\n",
    "\n",
    "        if self.debug_mode:\n",
    "            self._debug_print_bm25_scores(top_docs)\n",
    "            \n",
    "        return top_docs\n",
    "\n",
    "    def rerank_documents(self, query: str, documents: List[Document]) -> Dict[str, float]:\n",
    "        \"\"\"ì¿¼ë¦¬ì™€ ë¬¸ì„œë“¤ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ì—¬ ì¬ìˆœìœ„í™” ì ìˆ˜ ë°˜í™˜\"\"\"\n",
    "        if not self.reranker:\n",
    "            logging.warning(\"âš ï¸ ì¬ìˆœìœ„í™” ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ìˆ˜ê°€ 0ìœ¼ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤.\")\n",
    "            return {self.get_doc_key(doc): 0.0 for doc in documents}\n",
    "        \n",
    "        texts_to_rerank = [doc.page_content[:self.rerank_max_length] for doc in documents]\n",
    "        base_scores = self.reranker.rerank(query, texts_to_rerank)\n",
    "    \n",
    "        query_tokens = self.tokenizer.tokenize_korean(query)\n",
    "        bonus_weight = 1.0\n",
    "    \n",
    "        final_scores = {}\n",
    "        for doc, base_score in zip(documents, base_scores.values()):\n",
    "            bonus = 0\n",
    "            if query in doc.page_content:\n",
    "                bonus += 2.0\n",
    "            bonus += sum(1 for token in query_tokens if token in doc.page_content) * bonus_weight\n",
    "    \n",
    "            key = self.get_doc_key(doc)\n",
    "            final_scores[key] = base_score + bonus\n",
    "    \n",
    "        logging.info(\"ğŸ§  ì¬ìˆœìœ„í™” ì ìˆ˜ ê³„ì‚° ì™„ë£Œ (ë³´ë„ˆìŠ¤ í¬í•¨)\")\n",
    "        return final_scores\n",
    "    \n",
    "    def _calculate_combined_scores(self, documents: List[Document], query: str, \n",
    "                                 bm25_scores: Dict[str, float], rerank_scores: Dict[str, float]) -> List[Tuple[float, Document]]:\n",
    "        \"\"\"ë¬¸ì„œë“¤ì— ëŒ€í•œ BM25 + ì¬ìˆœìœ„í™” ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜\"\"\"\n",
    "        final_scored = []\n",
    "        self.last_scores= {}\n",
    "\n",
    "        # 1. ì ìˆ˜ ì •ê·œí™”\n",
    "        scaled_bm25 = minmax_scale(bm25_scores)\n",
    "        scaled_rerank = minmax_scale(rerank_scores)\n",
    "\n",
    "        for doc in documents:\n",
    "            key = self.get_doc_key(doc)\n",
    "            bm25 = scaled_bm25.get(key, 0.0)\n",
    "            rerank = scaled_rerank.get(key, 0.0)\n",
    "            combined = self.bm25_weight * bm25 + self.rerank_weight * rerank\n",
    "            \n",
    "            self.last_scores[key] = {\n",
    "                \"bm25\": bm25,\n",
    "                \"rerank\": rerank,\n",
    "                \"combined\": combined\n",
    "            }\n",
    "            final_scored.append((combined, doc))\n",
    "    \n",
    "        return final_scored\n",
    "\n",
    "    def _debug_print_scores(self, documents: List[Document], search_type: str):\n",
    "        \"\"\"ë””ë²„ê·¸ ëª¨ë“œì¼ ë•Œ ì ìˆ˜ ì •ë³´ ì¶œë ¥\"\"\"\n",
    "        if not self.debug_mode:\n",
    "            return\n",
    "            \n",
    "        logging.info(f\"{search_type} ì ìˆ˜ ì •ë³´\")\n",
    "        for doc in documents:\n",
    "            key = self.get_doc_key(doc)\n",
    "            scores = self.last_scores.get(key, {})\n",
    "            bm25 = scores.get(\"bm25\", 0.0)\n",
    "            rerank = scores.get(\"rerank\", 0.0)\n",
    "            combined = scores.get(\"combined\", 0.0)\n",
    "\n",
    "            source = doc.metadata.get(\"íŒŒì¼ëª…\", \"â“\")\n",
    "            chunk_index = doc.metadata.get(\"chunk_id\", \"â“\")\n",
    "            print(f\"ğŸ” {source} | Chunk {chunk_index} | BM25: {bm25:.2f} | Rerank: {rerank:.2f} | Combined: {combined:.2f}\")\n",
    "\n",
    "        \n",
    "    def _merge_search_results(self, vector_results: List[Document], bm25_results: List[Tuple[float, Document]]) -> Tuple[List[Document], Dict[str, float]]:\n",
    "        \"\"\"ë²¡í„°ì™€ BM25 ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³‘í•©í•˜ê³  ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜\"\"\"\n",
    "        merged = {}\n",
    "        bm25_scores = {}\n",
    "        \n",
    "        # BM25 ê²°ê³¼ ìš°ì„  ì¶”ê°€\n",
    "        for score, doc in bm25_results:\n",
    "            key = self.get_doc_key(doc)\n",
    "            merged[key] = doc\n",
    "            bm25_scores[key] = score\n",
    "        \n",
    "        # ë²¡í„° ê²°ê³¼ì—ì„œ ìƒˆë¡œìš´ ë¬¸ì„œë§Œ ì¶”ê°€\n",
    "        for doc in vector_results:\n",
    "            key = self.get_doc_key(doc)\n",
    "            if key not in merged:\n",
    "                merged[key] = doc\n",
    "                bm25_scores[key] = 0.0\n",
    "        \n",
    "        return list(merged.values()), bm25_scores\n",
    "    \n",
    "    def hybrid_search(self, query: str, top_k: int = 3, candidate_size: int = 10,\n",
    "                      filter_dict: Dict = None, candidate_filenames: List[str] = None) -> List[Document]:\n",
    "        \"\"\"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: ë²¡í„° + BM25 + ì¬ìˆœìœ„í™” + í•„í„°ë§\"\"\"\n",
    "        if self.db is None:\n",
    "            raise ValueError(\"Vector DBê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        if not self.bm25_ready:\n",
    "            raise ValueError(\"BM25 ì¸ë±ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "        if filter_dict:\n",
    "            logging.info(f\"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ í•„í„° ì ìš©: {filter_dict}\")\n",
    "    \n",
    "        # 1. ë‹¨ìˆœ í•„í„° (=)ë§Œ ì¶”ì¶œ\n",
    "        simple_filter = {\n",
    "            key: val[\"value\"]\n",
    "            for key, val in filter_dict.items()\n",
    "            if val.get(\"operator\") == \"=\" and key != \"ì‚¬ì—… ìš”ì•½\"\n",
    "        } or None\n",
    "    \n",
    "        # 2. ë²¡í„° + BM25 ê²€ìƒ‰\n",
    "        vector_results = self.db.similarity_search(query, k=candidate_size, filter=simple_filter)\n",
    "        bm25_results = self.bm25_search(query, k=candidate_size, filter=simple_filter)\n",
    "        \n",
    "        # 3. íŒŒì¼ëª… ê¸°ë°˜ í›„ë³´ ì œí•œ (metadata ì¿¼ë¦¬ì¼ ë•Œë§Œ ì ìš©ë¨)\n",
    "        if candidate_filenames:\n",
    "            vector_results = [doc for doc in vector_results if doc.metadata.get(\"íŒŒì¼ëª…\") in candidate_filenames]\n",
    "            bm25_results = [(score, doc) for score, doc in bm25_results if doc.metadata.get(\"íŒŒì¼ëª…\") in candidate_filenames]\n",
    "            logging.info(f\"ğŸ“ íŒŒì¼ëª… ê¸°ë°˜ í›„ë³´ ì œí•œ ì ìš©ë¨: {len(candidate_filenames)}ê°œ\")\n",
    "\n",
    "        # 4. ê²°ê³¼ ë³‘í•©\n",
    "        merged_docs, bm25_scores = self._merge_search_results(vector_results, bm25_results)\n",
    "    \n",
    "        # 5. ê³ ê¸‰ ì¡°ê±´ í•„í„°ë§ (>, < ë“±)\n",
    "        filtered_docs = [doc for doc in merged_docs if check_filter_match(doc.metadata, filter_dict)]\n",
    "        logging.info(f\"âœ… ê³ ê¸‰ í•„í„°ë§ í›„ ë¬¸ì„œ ìˆ˜: {len(filtered_docs)}\")\n",
    "    \n",
    "        final_docs_to_score = filtered_docs if filtered_docs else merged_docs\n",
    "        if not filtered_docs:\n",
    "            logging.warning(f\"âš ï¸ í•„í„°ë§ ê²°ê³¼ ì—†ìŒ â†’ ì›ë³¸ ê²°ê³¼ì—ì„œ ìƒìœ„ {top_k}ê°œ ë°˜í™˜\")\n",
    "    \n",
    "        # 6. ì¬ìˆœìœ„í™”\n",
    "        rerank_scores = self.rerank_documents(query, final_docs_to_score)\n",
    "    \n",
    "        # 7. ìµœì¢… ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬\n",
    "        scored_docs = self._calculate_combined_scores(final_docs_to_score, query, bm25_scores, rerank_scores)\n",
    "        final_results = sorted(scored_docs, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "        if self.debug_mode:\n",
    "            self._debug_print_scores([doc for _, doc in final_results], \"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\")\n",
    "    \n",
    "        logging.info(f\"ğŸ“Š í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)} â†’ {top_k}ê°œ ë°˜í™˜\")\n",
    "        return [doc for _, doc in final_results[:top_k]]\n",
    "\n",
    "\n",
    "    def detect_query_type(self, query: str, filters: Dict[str, Dict]) -> str:\n",
    "        normalized_query = query.replace(\" \", \"\").lower()\n",
    "        \n",
    "        explicit_summary_keywords = normalize_keywords([\n",
    "            \"ì‚¬ì—…ìš”ì•½\", \"ê³µê³ ìš”ì•½\", \"ì‚¬ì—…ê°œìš”\", \"ê³µê³ ê°œìš”\"\n",
    "        ])\n",
    "        \n",
    "        metadata_keywords = normalize_keywords([\n",
    "            \"ì‚¬ì—…ê¸ˆì•¡\",  \"ì…ì°°ì¼\", \"ì…ì°°ì‹œì‘ì¼\", \"ì°¸ì—¬ì‹œì‘ì¼\",\n",
    "            \"ì…ì°°ë§ˆê°ì¼\", \"ì°¸ì—¬ë§ˆê°ì¼\", \"ê³µê³ ë²ˆí˜¸\", \"ê³µê°œì¼ì\", \"ì…ì°°ê³µê³ ì¼\"\n",
    "        ])\n",
    "\n",
    "        if any(k in normalized_query for k in explicit_summary_keywords):\n",
    "            return \"metadata\"\n",
    "        if any(filters for field in metadata_keywords):\n",
    "            return \"metadata\"\n",
    "        return \"semantic\"\n",
    "\n",
    "    \n",
    "    def smart_search(self, query: str, top_k: int = 5, candidate_size: int = 10) -> List[Document]:\n",
    "        \"\"\"ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰: í•„í„° ì¶”ì¶œ + ì¿¼ë¦¬ ìœ í˜• íŒë‹¨ + í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\"\"\"\n",
    "        if self.db is None or not self.bm25_ready:\n",
    "            raise ValueError(\"âŒ Vector DB ë˜ëŠ” BM25 ì¸ë±ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "        # 1. í•„í„° ì¶”ì¶œ\n",
    "        filters = extract_filters(query, self.meta_df, self.tokenizer)\n",
    "        logging.info(f\"ğŸ§  ì¶”ì¶œëœ í•„í„°: {filters}\")\n",
    "    \n",
    "        # 2. ì¿¼ë¦¬ ìœ í˜• íŒë‹¨\n",
    "        query_type = self.detect_query_type(query, filters)\n",
    "    \n",
    "        # 3. ë°œì£¼ê¸°ê´€ í‚¤ì›Œë“œ ì œê±°\n",
    "        if filters.get(\"ë°œì£¼ ê¸°ê´€\"):\n",
    "            agency_name = filters[\"ë°œì£¼ ê¸°ê´€\"][\"value\"]\n",
    "            query = re.sub(rf\"\\b{re.escape(agency_name)}\\b\", \"\", query).strip()\n",
    "            logging.info(f\"ğŸ§¹ ì¿¼ë¦¬ì—ì„œ ë°œì£¼ê¸°ê´€ í‚¤ì›Œë“œ ì œê±°ë¨: '{agency_name}'\")\n",
    "    \n",
    "        # 4. ë©”íƒ€ë°ì´í„° ê¸°ë°˜ í•„í„°ë§ (metadata ì¿¼ë¦¬ì¼ ë•Œë§Œ)\n",
    "        matched_records = []\n",
    "        candidate_filenames = None\n",
    "        if query_type == \"metadata\" and self.meta_df is not None:\n",
    "            matched_df = self.meta_df[\n",
    "                self.meta_df.apply(lambda row: check_filter_match(row, filters), axis=1)\n",
    "            ]\n",
    "            logging.info(f\"ğŸ“Š ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì™„ë£Œ: {len(matched_df)}ê°œ\")\n",
    "    \n",
    "            if not matched_df.empty:\n",
    "                matched_records = matched_df.head(10).to_dict(orient=\"records\")\n",
    "                candidate_filenames = matched_df[\"íŒŒì¼ëª…\"].dropna().unique().tolist()\n",
    "                logging.info(f\"ğŸ“ ì˜ë¯¸ ê²€ìƒ‰ ëŒ€ìƒ ì œí•œë¨ (íŒŒì¼ëª… ê¸°ì¤€): {len(candidate_filenames)}ê°œ\")\n",
    "            else:\n",
    "                logging.warning(\"âš ï¸ ë©”íƒ€ë°ì´í„° í•„í„°ë§ ê²°ê³¼ ì—†ìŒ â†’ ì „ì²´ ë¬¸ì„œ ëŒ€ìƒìœ¼ë¡œ ê²€ìƒ‰\")\n",
    "    \n",
    "        # 5. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰\n",
    "        logging.info(\"ğŸ” ì˜ë¯¸ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰\")\n",
    "        semantic_docs = self.hybrid_search(\n",
    "            query=query,\n",
    "            top_k=top_k,\n",
    "            candidate_size=candidate_size,\n",
    "            filter_dict=filters,\n",
    "            candidate_filenames=candidate_filenames\n",
    "        )\n",
    "        \n",
    "        return matched_records, semantic_docs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63000065-4e46-47c1-80ac-47e907cdc907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Union, Any, Optional\n",
    "\n",
    "FILTER_MAPPER = {\n",
    "    \"ì‚¬ì—…ê¸ˆì•¡\": {\n",
    "        \"field\": \"ì‚¬ì—… ê¸ˆì•¡\", \n",
    "        \"type\": int,\n",
    "        \"pattern\": r\"(ì‚¬ì—…\\s?ê¸ˆì•¡)?\\s*(\\d+[ì–µë§Œì²œë°±ì¡°]+)\\s*(ì´ìƒ|ì´í•˜|ì´ˆê³¼|ë¯¸ë§Œ)?\"\n",
    "    },\n",
    "    \"ì…ì°°ì‹œì‘ì¼\": {\n",
    "        \"field\": \"ì…ì°° ì°¸ì—¬ ì‹œì‘ì¼\",\n",
    "        \"type\": \"date\",\n",
    "        \"pattern\": r\"(ì…ì°°\\s?ì‹œì‘ì¼|ì°¸ì—¬\\s?ì‹œì‘ì¼)[^\\d]*(\\d{4})[ë…„\\s]*(\\d{1,2})?[ì›”]?\"\n",
    "    },\n",
    "    \"ì…ì°°ë§ˆê°ì¼\": {\n",
    "        \"field\": \"ì…ì°° ì°¸ì—¬ ë§ˆê°ì¼\",\n",
    "        \"type\": \"date\",\n",
    "        \"pattern\": r\"(ì…ì°°\\s?ë§ˆê°ì¼|ì°¸ì—¬\\s?ë§ˆê°ì¼)[^\\d]*(\\d{4})[ë…„\\s]*(\\d{1,2})?[ì›”]?\"\n",
    "    },\n",
    "    \"ì…ì°°ê³µê³ ì¼\": {\n",
    "        \"field\": \"ê³µê°œ ì¼ì\",\n",
    "        \"type\": \"date\",\n",
    "        \"pattern\": r\"(ì…ì°°\\s?ê³µê³ ì¼)[^\\d]*(\\d{4})[ë…„\\s]*(\\d{1,2})?[ì›”]?\"\n",
    "    },\n",
    "    \"ë°œì£¼ê¸°ê´€\": {\n",
    "        \"field\": \"ë°œì£¼ ê¸°ê´€\",  \n",
    "        \"type\": str,\n",
    "        \"pattern\": r\"(í•œêµ­ë†ì–´ì´Œê³µì‚¬|ì¡°ë‹¬ì²­|ë„ë¡œê³µì‚¬|[ê°€-í£]{2,})\"\n",
    "    },\n",
    "    \"ê³µê³ ë²ˆí˜¸\": {\n",
    "        \"field\": \"ê³µê³  ë²ˆí˜¸\", \n",
    "        \"type\": str,\n",
    "        \"pattern\": r\"(ê³µê³ ë²ˆí˜¸\\s?\\d{4}-?\\d{3,})\"\n",
    "    },\n",
    "}\n",
    "def normalize_keywords(keywords: list[str]) -> set[str]:\n",
    "    \"\"\"í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•˜ì—¬ ë¹„êµ ê°€ëŠ¥í•˜ê²Œ ë³€í™˜\"\"\"\n",
    "    return {k.replace(\" \", \"\").lower() for k in keywords}\n",
    "\n",
    "def safe_parse_date(value: str) -> Optional[datetime]:\n",
    "    if not isinstance(value, str):\n",
    "        return None\n",
    "    try:\n",
    "        parts = [int(p) for p in re.findall(r\"\\d+\", value)]\n",
    "        if len(parts) >= 2:\n",
    "            year, month = parts[0], parts[1]\n",
    "            day = parts[2] if len(parts) > 2 else 1\n",
    "            return datetime(year, month, day)\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"âŒ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {value} â†’ {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_korean_number(text: str) -> int:\n",
    "    unit_values = {\n",
    "        \"ì‹­\": 10,\n",
    "        \"ë°±\": 100,\n",
    "        \"ì²œ\": 1000,\n",
    "        \"ë§Œ\": 10_000,\n",
    "        \"ì–µ\": 100_000_000,\n",
    "        \"ì¡°\": 1_000_000_000_000\n",
    "    }\n",
    "\n",
    "    # ì •ê·œí™”\n",
    "    text = text.replace(\",\", \"\").replace(\"ì–µì›\", \"ì–µ\").replace(\"ë°±ë§Œì›\", \"ë°±ë§Œ\") \\\n",
    "               .replace(\"ì²œë§Œì›\", \"ì²œë§Œ\").replace(\"ë§Œì›\", \"ë§Œ\").replace(\"ì›\", \"\").strip()\n",
    "    print(\"ğŸŒ¸ ì²˜ë¦¬ì „ text:\", text)\n",
    "\n",
    "    # ë‹¨ìœ„ë³„ ë¸”ë¡ ì¶”ì¶œ\n",
    "    blocks = re.findall(r\"(\\d+)([ì‹­ë°±ì²œë§Œì–µì¡°]+)\", text)\n",
    "\n",
    "    total = 0\n",
    "    current_block = 0\n",
    "    last_big_unit = 1\n",
    "\n",
    "    for num_str, unit_str in blocks:\n",
    "        num = int(num_str)\n",
    "        small_unit = 1\n",
    "        big_unit = 1\n",
    "\n",
    "        for char in unit_str:\n",
    "            if char in [\"ì‹­\", \"ë°±\", \"ì²œ\"]:\n",
    "                small_unit *= unit_values[char]\n",
    "            elif char in [\"ë§Œ\", \"ì–µ\", \"ì¡°\"]:\n",
    "                big_unit = unit_values[char]\n",
    "\n",
    "        current_block += num * small_unit\n",
    "\n",
    "        # í° ë‹¨ìœ„ê°€ ë¶™ì—ˆìœ¼ë©´ ì „ì²´ ë¸”ë¡ì— ê³±í•´ì„œ totalì— ë”í•¨\n",
    "        if big_unit > 1:\n",
    "            total += current_block * big_unit\n",
    "            current_block = 0\n",
    "\n",
    "    total += current_block\n",
    "    print(\"ğŸŒ¸ ì²˜ë¦¬ì™„ë£Œí›„:\", total)\n",
    "    return total\n",
    "\n",
    "\n",
    "# ì˜ˆì‹œ:\n",
    "# parse_korean_number(\"5ì²œë§Œì›\")        # 50000000\n",
    "# parse_korean_number(\"1ì–µ 2ì²œë§Œì›\")    # 120000000\n",
    "# parse_korean_number(\"2ì²œë§Œ\")         # 20000000\n",
    "# parse_korean_number(\"3ë°±ì–µ\")         # 30000000000\n",
    "# parse_korean_number(\"456ë°±ë§Œ\")       # 456000000\n",
    "\n",
    "\n",
    "def convert_value(raw: str, value_type):\n",
    "    \"\"\"í•„í„° ì¶”ì¶œìš© ê°’ ë³€í™˜\"\"\"\n",
    "    if value_type in (\"int\", int):\n",
    "        return parse_korean_number(raw)\n",
    "    elif value_type in (\"date\", datetime):\n",
    "        return safe_parse_date(raw)\n",
    "    elif value_type in (\"float\", float):\n",
    "        try:\n",
    "            return float(str(raw).replace(\",\", \"\").strip())\n",
    "        except ValueError:\n",
    "            return None\n",
    "    else:\n",
    "        return raw.strip()\n",
    "\n",
    "\n",
    "OPERATOR_FUNC = {\n",
    "    \">=\": lambda v, t: v >= t,\n",
    "    \"<=\": lambda v, t: v <= t,\n",
    "    \">\":  lambda v, t: v > t,\n",
    "    \"<\":  lambda v, t: v < t,\n",
    "    \"=\":  lambda v, t: v == t,\n",
    "    \"~\":  lambda v, t: abs(v - t) <= t * 0.1\n",
    "}\n",
    "\n",
    "def extract_operator(text: str, context: str = \"\") -> str:\n",
    "    full_text = text + \" \" + context\n",
    "    if \"ì´í›„\" in full_text or \"ë¶€í„°\" in full_text or \"ìµœì†Œ\" in full_text or \"ì´ìƒ\" in full_text:\n",
    "        return \">=\"\n",
    "    elif \"ì´ì „\" in full_text or \"ê¹Œì§€\" in full_text or \"ìµœëŒ€\" in full_text or \"ì´í•˜\" in full_text:\n",
    "        return \"<=\"\n",
    "    elif \"ì´ˆê³¼\" in full_text:\n",
    "        return \">\"\n",
    "    elif \"ë¯¸ë§Œ\" in full_text:\n",
    "        return \"<\"\n",
    "    elif \"ì•½\" in full_text or \"ì •ë„\" in full_text:\n",
    "        return \"~\"\n",
    "    return \"=\"\n",
    "\n",
    "\n",
    "# ğŸš¨ ê¸°ê´€ëª…/íŒŒì¼ëª… í•„í„°ë§ ì‹œ ì œê±°í•  ì¡ìŒ ë‹¨ì–´ ëª©ë¡\n",
    "NOISE_WORDS = {\n",
    "     # ë‚ ì§œ/ì‹œì  ê´€ë ¨\n",
    "    \"ë…„\", \"ì›”\", \"ì¼\", \"ë…„ë„\", \"2024\", \"2025\",\n",
    "\n",
    "    # ì…ì°°/ê³µê³  ê´€ë ¨\n",
    "    \"ì…ì°°\", \"ê³µê³ \", \"ì¬ê³µê³ \", \"ê¸´ê¸‰\", \"í˜‘ìƒ\", \"ì‚¬ì „ê³µê°œ\",\n",
    "\n",
    "    # ê¸ˆì•¡ ê´€ë ¨\n",
    "    \"ì›\", \"ì˜ˆì‚°\",\n",
    "\n",
    "}\n",
    "\n",
    "def extract_field_filter_by_tokens(\n",
    "    query: str,\n",
    "    field_values: List[str],\n",
    "    tokenizer,\n",
    "    field_name: str,\n",
    "    use_exact_match: bool = True,\n",
    "    threshold: float = 0.5\n",
    ") -> Optional[Dict[str, Dict]]:\n",
    "    \n",
    "    query_tokens = set(tokenizer.tokenize_korean(query, use_bigrams=False)) - NOISE_WORDS\n",
    "    print(\"â¤ï¸query_tokens\", query_tokens)\n",
    "    logging.debug(f\"ğŸ§¹ í•„í„°ë§ìš© í† í°ì…‹: {query_tokens}\")\n",
    "\n",
    "    # 1ï¸âƒ£ ì •í™• ë§¤ì¹­ ìš°ì„ \n",
    "    if use_exact_match:\n",
    "        for value in field_values:\n",
    "            if value and value in query:\n",
    "                return {field_name: {\"value\": value, \"operator\": \"=\"}}\n",
    "\n",
    "    # ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    for value in field_values:\n",
    "        match_count = sum(1 for token in query_tokens if token in value)\n",
    "        score = match_count / len(query_tokens) if query_tokens else 0\n",
    "        if score > best_score and score > threshold:\n",
    "            best_match = value\n",
    "            best_score = score\n",
    "           \n",
    "    if best_match:\n",
    "        print(\"â¤ï¸best_match\", best_match, best_score)\n",
    "        return {field_name: {\"value\": best_match, \"operator\": \"=\"}}\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_filters(query: str, meta_df: pd.DataFrame, tokenizer) -> Dict[str, Dict]:\n",
    "    filters = {}\n",
    "    \n",
    "    # 3ï¸âƒ£ ì •ê·œì‹ ê¸°ë°˜ í•„í„° ì¶”ì¶œ\n",
    "    for keyword, filter_info in FILTER_MAPPER.items():\n",
    "        field_name = filter_info.get(\"field\")\n",
    "    \n",
    "        # âœ… ê¸°ê´€ëª…/íŒŒì¼ëª…ì€ ì •ê·œì‹ìœ¼ë¡œ ì¶”ì¶œí•˜ì§€ ì•ŠìŒ\n",
    "        if field_name in filters or field_name in [\"ë°œì£¼ ê¸°ê´€\", \"íŒŒì¼ëª…\"]:\n",
    "            continue\n",
    "            \n",
    "        match = re.search(filter_info['pattern'], query)\n",
    "        if match:\n",
    "            value_type = filter_info.get('type')\n",
    "            if value_type == \"date\":\n",
    "                year = match.group(2)\n",
    "                month = match.group(3) if match.lastindex and match.lastindex >= 3 and match.group(3) else \"1\"\n",
    "                raw_value = f\"{year}ë…„ {month}ì›”\"\n",
    "            elif value_type == int:\n",
    "                raw_value = match.group(2)\n",
    "                condition = match.group(3) or \"\"\n",
    "                operator = extract_operator(condition, query)\n",
    "            else:\n",
    "                raw_value = match.group(1)\n",
    "                operator = \"=\"\n",
    "    \n",
    "            value = convert_value(raw_value, value_type)\n",
    "            operator = extract_operator(raw_value, query) if value_type in [\"date\", int] else \"=\"\n",
    "            if value is not None:\n",
    "                filters[field_name] = {\"value\": value, \"operator\": operator}\n",
    "                logging.info(f\"ğŸ“Œ {field_name} í•„í„° ì ìš©ë¨: {value} ({operator})\")\n",
    "\n",
    "    # ë°œì£¼ ê¸°ê´€ í•„í„°ë§\n",
    "    agency_filter_applied = False\n",
    "    if \"ë°œì£¼ ê¸°ê´€\" in meta_df.columns:\n",
    "        agency_list = meta_df[\"ë°œì£¼ ê¸°ê´€\"].dropna().unique().tolist()\n",
    "        agency_filter = extract_field_filter_by_tokens(\n",
    "            query=query,\n",
    "            field_values=agency_list,\n",
    "            tokenizer=tokenizer,\n",
    "            field_name=\"ë°œì£¼ ê¸°ê´€\",\n",
    "            use_exact_match=True,\n",
    "            threshold=0.5\n",
    "        )\n",
    "        \n",
    "        print(\"â¤ï¸agency_filter : \", agency_filter)\n",
    "        if agency_filter:\n",
    "            filters.update(agency_filter)\n",
    "            agency_filter_applied = True\n",
    "            logging.info(f\"ğŸ¢ ë°œì£¼ ê¸°ê´€ í•„í„° ì ìš©ë¨: {agency_filter['ë°œì£¼ ê¸°ê´€']['value']}\")\n",
    "   \n",
    "    # íŒŒì¼ëª… ë³´ì¡° í•„í„°ë§ (ê¸°ê´€ í•„í„° ì—†ì„ ë•Œë§Œ)\n",
    "    if not agency_filter_applied and \"íŒŒì¼ëª…\" in meta_df.columns:\n",
    "        filename_list = meta_df[\"íŒŒì¼ëª…\"].dropna().unique().tolist()\n",
    "        print(\"â¤ï¸íŒŒì¼í•„í„°ì‘ë™ \")\n",
    "        filename_filter = extract_field_filter_by_tokens(\n",
    "            query=query,\n",
    "            field_values=filename_list,\n",
    "            tokenizer=tokenizer,\n",
    "            field_name=\"íŒŒì¼ëª…\",\n",
    "            use_exact_match=True,\n",
    "            threshold=0.5  # âœ… ë” ìœ ì—°í•˜ê²Œ\n",
    "        )\n",
    "        print(\"â¤ï¸file_filter : \", filename_filter)\n",
    "        if filename_filter:\n",
    "            filters.update(filename_filter)\n",
    "            logging.info(f\"ğŸ“ íŒŒì¼ëª… í•„í„° ì ìš©ë¨: {filename_filter['íŒŒì¼ëª…']['value']}\")\n",
    "\n",
    "    return filters\n",
    "\n",
    "\n",
    "def is_valid_value(value):\n",
    "    \"\"\"ê°’ì´ ìœ íš¨í•œì§€ í™•ì¸í•˜ëŠ” í—¬í¼ í•¨ìˆ˜\"\"\"\n",
    "    if value is None or str(value).strip() in [\"\", \"ë¯¸ì •\", \"nan\"]:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_filter_match(data: Union[Dict, Any], filters: Dict[str, Dict]) -> bool:\n",
    "    for field, condition in filters.items():\n",
    "        raw_value = data.get(field)\n",
    "\n",
    "        if not is_valid_value(raw_value):\n",
    "            return False\n",
    "\n",
    "        target = condition[\"value\"]\n",
    "        operator = condition[\"operator\"]\n",
    "\n",
    "        # âœ… raw_valueê°€ targetê³¼ ê°™ì€ íƒ€ì…ì¸ì§€ í™•ì¸\n",
    "        try:\n",
    "            if isinstance(target, int):\n",
    "                value = int(str(raw_value).replace(\",\", \"\").strip())\n",
    "            elif isinstance(target, float):\n",
    "                value = float(str(raw_value).replace(\",\", \"\").strip())\n",
    "            elif isinstance(target, datetime):\n",
    "                value = safe_parse_date(str(raw_value))\n",
    "            else:\n",
    "                value = str(raw_value).strip()\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "        compare_func = OPERATOR_FUNC.get(operator)\n",
    "        if not compare_func:\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            return compare_func(value, target)\n",
    "        except TypeError:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# ì˜ˆì‹œ: 'ì‚¬ì—…ê¸ˆì•¡ 5ì²œë§Œì› ì´ìƒì¸ ê³µê³  ì°¾ì•„ì¤˜'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06380fd1-e56e-4af7-b466-66cb19745fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "def merge_docs_to_text(docs):\n",
    "    \"\"\"\n",
    "    ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼(Document ë¦¬ìŠ¤íŠ¸)ë¥¼ ë°›ì•„ì„œ\n",
    "    LLM contextë¡œ í•©ì¹˜ëŠ” í•¨ìˆ˜.\n",
    "    (ë¬¸ì„œ ì „ì²´ ë‚´ìš©ì„ í•©ì¹¨, ì˜ë¼ë‚´ê¸° ì œí•œ ì—†ìŒ)\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return \"\"\n",
    "\n",
    "    merged = []\n",
    "    for doc in docs:\n",
    "        text = doc.page_content.strip()\n",
    "        merged.append(f\"[ì¶œì²˜: {doc.metadata.get('íŒŒì¼ëª…', 'â“')}]\\n{text}\")\n",
    "\n",
    "    return \"\\n\\n\".join(merged)\n",
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY, \n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=1,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤:\n",
    "\n",
    "{context}\n",
    "\n",
    "ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:\n",
    "ì§ˆë¬¸: {question}\n",
    "\"\"\")\n",
    "\n",
    "qa_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fb5a1f7-d943-4969-9959-50aec34c0e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 08:41:54,096 - INFO - Load pretrained SentenceTransformer: nlpai-lab/KURE-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë””ë°”ì´ìŠ¤: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 08:41:58,396 - INFO - ğŸ“¦ ìºì‹œëœ JSON ë¬¸ì„œ ë¡œë“œ ì¤‘...\n",
      "2025-09-26 08:41:58,492 - INFO - ğŸ”§ ê°€ì¤‘ì¹˜ ì„¤ì •ë¨ | BM25: 0.3 | Rerank: 0.7\n",
      "2025-09-26 08:41:58,493 - INFO - âœ… ê¸°ì¡´ ë²¡í„° DB ë¡œë“œ ì¤‘...\n",
      "2025-09-26 08:41:59,400 - INFO - â© ìƒˆ ë¬¸ì„œ ì—†ìŒ, DB ì¶”ê°€ ìƒëµ\n",
      "2025-09-26 08:42:01,306 - INFO - âœ… BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: /home/spai0320/projectmission2/data/cache/bm25_index.pkl\n",
      "2025-09-26 08:42:01,307 - INFO - ğŸ’¡ ë¦¬ë­ì»¤ ì„ë² ë”© ìºì‹± ì¤‘...\n",
      "2025-09-26 08:42:01,387 - INFO - âœ… ë¦¬ë­ì»¤ ìºì‹± ì™„ë£Œ.\n",
      "2025-09-26 08:42:01,390 - INFO - ğŸš€ ëª¨ë“  DB ë° ì¸ë±ìŠ¤ ì¤€ë¹„ ì™„ë£Œ.\n",
      "2025-09-26 08:42:01,390 - INFO - \n",
      "[ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì‹¤í–‰] ì§ˆë¬¸: ì„œìš¸íŠ¹ë³„ì‹œ ê³µê³µë°ì´í„° ê°œë°©ì´ë‚˜ ì—°ê³„ ê´€ë ¨í•´ì„œ ì–´ë–¤ ìš”êµ¬ì‚¬í•­ì´ ìˆì–´?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì˜ë¯¸ ì„ë² ë”© ìºì‹± ì™„ë£Œ | ìƒˆë¡œ ìºì‹±: 0ê°œ | ìŠ¤í‚µ: 7569ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 08:42:03,095 - INFO - ğŸ¢ ë°œì£¼ ê¸°ê´€ í•„í„° ì ìš©ë¨: ì„œìš¸íŠ¹ë³„ì‹œ\n",
      "2025-09-26 08:42:03,098 - INFO - ğŸ§  ì¶”ì¶œëœ í•„í„°: {'ë°œì£¼ ê¸°ê´€': {'value': 'ì„œìš¸íŠ¹ë³„ì‹œ', 'operator': '='}}\n",
      "2025-09-26 08:42:03,100 - INFO - ğŸ§¹ ì¿¼ë¦¬ì—ì„œ ë°œì£¼ê¸°ê´€ í‚¤ì›Œë“œ ì œê±°ë¨: 'ì„œìš¸íŠ¹ë³„ì‹œ'\n",
      "2025-09-26 08:42:03,103 - INFO - ğŸ“Š ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì™„ë£Œ: 1ê°œ\n",
      "2025-09-26 08:42:03,106 - INFO - ğŸ“ ì˜ë¯¸ ê²€ìƒ‰ ëŒ€ìƒ ì œí•œë¨ (íŒŒì¼ëª… ê¸°ì¤€): 1ê°œ\n",
      "2025-09-26 08:42:03,107 - INFO - ğŸ” ì˜ë¯¸ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰\n",
      "2025-09-26 08:42:03,107 - INFO - ğŸ” í•˜ì´ë¸Œë¦¬ë“œ í•„í„° ì ìš©: {'ë°œì£¼ ê¸°ê´€': {'value': 'ì„œìš¸íŠ¹ë³„ì‹œ', 'operator': '='}}\n",
      "2025-09-26 08:42:03,218 - INFO - ğŸ“ íŒŒì¼ëª… ê¸°ë°˜ í›„ë³´ ì œí•œ ì ìš©ë¨: 1ê°œ\n",
      "2025-09-26 08:42:03,220 - INFO - âœ… ê³ ê¸‰ í•„í„°ë§ í›„ ë¬¸ì„œ ìˆ˜: 13\n",
      "2025-09-26 08:42:03,239 - INFO - ğŸ§  ì¬ìˆœìœ„í™” ì ìˆ˜ ê³„ì‚° ì™„ë£Œ (ë³´ë„ˆìŠ¤ í¬í•¨)\n",
      "2025-09-26 08:42:03,241 - INFO - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì ìˆ˜ ì •ë³´\n",
      "2025-09-26 08:42:03,242 - INFO - ğŸ“Š í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: 13 â†’ 3ê°œ ë°˜í™˜\n",
      "2025-09-26 08:42:03,242 - INFO - ğŸ§  LLM ì‘ë‹µ ìƒì„± ì‹œì‘ì¤‘...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” BM25 í‚¤ì›Œë“œ í† í°: ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ê³µê³µ', 'ë°ì´í„°', 'ê°œë°©', 'ì—°ê³„', 'ê´€ë ¨', 'ìš”êµ¬', 'ì‚¬í•­', 'ì„œìš¸íŠ¹ë³„ì‹œê³µê³µ', 'ê³µê³µë°ì´í„°', 'ë°ì´í„°ê°œë°©', 'ê°œë°©ì—°ê³„', 'ì—°ê³„ê´€ë ¨', 'ê´€ë ¨ìš”êµ¬', 'ìš”êµ¬ì‚¬í•­']\n",
      "â¤ï¸query_tokens {'ê³µê³µ', 'ì‚¬í•­', 'ë°ì´í„°', 'ê°œë°©', 'ìš”êµ¬', 'ì„œìš¸íŠ¹ë³„ì‹œ', 'ê´€ë ¨', 'ì—°ê³„'}\n",
      "â¤ï¸agency_filter :  {'ë°œì£¼ ê¸°ê´€': {'value': 'ì„œìš¸íŠ¹ë³„ì‹œ', 'operator': '='}}\n",
      "\n",
      "ğŸ“ˆ BM25 ìƒìœ„ ë¬¸ì„œ ë° ì ìˆ˜:\n",
      "BM25 ë¬¸ì„œ 1 | ì ìˆ˜: 32.0440 | ì¶œì²˜: ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf\n",
      "- 34 - ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ DAR-009 ìš”êµ¬ì‚¬í•­ ëª… ë°ì´í„° ê´€ë¦¬ì²´ê³„ ìˆ˜ë¦½ ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ë°ì´í„° í’ˆì§ˆ ìƒì„¸ ì„¤ëª… ì •ì˜ ë°ì´í„° ê´€ë¦¬ì²´ê³„ ìˆ˜ë¦½ ì„¸ë¶€ ë‚´ìš© ë°ì´í„° ê´€ë¦¬ì²´ê³„ ì •ì˜ - í‘œì¤€, êµ¬ì¡°, ì—°ê³„ ë“± ë°ì´í„° í•µì‹¬ ìš”ì†Œì˜ ì§€ì†ì ì¸ ê´€ë¦¬ë¥¼ ìœ„í•œ ì¡°ì§ê³¼ ì—­í• ì„ ì •ì˜í•˜ì—¬ì•¼ í•¨ - ë°ì´í„° ê°’ì˜ ì§„ë‹¨ ë° ê°œì„  ë“± í’ˆì§ˆê´€ë¦¬ ì¡°ì§ê³¼ ì—­í• ì„ ì •ì˜í•˜ì—¬ì•¼ í•¨ - ë°ì´í„° ê°’ ì§„ë‹¨ ë°©ì•ˆê¸°ëŠ¥, ì§„ë‹¨ í”„ë¡œê·¸ë¨ ë“±ì„ ì œì‹œí•˜ì—¬ì•¼ í•¨ - ë°ì´í„° í‘œì¤€ë‹¨ì–´ìš©ì–´ë„ë©”ì¸ì½”ë“œì˜ ì¶”ê°€, ë³€ê²½, ì‚­ì œ ì ˆì°¨ë¥¼ ìˆ˜ë¦½í•˜ì—¬ì•¼ í•¨. - ë°ì´í„° êµ¬ì¡°ë…¼ë¦¬ë¬¼ë¦¬ì™€ ê´€ë ¨ëœ ì¶”ê°€, ë³€ê²½, ì‚­ì œ ì ˆì°¨ë¥¼\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 2 | ì ìˆ˜: 17.1946 | ì¶œì²˜: ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf\n",
      "- 18 - 3. ì œì•ˆìš”ì²­ ë‚´ìš© ê°€. ìš”êµ¬ì‚¬í•­ êµ¬ì„± ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ì„¤ ëª… ìš”êµ¬ì‚¬í•­ ë²ˆí˜¸IDë¶€ì—¬ ê·œì¹™ ìš” êµ¬ ì‚¬í•­ìˆ˜ ì‹œìŠ¤í…œ ì¥ë¹„êµ¬ì„±ECR Equipment Composition Requirement - ëª©í‘œì‹œìŠ¤í…œì˜ êµ¬ì„±ì„ ìœ„í•´ í•„ìš”í•œ í•˜ë“œì›¨ì–´, ì†Œí”„íŠ¸ì›¨ì–´, ë„¤íŠ¸ì›Œí¬ ë“±ì˜ ë„ì… ì¥ë¹„ ë‚´ì—­ ë“± ì‹œìŠ¤í…œ ì¥ë¹„ êµ¬ì„±ì— ëŒ€í•œ ìš”êµ¬ì‚¬í•­ 1 ê¸°ëŠ¥SFR System Function Requirement - ëª©í‘œì‹œìŠ¤í…œì´ ë°˜ë“œì‹œ ìˆ˜í–‰í•´ì•¼ í•˜ê±°ë‚˜ ëª©í‘œì‹œìŠ¤í…œì„ ì´ìš©í•˜ì—¬ ì‚¬ìš©ìê°€ ë°˜ë“œì‹œ ìˆ˜í–‰í•  ìˆ˜ ìˆì–´ì•¼ í•˜ëŠ” ê¸°ëŠ¥ë™ì‘ ê°œë°œ ìš”êµ¬ì‚¬í•­ 14 ì„±ëŠ¥PER PErfo\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 3 | ì ìˆ˜: 16.1662 | ì¶œì²˜: ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf\n",
      "- 46 - ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ COR-010 ìš”êµ¬ì‚¬í•­ ëª… ì›¹ì‚¬ì´íŠ¸í™ˆí˜ì´ì§€, ëª¨ë°”ì¼ì›¹ì•± ì„œë¹„ìŠ¤ ì´ìš©í˜„í™© ë¶„ì„ì‹œìŠ¤í…œ í™œìš© ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ì œì•½ì‚¬í•­ ìƒì„¸ ì„¤ëª… ì •ì˜ ì„œìš¸ì‹œ í†µí•© ì›¹ì•±ë¡œê·¸ ë¶„ì„ì‹œìŠ¤í…œ í™œìš©ì— ê´€í•œ ì‚¬í•­ ì„¸ë¶€ ë‚´ìš© ì„œìš¸ì‹œ ì›¹ì•±ì„œë¹„ìŠ¤ ì‹ ê·œ êµ¬ì¶• ë° ë¦¬ë‰´ì–¼ ì‹œ í†µí•© ì›¹ì•± ë¡œê·¸ ë¶„ì„ì‹œìŠ¤í…œì„ í™œìš©í•˜ì—¬ ë°©ë¬¸ìì˜ ì´ìš©í˜„í™© ë¶„ì„ì„ ì‹¤ì‹œí•´ì•¼ í•¨ ì‹¤ì‹œê°„ ì›¹ì•±ë¡œê·¸ ìˆ˜ì§‘ ë° ë¶„ì„ì„ ìœ„í•´ ë‰´ë¯¸ë””ì–´ë‹´ë‹¹ê´€í™ˆí˜ì´ì§€íŒ€ì—ì„œ ì œê³µí•˜ëŠ” ê°€ì´ ë“œì— ë”°ë¼ ìŠ¤í¬ë¦½íŠ¸SDK ì ìš© ì‘ì—… ì‹¤ì‹œ - ì‹ ê·œ ì„œë¹„ìŠ¤ ì˜¤í”ˆ ì „ ë˜ëŠ” ì½˜í…ì¸  ì¶”ê°€ë³€ê²½ ì‹œ ëª¨ë“  í˜ì´ì§€ì— í•„ìˆ˜ ì ìš© - PCìš©ì›¹\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 4 | ì ìˆ˜: 15.8963 | ì¶œì²˜: ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf\n",
      "- 30 - ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ UIR-001 ìš”êµ¬ì‚¬í•­ ëª… ë§¤ë ¥ì„œìš¸ì§€ë„ UI êµ¬ì„± ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ì¸í„°í˜ì´ìŠ¤ ìš”êµ¬ì‚¬í•­ ìƒì„¸ ì„¤ëª… ì •ì˜ ì‚¬ìš©ì íŠ¹ì„±ì„ ê³ ë ¤í•˜ë˜ ìŠ¤ë§ˆíŠ¸ì„œìš¸ë§µê³¼ í†µì¼ì„± ìˆëŠ” ì§€ë„ í™”ë©´UI ì„¤ê³„ ì„¸ë¶€ ë‚´ìš© m ë§¤ë ¥ì„œìš¸ì§€ë„ í™”ë©´UI êµ¬ì„± - êµ¬ê¸€, ë„¤ì´ë²„ ë“± ì£¼ìš” ì‹œë¯¼ ëŒ€ìƒ ì§€ë„ ì„œë¹„ìŠ¤ UI ë™í–¥ ì¡°ì‚¬4ì¢… ì´ìƒ - ìŠ¤ë§ˆíŠ¸ì„œìš¸ë§µê³¼ í†µì¼ëœ ì§€ë„ ê¸°ëŠ¥ìœ¼ë¡œ êµ¬í˜„í•˜ë˜ ì‚¬ìš©ì íŠ¹ì„±ì„ ê³ ë ¤í•œ ì„¤ê³„ - ìŠ¤ë§ˆíŠ¸í°ê³¼ PCì—ì„œ ì´ì§ˆê° ì—†ëŠ” UI ì œê³µ - ë‹¤êµ­ì–´ ìë™ ë²ˆì—­ì—ë„ ê³µí†µí™œìš© ê°€ëŠ¥í•œ GUI ì±„íƒ ì‚°ì¶œì •ë³´ m êµ­ë‚´ì™¸ ì§€ë„ ì„œë¹„ìŠ¤ UI ë™í–¥ ì¡°ì‚¬ì„œ,\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 5 | ì ìˆ˜: 15.1356 | ì¶œì²˜: ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf\n",
      "- 44 - ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ COR-005 ìš”êµ¬ì‚¬í•­ ëª… ì›¹ì‚¬ì´íŠ¸í™ˆí˜ì´ì§€, ëª¨ë°”ì¼ì›¹ ì›¹ì ‘ê·¼ì„± ì¤€ìˆ˜ ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ì œì•½ì‚¬í•­ ìƒì„¸ ì„¤ëª… ì •ì˜ ì›¹ì‚¬ì´íŠ¸ ì¥ì• ì¸ ì›¹ì ‘ê·¼ì„± ì¤€ìˆ˜ ì˜ë¬´ì— ê´€í•œ ì‚¬í•­ ì„¸ë¶€ ë‚´ìš© ì›¹ì‚¬ì´íŠ¸ ì›¹ì ‘ê·¼ì„±ì„ ì¤€ìˆ˜í•˜ì—¬ ì‚¬ì—…ì„ ì¶”ì§„í•´ì•¼ í•˜ë©° ì•„ë˜ í•­ëª©ì„ ì´í–‰í•˜ì—¬ì•¼ í•¨. - ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ ì›¹ì ‘ê·¼ì„± í’ˆì§ˆë§ˆí¬ ì¸ì¦ ê¸°ì¤€ì— ë§ê²Œ êµ¬ì¶•í•˜ì—¬ì•¼ í•¨. í•œêµ­ì§€ëŠ¥ì •ë³´ì‚¬íšŒì§„í¥ì› ì›¹ì ‘ê·¼ì„± ì—°êµ¬ì†Œhttpwww.wah.or.krì˜ ì›¹ì½˜í…ì¸  ì œì‘ê¸°ë²• ì°¸ê³  - ì›¹ì ‘ê·¼ì„± ì¤€ìˆ˜ ì¦ë¹™ ì„œë¥˜ ì œì¶œ ì œì¶œì£¼ê¸° ìƒí˜¸í˜‘ì˜ í›„ ìµœì†Œ ë°˜ê¸°ë³„ ì œì¶œ ì œì¶œì„œì‹ ì›¹ì ‘ê·¼ì„± ì§„ë‹¨ ì²´í¬\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 6 | ì ìˆ˜: 14.8698 | ì¶œì²˜: ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf\n",
      "- 26 - ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ SFR-010 ìš”êµ¬ì‚¬í•­ ëª… ë§¤ë ¥ì„œìš¸ì§€ë„ì‚¬ì§„ì •ë³´ë¥¼ í™œìš©í•œ ì§€ì˜¤íƒœê¹…ìœ¼ë¡œ ë§¤ë ¥ì„œìš¸ ì´ë¯¸ì§€ ì•„ì¹´ì´ë¹™ ë§µ êµ¬ì¶• ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­ ìƒì„¸ ì„¤ëª… ì •ì˜ ìŠ¤ë§ˆíŠ¸ê¸°ìˆ  í™œìš© ì—¬í–‰ê° ë§ì¶¤ ë§¤ë ¥ì„œìš¸ì§€ë„ ë‹¤êµ­ì–´ ì„œë¹„ìŠ¤ êµ¬ì¶• ì„¸ë¶€ ë‚´ìš© m ì´ë¯¸ì§€ ì§€ì˜¤íƒœê¹… ê¸°ìˆ  ì ìš© - ì‚¬ìš©ì ì‚¬ì§„ ë“±ë¡ ì‹œ ì‚¬ì§„ì •ë³´EXIFë¥¼ í™œìš©í•œ ì§€ì˜¤íƒœê¹… ê¸°ëŠ¥ êµ¬í˜„ ì‚¬ì§„ì •ë³´EXIFê°€ ì—†ëŠ” ì´ë¯¸ì§€ëŠ” ë“±ë¡ìê°€ ì§€ë„ì—ì„œ ìœ„ì¹˜ ë“±ë¡ - ì‚¬ì§„ ë¡œë”©ì†ë„ ë° ì•ˆì •ì  ì‹œìŠ¤í…œ ìì› ìš´ìš©ì„ ìœ„í•œ í•´ìƒë„ ê¸°ì¤€ ë§ˆë ¨ ë° ì—…ë¡œë“œ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• ê¸°ìˆ  ì ìš© - ì´ë¯¸ì§€ ì™¸ URL ë§\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 7 | ì ìˆ˜: 13.3344 | ì¶œì²˜: ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf\n",
      "- 138 - êµ¬ ë¶„ í•­ ëª© ì ìš©ê³„íšê²°ê³¼ ë¶€ë¶„ì ìš© ë¯¸ ì ìš©ì‹œ ì‚¬ìœ  ë° ëŒ€ì²´ê¸°ìˆ  ì ìš© ë¶€ë¶„ ì ìš© ë¯¸ ì ìš© í•´ë‹¹ ì—†ìŒ í•˜ì—¬ì•¼ í•˜ë©° ê·¸ë ‡ì§€ ëª»í•œ ê²½ìš°ì—ëŠ” í–‰ì •ê¸°ê´€ë“±ì˜ ì¥ì´ ê·¸ ì‚¬ìœ ë¥¼ í–‰ì •ì•ˆì „ë¶€ì¥ê´€ì—ê²Œ ë³´ê³ í•˜ê³  í–‰ì •ì•ˆì „ë¶€ì˜í–‰ì •ê¸°ê´€ì˜ ì½”ë“œí‘œ ì¤€í™” ì¶”ì§„ì§€ì¹¨ì— ë”°ë¼ ì½”ë“œì²´ê³„ ë° ì½”ë“œë¥¼ ìƒì„±í•˜ì—¬ í–‰ì •ì•ˆì „ë¶€ì¥ ê´€ì—ê²Œ í‘œì¤€ ë“±ë¡ì„ ìš”ì²­í•˜ì—¬ì•¼ í•œë‹¤. o íŒ¨í‚¤ì§€ì†Œí”„íŠ¸ì›¨ì–´ëŠ” íƒ€ íŒ¨í‚¤ì§€ì†Œí”„íŠ¸ì›¨ì–´ ë˜ëŠ” íƒ€ ì •ë³´ì‹œìŠ¤í…œê³¼ì˜ ì—°ê³„ë¥¼ ìœ„í•´ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©ì´ íˆ¬ëª…í•´ì•¼ í•˜ë©° ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì§€ì›í•˜ì—¬ì•¼ í•œë‹¤. ì„¸ë¶€ ê¸°ìˆ  ì§€ì¹¨ ê´€ë ¨ê·œì • o ê³µê³µê¸°ê´€ì˜ ë°ì´í„°ë² ì´\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 8 | ì ìˆ˜: 13.0853 | ì¶œì²˜: ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf\n",
      "- 100 - êµ¬ ë¶„ í•­ ëª© ì ìš©ê³„íšê²°ê³¼ ë¶€ë¶„ì ìš© ë¯¸ ì ìš©ì‹œ ì‚¬ìœ  ë° ëŒ€ì²´ê¸°ìˆ  ì ìš© ë¶€ë¶„ ì ìš© ë¯¸ ì ìš© í•´ë‹¹ ì—†ìŒ o í–‰ì •ì •ë³´ì˜ ê³µë™í™œìš©ì— í•„ìš”í•œ í–‰ì •ì½”ë“œëŠ” í–‰ì •í‘œì¤€ì½”ë“œë¥¼ ì¤€ìˆ˜ í•˜ì—¬ì•¼ í•˜ë©° ê·¸ë ‡ì§€ ëª»í•œ ê²½ìš°ì—ëŠ” í–‰ì •ê¸°ê´€ë“±ì˜ ì¥ì´ ê·¸ ì‚¬ìœ ë¥¼ í–‰ì •ì•ˆì „ë¶€ì¥ê´€ì—ê²Œ ë³´ê³ í•˜ê³  í–‰ì •ì•ˆì „ë¶€ì˜í–‰ì •ê¸°ê´€ì˜ ì½”ë“œí‘œ ì¤€í™” ì¶”ì§„ì§€ì¹¨ì— ë”°ë¼ ì½”ë“œì²´ê³„ ë° ì½”ë“œë¥¼ ìƒì„±í•˜ì—¬ í–‰ì •ì•ˆì „ë¶€ì¥ ê´€ì—ê²Œ í‘œì¤€ ë“±ë¡ì„ ìš”ì²­í•˜ì—¬ì•¼ í•œë‹¤. O o íŒ¨í‚¤ì§€ì†Œí”„íŠ¸ì›¨ì–´ëŠ” íƒ€ íŒ¨í‚¤ì§€ì†Œí”„íŠ¸ì›¨ì–´ ë˜ëŠ” íƒ€ ì •ë³´ì‹œìŠ¤í…œê³¼ì˜ ì—°ê³„ë¥¼ ìœ„í•´ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©ì´ íˆ¬ëª…í•´ì•¼ í•˜ë©° ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ \n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 9 | ì ìˆ˜: 12.6239 | ì¶œì²˜: ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf\n",
      "- 42 - 9 ì œì•½ì‚¬í•­ ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ COR-001 ìš”êµ¬ì‚¬í•­ ëª… ì‚¬ì—…ê´€ë ¨ ê³µí†µ ê·œì • ì¤€ìˆ˜ ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ì œì•½ì‚¬í•­ ìƒì„¸ ì„¤ëª… ì •ì˜ ì •ë³´í™”ì‚¬ì—… ì¶”ì§„ ì‹œ ê¸°ë³¸ê·œì • ì¤€ìˆ˜ì— ê´€í•œ ì‚¬í•­ ì„¸ë¶€ ë‚´ìš© m ì‚¬ì—… ì¶”ì§„ ì‹œ í–‰ì •ê¸°ê´€ ë° ê³µê³µê¸°ê´€ ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶•ìš´ì˜ ì§€ì¹¨í–‰ì •ì•ˆì „ë¶€ ê³ ì‹œ ì— ê·œì •ëœ ì‚¬í•­ì„ ì¤€ìˆ˜í•˜ì—¬ì•¼ í•¨ m ì‚¬ì—… ì¶”ì§„ ê¸°ê°„ ë‚´ ì ìš© ë²•ë ¹ ë° ê·œì •, ì ìš© í‘œì¤€ ë“±ì— ë³€ê²½ì‚¬í•­ ë°œìƒ ì‹œ ë°˜ì˜í•˜ì—¬ ì‚¬ì—… ì¶”ì§„í•˜ì—¬ì•¼ í•¨. ë³€ê²½ ì‚¬í•­ì˜ ì ìš©ì‹œì ì„ ê³ ë ¤í•˜ì—¬ ë°œì£¼ê¸°ê´€ê³¼ í˜‘ì˜í•˜ì—¬ ì ìš© ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ COR-002 ìš”êµ¬ì‚¬í•­ ëª… ì‚¬ì—…ê´€ë ¨ ê³µí†µ ê¸°ìˆ í‘œì¤€ ì¤€ìˆ˜ ìš”êµ¬ì‚¬\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 10 | ì ìˆ˜: 12.5702 | ì¶œì²˜: ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf\n",
      "- 40 - ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ SER-004 ìš”êµ¬ì‚¬í•­ ëª… ê°œì¸ì •ë³´ì˜ ì²˜ë¦¬ë‹¨ê³„ë³„ ë³´í˜¸ì¡°ì¹˜ ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ë³´ì•ˆ ìš”êµ¬ì‚¬í•­ ìƒì„¸ ì„¤ëª… ì •ì˜ ê°œì¸ì •ë³´ì˜ ì•ˆì „ì„± í™•ë³´ë¥¼ ìœ„í•œ ì²˜ë¦¬ë‹¨ê³„ë³„ ì¡°ì¹˜ì‚¬í•­ ì„¸ë¶€ ë‚´ìš© m ê°œì¸ì •ë³´ ìˆ˜ì§‘ ë° ì´ìš© ëŒ€í•œ ë™ì˜ ê°œì¸ì •ë³´ ë³´í˜¸ë²• ì œ15ì¡°ì œ18ì¡° - ê°œë°œ í˜¹ì€ êµ¬ì¶•í•˜ë ¤ëŠ” ì‹œìŠ¤í…œì´ ê°œì¸ì •ë³´ ìˆ˜ì§‘ì´ìš©ì— ëŒ€í•œ ë™ì˜ê°€ í•„ìš”í•œ ê²½ìš° í™ˆí˜ì´ì§€ íšŒì›ê°€ì…, ê²Œì‹œíŒ ì´ìš© ì‹œ ê°œì¸ì •ë³´ ìˆ˜ì§‘ ë“±, ì•ˆì „í•˜ê²Œ ë°œì£¼ìê°€ ì •ë³´ì£¼ì²´ ë¡œë¶€í„° ê°œì¸ì •ë³´ë¥¼ ìˆ˜ì§‘ì´ìš©í•˜ê¸° ìœ„í•œ í™˜ê²½ì„ ê³ ë ¤í•˜ì—¬ ê°œë°œêµ¬ì¶•í•˜ì—¬ì•¼ í•¨ ê³ ìœ ì‹ë³„ì •ë³´ ë˜ëŠ” ë¯¼ê°ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ìˆ˜ì§‘í•  ê²½ìš°\n",
      "----------------------------------------\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::19::type::text | BM25: 10.00 | Rerank: 10.00 | Combined: 10.00\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::25::type::text | BM25: 5.05 | Rerank: 7.12 | Combined: 6.50\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::17::type::text | BM25: 4.96 | Rerank: 7.12 | Combined: 6.47\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::11::type::text | BM25: 5.37 | Rerank: 5.73 | Combined: 5.62\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::15::type::text | BM25: 4.64 | Rerank: 5.60 | Combined: 5.31\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::22::type::text | BM25: 3.92 | Rerank: 5.69 | Combined: 5.16\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::23::type::text | BM25: 3.94 | Rerank: 5.64 | Combined: 5.13\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::50::type::text | BM25: 0.00 | Rerank: 7.09 | Combined: 4.96\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::24::type::text | BM25: 4.72 | Rerank: 4.29 | Combined: 4.42\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::69::type::text | BM25: 0.00 | Rerank: 5.65 | Combined: 3.95\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::71::type::text | BM25: 4.16 | Rerank: 2.86 | Combined: 3.25\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::52::type::text | BM25: 4.08 | Rerank: 2.88 | Combined: 3.24\n",
      "ğŸ” ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf | Chunk 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::70::type::text | BM25: 0.00 | Rerank: 0.00 | Combined: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 08:42:08,957 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-26 08:42:08,971 - INFO - ğŸ§  LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ (ì†Œìš” ì‹œê°„: 5.73ì´ˆ)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§  LLM ì‘ë‹µ ìƒì„± ì‘ë‹µ:\n",
      "ì„œìš¸íŠ¹ë³„ì‹œ ê³µê³µë°ì´í„° ê°œë°© ë° ì—°ê³„ ê´€ë ¨ ìš”êµ¬ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ê°œë°© ë°ì´í„° ê´€ë¦¬ì²´ê³„**:\n",
      "   - ê°œë°© ë°ì´í„° ì„œë¹„ìŠ¤ì˜ ì—°ì†ì„±ì„ í™•ë³´í•˜ê³ , ê´€ë ¨ ê°œë°© ë°ì´í„° ëª©ë¡ì„ ì‹ë³„í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "   - ê³µê³µë°ì´í„° ì œê³µ ë° ì´ìš© í™œì„±í™”ë¥¼ ìœ„í•œ ë²•ë¥  ë° ì¡°ë¡€ë¥¼ ì¤€ìˆ˜í•˜ë©°, ê°œë°©ëŒ€ìƒ ë°ì´í„°ì— ëŒ€í•´ ì‹œìŠ¤í…œ DB ì—°ê³„ ë“± ê´€ë ¨ ì—…ë¬´ë¥¼ ì§€ì›í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **ì—°ê³„ ë°ì´í„° ê´€ë¦¬ì²´ê³„**:\n",
      "   - ì œê³µê¸°ê´€ê³¼ í™œìš©ê¸°ê´€ ê°„ì˜ ì—°ê³„ ë°ì´í„° ì •í•©ì„±ì„ ìœ ì§€í•˜ê¸° ìœ„í•œ ë°©ì•ˆì„ ì œì‹œí•´ì•¼ í•˜ë©°, ë©”íƒ€ë°ì´í„°ë¥¼ ì‘ì„±í•˜ê³  í‘œì¤€í™”í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "   - ì—°ê³„ ë°ì´í„° í’ˆì§ˆ í™•ë³´ë¥¼ ìœ„í•´ í˜‘ì˜ì²´ë¥¼ êµ¬ì„±í•˜ê³  ì •ê¸°ì ì¸ ë°ì´í„° ì •í•©ì„± ê²€ì¦ì„ ì‹¤ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ë°ì´í„° í‘œì¤€í™” ë° ê´€ë¦¬**:\n",
      "   - ë°ì´í„° í‘œì¤€ ì›ì¹™ ë° ê°€ì´ë“œë¥¼ ìˆ˜ë¦½í•˜ê³ , ë²”ì •ë¶€ ë° ì„œìš¸ì‹œ í‘œì¤€ì„ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "   - ë°ì´í„° í‘œì¤€ ê´€ë¦¬ ë°©ì•ˆì„ ë§ˆë ¨í•˜ì—¬ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ ë“±ì„ í†µí•´ ë³€ê²½ ì´ë ¥ì„ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ì™€ ê°™ì€ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•¨ìœ¼ë¡œì¨ ì„œìš¸íŠ¹ë³„ì‹œì˜ ê³µê³µë°ì´í„° ê°œë°©ê³¼ ì—°ê³„ ì²´ê³„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“ˆ ë°˜í™˜ ë¬¸ì„œ ë‚´ìš©:\n",
      "\n",
      "ğŸ“Š ë©”íƒ€ë°ì´í„° í•„í„°ë§ ê²°ê³¼ (ìµœëŒ€ 10ê°œ):\n",
      "\n",
      "ğŸ“„ ë¬¸ì„œ 1\n",
      "ğŸ”¹ ê³µê³  ë²ˆí˜¸: 20240404154\n",
      "ğŸ”¹ ê³µê³  ì°¨ìˆ˜: 0.0\n",
      "ğŸ”¹ ì‚¬ì—…ëª…: 2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©ì—­\n",
      "ğŸ”¹ ì‚¬ì—… ê¸ˆì•¡: 493763000\n",
      "ğŸ”¹ ë°œì£¼ ê¸°ê´€: ì„œìš¸íŠ¹ë³„ì‹œ\n",
      "ğŸ”¹ ê³µê°œ ì¼ì: 2024-04-02 15:49:39\n",
      "ğŸ”¹ ì…ì°° ì°¸ì—¬ ì‹œì‘ì¼: 2024-04-19 09:00:00\n",
      "ğŸ”¹ ì…ì°° ì°¸ì—¬ ë§ˆê°ì¼: 2024-04-23 16:00:00\n",
      "ğŸ”¹ ì‚¬ì—… ìš”ì•½: - ì‚¬ì—…ê°œìš”: 2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” êµ¬ì¶•\n",
      "- ì¶”ì§„ë°°ê²½ ë° í•„ìš”ì„±: ì™¸ë˜ê´€ê´‘ê° ìœ ì¹˜, ê°œì¸í™” ë° ë¡œì»¬í™”ëœ ê´€ê´‘ íŠ¸ë Œë“œì— ë§ëŠ” ì„œë¹„ìŠ¤ í•„ìš”\n",
      "- ì‚¬ì—…ë²”ìœ„: ë§¤ë ¥ì„œìš¸ì§€ë„ ë‹¤êµ­ì–´ ì„œë¹„ìŠ¤ êµ¬ì¶•, ì§€ë„ì •ë³´ í”Œë«í¼ ê³ ë„í™”, ì‹œê°í™” ì„œë¹„ìŠ¤ ë° ì£¼ì†Œ-ì¢Œí‘œ ë³€í™˜ ê¸°ëŠ¥ ê³ ë„í™”\n",
      "- ê¸°ëŒ€íš¨ê³¼: ì†Œí†µí–‰ì • í˜ì‹ , ì™¸êµ­ì¸ ê´€ê´‘ê° í¸ì˜ ì„œë¹„ìŠ¤ í™•ëŒ€, ë™í–‰ë§¤ë ¥íŠ¹ë³„ì‹œ ì„œìš¸ ì •ì±… í™ë³´, ë‹¤ì–‘í•œ ì§€ë„ ì‹œê°í™” ê¸°ëŠ¥ ì œê³µ\n",
      "ğŸ”¹ íŒŒì¼í˜•ì‹: pdf\n",
      "ğŸ”¹ íŒŒì¼ëª…: ì„œìš¸íŠ¹ë³„ì‹œ_2024ë…„ ì§€ë„ì •ë³´ í”Œë«í¼ ë° ì „ë¬¸í™œìš© ì—°ê³„ ì‹œìŠ¤í…œ ê³ ë„í™” ìš©.pdf\n",
      "ğŸ”¹ ê³µê³ ë²ˆí˜¸_ê²°ì¸¡: False\n",
      "ğŸ”¹ ê³µê³ ì°¨ìˆ˜_ê²°ì¸¡: False\n",
      "ğŸ”¹ ì…ì°°ì°¸ì—¬ì‹œì‘ì¼_ê²°ì¸¡: False\n",
      "ğŸ”¹ ì…ì°°ì°¸ì—¬ë§ˆê°ì¼_ê²°ì¸¡: False\n",
      "ğŸ”¹ ì‚¬ì—…ê¸ˆì•¡_ê²°ì¸¡: False\n",
      "==================================================\n",
      "ë¬¸ì„œ 1 | ì¶œì²˜: 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::19::type::text\n",
      "ğŸ”¹ BM25 ì ìˆ˜: 10.00 | ğŸ”¹ Rerank ì ìˆ˜: 10.00 | ğŸ”¹ Combined: 10.00\n",
      "- 34 - ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ DAR-009 ìš”êµ¬ì‚¬í•­ ëª… ë°ì´í„° ê´€ë¦¬ì²´ê³„ ìˆ˜ë¦½ ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ë°ì´í„° í’ˆì§ˆ ìƒì„¸ ì„¤ëª… ì •ì˜ ë°ì´í„° ê´€ë¦¬ì²´ê³„ ìˆ˜ë¦½ ì„¸ë¶€ ë‚´ìš© ë°ì´í„° ê´€ë¦¬ì²´ê³„ ì •ì˜ - í‘œì¤€, êµ¬ì¡°, ì—°ê³„ ë“± ë°ì´í„° í•µì‹¬ ìš”ì†Œì˜ ì§€ì†ì ì¸ ê´€ë¦¬ë¥¼ ìœ„í•œ ì¡°ì§ê³¼ ì—­í• ì„ ì •ì˜í•˜ì—¬ì•¼ í•¨ - ë°ì´í„° ê°’ì˜ ì§„ë‹¨ ë° ê°œì„  ë“± í’ˆì§ˆê´€ë¦¬ ì¡°ì§ê³¼ ì—­í• ì„ ì •ì˜í•˜ì—¬ì•¼ í•¨ - ë°ì´í„° ê°’ ì§„ë‹¨ ë°©ì•ˆê¸°ëŠ¥, ì§„ë‹¨ í”„ë¡œê·¸ë¨ ë“±ì„ ì œì‹œí•˜ì—¬ì•¼ í•¨ - ë°ì´í„° í‘œì¤€ë‹¨ì–´ìš©ì–´ë„ë©”ì¸ì½”ë“œì˜ ì¶”ê°€, ë³€ê²½, ì‚­ì œ ì ˆì°¨ë¥¼ ìˆ˜ë¦½í•˜ì—¬ì•¼ í•¨. - ë°ì´í„° êµ¬ì¡°ë…¼ë¦¬ë¬¼ë¦¬ì™€ ê´€ë ¨ëœ ì¶”ê°€, ë³€ê²½, ì‚­ì œ ì ˆì°¨ë¥¼ ìˆ˜ë¦½í•˜ì—¬ì•¼ í•¨ - ë°ì´í„° ì—°ê³„ëª©ë¡ ë° í•­ëª©ì˜ ì¶”ê°€, ë³€ê²½, ì‚­ì œ ì ˆì°¨ì˜ ì •ì˜ ì ˆì°¨ë¥¼ ìˆ˜ë¦½í•˜ì—¬ì•¼ í•¨. ì—°ê³„ ì‹œìŠ¤í…œ ë„ì… ì‹œ ì‹œìŠ¤í…œê³¼ ì—°ê³„ëœ ì²´ê³„ ìˆ˜ë¦½ - ì˜¤ë¥˜ ë°ì´í„°ì˜ ì§„ë‹¨ ë° ê°œì„  ì ˆì°¨ë¥¼ ì œì‹œí•˜ì—¬ì•¼ í•¨ ì‚°ì¶œì •ë³´ ë°ì´í„°í‘œì¤€, êµ¬ì¡°, ì—°ê³„, í’ˆì§ˆ ê´€ë¦¬ ì²´ê³„ì„œ ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ DAR-010 ìš”êµ¬ì‚¬í•­ ëª… ì—°ê³„ ë°ì´í„° ê´€ë¦¬ì²´ê³„ ìˆ˜ë¦½ ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ë°ì´í„° í’ˆì§ˆ ìƒì„¸ ì„¤\n",
      "==================================================\n",
      "ë¬¸ì„œ 2 | ì¶œì²˜: 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::25::type::text\n",
      "ğŸ”¹ BM25 ì ìˆ˜: 5.05 | ğŸ”¹ Rerank ì ìˆ˜: 7.12 | ğŸ”¹ Combined: 6.50\n",
      "- 46 - ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ COR-010 ìš”êµ¬ì‚¬í•­ ëª… ì›¹ì‚¬ì´íŠ¸í™ˆí˜ì´ì§€, ëª¨ë°”ì¼ì›¹ì•± ì„œë¹„ìŠ¤ ì´ìš©í˜„í™© ë¶„ì„ì‹œìŠ¤í…œ í™œìš© ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ì œì•½ì‚¬í•­ ìƒì„¸ ì„¤ëª… ì •ì˜ ì„œìš¸ì‹œ í†µí•© ì›¹ì•±ë¡œê·¸ ë¶„ì„ì‹œìŠ¤í…œ í™œìš©ì— ê´€í•œ ì‚¬í•­ ì„¸ë¶€ ë‚´ìš© ì„œìš¸ì‹œ ì›¹ì•±ì„œë¹„ìŠ¤ ì‹ ê·œ êµ¬ì¶• ë° ë¦¬ë‰´ì–¼ ì‹œ í†µí•© ì›¹ì•± ë¡œê·¸ ë¶„ì„ì‹œìŠ¤í…œì„ í™œìš©í•˜ì—¬ ë°©ë¬¸ìì˜ ì´ìš©í˜„í™© ë¶„ì„ì„ ì‹¤ì‹œí•´ì•¼ í•¨ ì‹¤ì‹œê°„ ì›¹ì•±ë¡œê·¸ ìˆ˜ì§‘ ë° ë¶„ì„ì„ ìœ„í•´ ë‰´ë¯¸ë””ì–´ë‹´ë‹¹ê´€í™ˆí˜ì´ì§€íŒ€ì—ì„œ ì œê³µí•˜ëŠ” ê°€ì´ ë“œì— ë”°ë¼ ìŠ¤í¬ë¦½íŠ¸SDK ì ìš© ì‘ì—… ì‹¤ì‹œ - ì‹ ê·œ ì„œë¹„ìŠ¤ ì˜¤í”ˆ ì „ ë˜ëŠ” ì½˜í…ì¸  ì¶”ê°€ë³€ê²½ ì‹œ ëª¨ë“  í˜ì´ì§€ì— í•„ìˆ˜ ì ìš© - PCìš©ì›¹ëª¨ë°”ì¼ì›¹ëª¨ë°”ì¼ì•± ìœ í˜•ì— ë”°ë¼ íŠ¹ì„±ì— ë§ëŠ” ìŠ¤í¬ë¦½íŠ¸SDK ì ìš© í†µí•© ì›¹ì•±ë¡œê·¸ ë¶„ì„ì‹œìŠ¤í…œ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ì›¹ì•±ì‚¬ì´íŠ¸ ê°œì„  ë° ì´ìš©í™œì„±í™” ë°©ì•ˆ ë§ˆ ë ¨ì— í™œìš© - ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼ ë° ë°©ë¬¸ì ì´ë™ê²½ë¡œ ë¶„ì„ ë“± ìë£Œ í™œìš© ì‚°ì¶œì •ë³´ ê´€ë ¨ìš”êµ¬ì‚¬í•­ - ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ COR-011 ìš”êµ¬ì‚¬í•­ ëª… ê°ë¦¬ ëŒ€ì‘ ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ì œì•½ì‚¬í•­ ìƒì„¸ ì„¤ëª… ì •ì˜ ê°ë¦¬ ëŒ€ì‘ì— ê´€í•œ ì‚¬í•­ ì„¸ë¶€ ë‚´\n",
      "==================================================\n",
      "ë¬¸ì„œ 3 | ì¶œì²˜: 20240404154_2024ë…„_ì§€ë„ì •ë³´_í”Œë«í¼_ë°_ì „ë¬¸í™œìš©_ì—°ê³„_ì‹œìŠ¤í…œ_ê³ ë„í™”_ìš©ì—­.json::page::17::type::text\n",
      "ğŸ”¹ BM25 ì ìˆ˜: 4.96 | ğŸ”¹ Rerank ì ìˆ˜: 7.12 | ğŸ”¹ Combined: 6.47\n",
      "- 30 - ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ UIR-001 ìš”êµ¬ì‚¬í•­ ëª… ë§¤ë ¥ì„œìš¸ì§€ë„ UI êµ¬ì„± ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ì¸í„°í˜ì´ìŠ¤ ìš”êµ¬ì‚¬í•­ ìƒì„¸ ì„¤ëª… ì •ì˜ ì‚¬ìš©ì íŠ¹ì„±ì„ ê³ ë ¤í•˜ë˜ ìŠ¤ë§ˆíŠ¸ì„œìš¸ë§µê³¼ í†µì¼ì„± ìˆëŠ” ì§€ë„ í™”ë©´UI ì„¤ê³„ ì„¸ë¶€ ë‚´ìš© m ë§¤ë ¥ì„œìš¸ì§€ë„ í™”ë©´UI êµ¬ì„± - êµ¬ê¸€, ë„¤ì´ë²„ ë“± ì£¼ìš” ì‹œë¯¼ ëŒ€ìƒ ì§€ë„ ì„œë¹„ìŠ¤ UI ë™í–¥ ì¡°ì‚¬4ì¢… ì´ìƒ - ìŠ¤ë§ˆíŠ¸ì„œìš¸ë§µê³¼ í†µì¼ëœ ì§€ë„ ê¸°ëŠ¥ìœ¼ë¡œ êµ¬í˜„í•˜ë˜ ì‚¬ìš©ì íŠ¹ì„±ì„ ê³ ë ¤í•œ ì„¤ê³„ - ìŠ¤ë§ˆíŠ¸í°ê³¼ PCì—ì„œ ì´ì§ˆê° ì—†ëŠ” UI ì œê³µ - ë‹¤êµ­ì–´ ìë™ ë²ˆì—­ì—ë„ ê³µí†µí™œìš© ê°€ëŠ¥í•œ GUI ì±„íƒ ì‚°ì¶œì •ë³´ m êµ­ë‚´ì™¸ ì§€ë„ ì„œë¹„ìŠ¤ UI ë™í–¥ ì¡°ì‚¬ì„œ, í™”ë©´UIì •ì˜ì„œ ê´€ë ¨ìš”êµ¬ì‚¬í•­ SFR-007 5 ë°ì´í„° ìš”êµ¬ì‚¬í•­ ìš”êµ¬ì‚¬í•­ë²ˆí˜¸ DAR-001 ìš”êµ¬ì‚¬í•­ ëª… ë°ì´í„° í‘œì¤€í™” ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜ ë°ì´í„° í’ˆì§ˆ ìƒì„¸ ì„¤ëª… ì •ì˜ ë°ì´í„° í‘œì¤€ ì›ì¹™ ë° ê°€ì´ë“œ ìˆ˜ë¦½ ì„¸ë¶€ ë‚´ìš© ë°ì´í„° í‘œì¤€ ì›ì¹™ ë° ê°€ì´ë“œ ìˆ˜ë¦½ - êµ¬ì¶•ë˜ëŠ” ì‹œìŠ¤í…œì˜ ë°ì´í„° íŠ¹ì„±ì„ ê³ ë ¤í•˜ì—¬ í‘œì¤€í™” ê´€ë¦¬ì²´ê³„ë°ì´í„° í‘œì¤€í™” ì§€ì¹¨ ë° ê°€ì´ë“œ ë“±ë¥¼ ê°œì„ ì •ë¹„í•˜ì—¬ì•¼ í•¨. ë²”ì •ë¶€\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import logging\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from config import Config\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ì„¤ì • ë¡œë“œ\n",
    "    cfg = Config()\n",
    "    \n",
    "    # ê¸°ë³¸ ì„¤ì •\n",
    "    LOAD_MODE = \"json\"\n",
    "    TOKENIZER = \"kiwi\"\n",
    "    \n",
    "    # ë©”íƒ€ë°ì´í„° ë¡œë“œ\n",
    "    meta_df = pd.read_csv(cfg.meta_csv_path)\n",
    "    \n",
    "    # ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "    import torch\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"âœ… ë””ë°”ì´ìŠ¤: {device}\")\n",
    "    \n",
    "    # ëª¨ë¸ ì´ˆê¸°í™” (ì™¸ë¶€ì—ì„œ ë¡œë“œí•˜ì—¬ ìºì‹œí™”)\n",
    "    embedder = HuggingFaceEmbeddings(\n",
    "        model_name=cfg.embedder_model,\n",
    "        model_kwargs={\"device\": device}\n",
    "    )\n",
    "\n",
    "    reranker = RerankModel(\n",
    "        model_name=cfg.reranker_model,\n",
    "        cache_dir=cfg.rerank_cache_dir,\n",
    "        device=device\n",
    "    )\n",
    "        \n",
    "    tokenizer = TokenizerWrapper(TOKENIZER)\n",
    "    \n",
    "    # Retriever ì´ˆê¸°í™” \n",
    "    retriever = Retriever(\n",
    "        meta_df=meta_df,\n",
    "        embedder=embedder,\n",
    "        reranker=reranker,\n",
    "        tokenizer=tokenizer,\n",
    "        persist_directory=cfg.chroma_db_path,\n",
    "        rerank_max_length=cfg.rerank_max_length,\n",
    "        bm25_path=cfg.bm25_path,\n",
    "        debug_mode=True\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # ë¬¸ì„œ ë¡œë”© (ê¸°ì¡´ ë¡œì§ 100% ë³´ì¡´)\n",
    "        if LOAD_MODE == \"json\":\n",
    "            docs = await retriever.load_or_cache_json_docs(\n",
    "                cfg.json_dir, \n",
    "                cache_path=cfg.cached_json_path\n",
    "            )\n",
    "        \n",
    "        # ê°€ì¤‘ì¹˜ ì„¤ì • ë° ë²¡í„° DB êµ¬ì¶• (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "        retriever.set_weights(bm25_weight=0.3, rerank_weight=0.7)\n",
    "        retriever.load_or_build_vector_db(docs)\n",
    "        \n",
    "        # ê²€ìƒ‰ ì‹¤í–‰\n",
    "        query_text = \"ì„œìš¸íŠ¹ë³„ì‹œ ê³µê³µë°ì´í„° ê°œë°©ì´ë‚˜ ì—°ê³„ ê´€ë ¨í•´ì„œ ì–´ë–¤ ìš”êµ¬ì‚¬í•­ì´ ìˆì–´?\"\n",
    "        logging.info(f\"\\n[ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì‹¤í–‰] ì§ˆë¬¸: {query_text}\")\n",
    "        \n",
    "        tokenized_query = retriever.tokenizer.tokenize_korean(query_text)\n",
    "        print(f\"\\nğŸ” BM25 í‚¤ì›Œë“œ í† í°: {tokenized_query}\")\n",
    "        \n",
    "        matched_records, semantic_docs = retriever.smart_search(\n",
    "            query=query_text,\n",
    "            top_k=3,\n",
    "            candidate_size=10,\n",
    "        )\n",
    "\n",
    "        # LLM ì‘ë‹µ ìƒì„±\n",
    "        logging.info(\"ğŸ§  LLM ì‘ë‹µ ìƒì„± ì‹œì‘ì¤‘...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        merged_text = merge_docs_to_text(semantic_docs)\n",
    "        response = qa_chain.invoke({\n",
    "            \"context\": merged_text,\n",
    "            \"question\": query_text\n",
    "        })\n",
    "       \n",
    "        final_answer = response.get(\"text\", \"\").strip()      \n",
    "        print(\"\\nğŸ§  LLM ì‘ë‹µ ìƒì„± ì‘ë‹µ:\")\n",
    "        print(final_answer)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        logging.info(f\"ğŸ§  LLM ì‘ë‹µ ìƒì„± ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ)\")\n",
    "        \n",
    "        print(\"\\nğŸ“ˆ ë°˜í™˜ ë¬¸ì„œ ë‚´ìš©:\")\n",
    "        \n",
    "        # ì°¸ê³ ìš© ë©”íƒ€ë°ì´í„° ì¶œë ¥ (ìµœëŒ€ 10ê°œ)\n",
    "        if matched_records:\n",
    "            print(\"\\nğŸ“Š ë©”íƒ€ë°ì´í„° í•„í„°ë§ ê²°ê³¼ (ìµœëŒ€ 10ê°œ):\")\n",
    "            for i, record in enumerate(matched_records, 1):\n",
    "                print(f\"\\nğŸ“„ ë¬¸ì„œ {i}\")\n",
    "                for key, value in record.items():\n",
    "                    print(f\"ğŸ”¹ {key}: {value}\")\n",
    "                print(\"=\" * 50)\n",
    "        \n",
    "        # ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼\n",
    "        for i, doc in enumerate(results, 1):\n",
    "            key = retriever.get_doc_key(doc)\n",
    "            scores = retriever.last_scores.get(key, {})\n",
    "            bm25 = scores.get(\"bm25\", 0.0)\n",
    "            rerank = scores.get(\"rerank\", 0.0)\n",
    "            combined = scores.get(\"combined\", 0.0)\n",
    "    \n",
    "            print(f\"ë¬¸ì„œ {i} | ì¶œì²˜: {doc.metadata.get('chunk_id')}\")\n",
    "            print(f\"ğŸ”¹ BM25 ì ìˆ˜: {bm25:.2f} | ğŸ”¹ Rerank ì ìˆ˜: {rerank:.2f} | ğŸ”¹ Combined: {combined:.2f}\")\n",
    "            print(doc.page_content[:500])\n",
    "            print(\"=\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"ì˜¤ë¥˜: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd974b48-b167-414e-b255-14412b7d25bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 02:43:04,582 - INFO - \n",
      "[ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì‹¤í–‰] ì§ˆë¬¸: ì‚¬ì—…ê¸ˆì•¡ 100ì–µì´ìƒ ê³µê³  ì•Œë ¤ì¤˜\n",
      "2025-09-26 02:43:04,587 - INFO - ğŸ“Œ ì‚¬ì—… ê¸ˆì•¡ í•„í„° ì ìš©ë¨: 10000000000 (>=)\n",
      "2025-09-26 02:43:04,592 - INFO - ğŸ§  ì¶”ì¶œëœ í•„í„°: {'ì‚¬ì—… ê¸ˆì•¡': {'value': 10000000000, 'operator': '>='}}\n",
      "2025-09-26 02:43:04,594 - INFO - ğŸ” ì˜ë¯¸ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰\n",
      "2025-09-26 02:43:04,595 - INFO - ğŸ” í•˜ì´ë¸Œë¦¬ë“œ í•„í„° ì ìš©: {'ì‚¬ì—… ê¸ˆì•¡': {'value': 10000000000, 'operator': '>='}}\n",
      "2025-09-26 02:43:04,671 - INFO - âœ… ê³ ê¸‰ í•„í„°ë§ í›„ ë¬¸ì„œ ìˆ˜: 0\n",
      "2025-09-26 02:43:04,673 - WARNING - âš ï¸ í•„í„°ë§ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ ê²°ê³¼ì—ì„œ ìƒìœ„ {top_k}ê°œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "2025-09-26 02:43:04,724 - INFO - ğŸ§  ì¬ìˆœìœ„í™” ì ìˆ˜ ê³„ì‚° ì™„ë£Œ (ë³´ë„ˆìŠ¤ í¬í•¨)\n",
      "2025-09-26 02:43:04,725 - INFO - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì ìˆ˜ ì •ë³´\n",
      "2025-09-26 02:43:04,726 - INFO - ğŸ“Š í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: 20 â†’ 3ê°œ ë°˜í™˜\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” BM25 í‚¤ì›Œë“œ í† í°: ['ì‚¬ì—…', 'ê¸ˆì•¡', 'ì´ìƒ', 'ê³µê³ ', 'ì‚¬ì—…ê¸ˆì•¡', 'ê¸ˆì•¡ì´ìƒ', 'ì´ìƒê³µê³ ']\n",
      "ğŸŒ¸ ì²˜ë¦¬ì „ text: 100ì–µ\n",
      "ğŸŒ¸ ì²˜ë¦¬ì™„ë£Œí›„: 10000000000\n",
      "â¤ï¸query_tokens {'ê¸ˆì•¡', 'ì‚¬ì—…', 'ì´ìƒ'}\n",
      "â¤ï¸agency_filter :  None\n",
      "â¤ï¸íŒŒì¼í•„í„°ì‘ë™ \n",
      "â¤ï¸query_tokens {'ê¸ˆì•¡', 'ì‚¬ì—…', 'ì´ìƒ'}\n",
      "â¤ï¸file_filter :  None\n",
      "\n",
      "ğŸ“ˆ BM25 ìƒìœ„ ë¬¸ì„œ ë° ì ìˆ˜:\n",
      "BM25 ë¬¸ì„œ 1 | ì ìˆ˜: 23.7156 | ì¶œì²˜: ì„¸ì¢…í…Œí¬ë…¸íŒŒí¬_ì„¸ì¢…í…Œí¬ë…¸íŒŒí¬ ì¸ì‚¬ì •ë³´ ì „ì‚°ì‹œìŠ¤í…œ êµ¬ì¶• ìš©ì—­ ì…ì°°ê³µ.pdf\n",
      "- 45 - ìƒˆë¡œìš´ ì‹ ìš©í‰ê°€ë“±ê¸‰ì´ ì—†ëŠ” ê²½ìš°ì—ëŠ” í•©ë³‘ ëŒ€ìƒì—…ì²´ ì¤‘ ê°€ì¥ ë‚®ì€ ì‹ ìš©í‰ê°€ë“±ê¸‰ì„ ë°›ì€ ì—…ì²´ì˜ ì‹ ìš©í‰ê°€ë“±ê¸‰ìœ¼ë¡œ í‰ê°€ 2 ìœ ì‚¬ì‚¬ì—… ìˆ˜í–‰ì‹¤ì  í‰ê°€ ë°°ì  ê¸°ì¤€ ë° ìœ ì‚¬ìš©ì—­ ê¸°ì¤€ì€ ì•„ë˜ì™€ ê°™ìŒ í•­ëª© ê³„ì‚° ë°©ë²• ë°°ì í•œë„ ê¸° ì¤€ ë°°ì  ìœ ì‚¬ ì‚¬ì—… ì‹¤ì  ê±´ìˆ˜ ì¤€ê³µì‹¤ì  ê±´ìˆ˜ 4 A. ì‚¬ì—…ìˆ˜í–‰ 5ê±´ ì´ìƒ 4 B. ì‚¬ì—…ìˆ˜í–‰ 4ê±´ ì´ìƒ 3 C. ì‚¬ì—…ìˆ˜í–‰ 3ê±´ ì´ìƒ 2 D. ì‚¬ì—…ìˆ˜í–‰ 2ê±´ ì´ìƒ 1 í•­ëª© ê³„ì‚° ë°©ë²• ë°°ì í•œë„ ê¸° ì¤€ ë°°ì  ìœ ì‚¬ ì‚¬ì—… ì‹¤ì  ê¸ˆì•¡ ë³¸ì‚¬ì—…ë¹„ ì¤€ê³µì‹¤ì ê¸ˆì•¡ 3 A. 200ì´ìƒ 3 B. 100ì´ìƒ - 200ë¯¸ë§Œ 2 C. 100ë¯¸\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 2 | ì ìˆ˜: 21.7840 | ì¶œì²˜: ìˆ˜í˜‘ì¤‘ì•™íšŒ_ê°•ë¦‰ì–´ì„ ì•ˆì „ì¡°ì—…êµ­ ìƒí™©ê´€ì œì‹œìŠ¤í…œ êµ¬ì¶•.pdf\n",
      "- 59 - ë³„ì²¨ 1 ê¸°ìˆ í‰ê°€ê°ê´€ì  í‰ê°€ê¸°ì¤€ ë° ì±„ì í‘œ í‰ ê°€ ìœ„ ì› ì„± ëª… ì„œëª… ì œì•ˆì—…ì²´ëª… ê°€. ê²½ì˜ìƒíƒœ í‰ê°€í•­ëª© í‰ ê°€ ìš” ì†Œ ë°°ì  ê¸°ì¤€ ê²½ì˜ìƒíƒœ íšŒì‚¬ì±„ì— ëŒ€í•œ ì‹ ìš©í‰ê°€ë“±ê¸‰ AAA 5.0 AA, AA0, AA- 4.5 A, A0, A- 4.0 BBB 3.5 BBB0, BBB- 3.0 BB, BB0 2.5 BB- 2.0 B, B0 1.5 B- 1.0 CCC ì´í•˜ 0.5 ë‚˜. ìœ ì‚¬ìš©ì—­ì‹¤ì  í‰ê°€í•­ëª© í‰ ê°€ ìš” ì†Œ ë°°ì  ê¸°ì¤€ ìœ ì‚¬ ë¶„ì•¼ì—ì„œì˜ ìœ ì§€ë³´ìˆ˜ ê²½í—˜ ìš©ì—­ ë˜ëŠ” êµ¬ì¶• ê²½í—˜ì‹¤ì  ìµœê·¼3ë…„ ìœ ì‚¬ì‚¬ì—… ìˆ˜í–‰ì‹¤ì  ì´ê¸ˆì•¡ 12ì–µ ì´ìƒ 10 ìœ ì‚¬\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 3 | ì ìˆ˜: 19.5945 | ì¶œì²˜: ì¶•ì‚°ë¬¼í’ˆì§ˆí‰ê°€ì›_ì¶•ì‚°ë¬¼ì´ë ¥ê´€ë¦¬ì‹œìŠ¤í…œ ê°œì„ (ì •ë³´í™” ì‚¬ì—…).pdf\n",
      "- 45 - ë³¸ ì‚¬ì—… ê³¼ì—…ì˜ ì¼ë¶€ë¥¼ í•˜ë„ê¸‰ í•˜ë ¤ëŠ” ê²½ìš° ì…ì°° ë° ê³„ì•½ì²´ê²° ì‹œ ì†Œ í”„íŠ¸ì›¨ì–´ì‚¬ì—… ê³„ì•½ ë° ê´€ë¦¬ê°ë…ì— ê´€í•œ ì§€ì¹¨ì œ19ì¡°ì— ë”°ë¥¸ ì†Œí”„íŠ¸ì›¨ ì–´ í•˜ë„ê¸‰ ê³„íšì„œë¥¼ ì œì¶œí•˜ì—¬ì•¼ í•¨ í•˜ë„ê¸‰ê³„ì•½ì˜ ìŠ¹ì¸ì„ ì‹ ì²­í•˜ëŠ” ê²½ìš°, ì†Œí”„íŠ¸ì›¨ì–´ì‚¬ì—… ê³„ì•½ ë° ê´€ë¦¬ê° ë…ì— ê´€í•œ ì§€ì¹¨ì œ19ì¡°ì— ë”°ë¥¸ í•˜ë„ê¸‰ê³„ì•½ì˜ ì ì •ì„±íŒë‹¨ ì„¸ë¶€ê¸°ì¤€ì— ì˜ê±°í•˜ì—¬, í‰ê°€ì ìˆ˜ê°€ 85ì  ì´ìƒì¸ ê²½ìš°ì— í•œí•˜ì—¬ í•˜ë„ê¸‰ ê³„ì•½ì„ ìŠ¹ì¸ í•¨. ë‹¤ë§Œ, 85ì  ì´ìƒì¸ ê²½ìš°ë¼ í•˜ë”ë¼ë„ í•˜ë„ê¸‰ ê³„ì•½ì˜ ì„¸ë¶€ ì¡°ê±´ ë“± ìœ¼ë¡œ ì¸í•˜ì—¬ ì‚¬ì—…ì˜ ì›í™œí•œ ìˆ˜í–‰ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤ê³  ì¸ì •ë˜ëŠ” ê²½ìš° ê·¸ ì‚¬ìœ ë¥¼ ê¸°ì¬í•˜ì—¬ í•˜ë„\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 4 | ì ìˆ˜: 19.3042 | ì¶œì²˜: ë‚¨ì„œìš¸ëŒ€í•™êµ_[í˜ì‹ -êµ­ê³ ] ë‚¨ì„œìš¸ëŒ€í•™êµ ìŠ¤ë§ˆíŠ¸ ì •ë³´ì‹œìŠ¤í…œ í™œì„±í™”(í•™ì‚¬.pdf\n",
      "- 29 - ì œì•ˆì‚¬ëŠ” ì¢…ì „ì˜ì†Œí”„íŠ¸ì›¨ì–´ì‚°ì—… ì§„í¥ë²•ì œ24ì¡° ë“±ì— ë”°ë¼ ìµœê·¼ë…„ë„ ê²°ì‚° ì‹ ê³ ëœ ì†Œí”„íŠ¸ì›¨ì–´ì‚¬ì—…ì ì‹ ê³ í™•ì¸ì„œí˜¹ì€ ê°œì • ë²•ë ¹ì†Œí”„íŠ¸ì›¨ì–´ ì§„í¥ë²•ì œ58ì¡°ì œ2í•­ ë° ê°™ì€ ë²• ì‹œí–‰ê·œì¹™ ì œ17ì¡°ì— ë”°ë¥¸ ì†Œí”„íŠ¸ì›¨ì–´ì‚¬ì—…ì ì¼ë°˜ í˜„í™© ê´€ë¦¬í™•ì¸ì„œë¥¼ ì œì¶œí•˜ì—¬ì•¼ í•¨ ìƒí˜¸ì¶œìì œí•œê¸°ì—…ì§‘ë‹¨ ì†Œì†ê¸°ì—… ë° ëŒ€ê¸°ì—… ì°¸ì—¬ì œí•œ -ì†Œí”„íŠ¸ì›¨ì–´ ì§„í¥ë²•ì œ48ì¤‘ì†Œ ì†Œí”„íŠ¸ì›¨ì–´ì‚¬ì—…ìì˜ ì‚¬ì—…ì°¸ì—¬ ì§€ì› ì œ4í•­ì— ë”°ë¼ ìƒí˜¸ì¶œìì œí•œê¸°ì—…ì§‘ë‹¨ì— ì†í•˜ëŠ” ì—…ì²´ëŠ” ì…ì°° ì°¸ì—¬ë¥¼ì œí•œí•¨ - ë³¸ ì‚¬ì—…ì€ 20ì–µ ë¯¸ë§Œì˜ ì‚¬ì—…ìœ¼ë¡œì¨,ì†Œí”„íŠ¸ì›¨ì–´ ì§„í¥ë²•ì œ48ì¡° ì¤‘ì†Œ ì†Œí”„íŠ¸ì›¨ì–´ì‚¬ì—…ìì˜ ì‚¬ì—…ì°¸ì—¬ ì§€ì› ì œ2í•­ ë°\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 5 | ì ìˆ˜: 18.9402 | ì¶œì²˜: ê²½ìƒë¶ë„ ë´‰í™”êµ°_ë´‰í™”êµ° ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ ê³ ë„í™” ì‚¬ì—…(í˜‘ìƒ)(ê¸´ê¸‰).pdf\n",
      "- 64 - ë³„ì§€ì„œì‹ 7í˜¸ ì‚¬ì—…ìˆ˜í–‰ ì‹¤ì ì¦ëª…ì„œ ì‹  ì²­ ì¸ ì—…ì²´ëª… ëŒ€ í‘œ ì ì˜ì—…ì†Œì¬ì§€ ì „í™”ë²ˆí˜¸ ì‚¬ì—…ìë²ˆí˜¸ ë²•ì¸ë“±ë¡ë²ˆí˜¸ ì¦ëª…ì„œ ìš©ë„ ì…ì°° ë° ì œì•ˆì„œ ì‹¬ì‚¬ ì œì¶œìš© ì œ ì¶œ ì²˜ êµ­ê°€ê¸°ê´€, ì§€ë°©ìì¹˜ë‹¨ì²´ ë° ê³µê³µê¸°ê´€ ì‚¬ì—…ì´í–‰ ì‹¤ì ë‚´ìš© ì‚¬ ì—… ëª… êµ¬ ë¶„ ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œ ìœ ì§€ê´€ë¦¬ìš´ì˜ìœ„íƒ ì •ë³´í†µì‹  ê¸°íƒ€ ì‚¬ì—…ê°œìš” ì‚¬ì—…ê¸ˆì•¡ VAT í¬í•¨ ê³„ì•½ì¼ìê³„ì•½ê¸°ê°„ ê³„ì•½ê¸ˆì•¡ VAT í¬í•¨ ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œ ë¶„ì•¼ ìš©ì—­ì´í–‰ ì‹¤ì  ì™„ë£Œì¼ì ë¹„ìœ¨ ì‹¤ì ì› ì¦ ëª… ì„œ ë°œê¸‰ê¸°ê´€ ìœ„ ì‚¬ì‹¤ì„ ì¦ëª…í•¨. ë…„ ì›” ì¼ ê¸°ê´€ëª… ì¸ ì „í™”ë²ˆí˜¸ ì£¼ ì†Œ ë°œê¸‰ë¶€ì„œ ë‹´ë‹¹ì ì „í™”ë²ˆí˜¸ ì‚¬ì—…ìˆ˜í–‰ì‹¤ì ì€ ì…ì°°ê³µê³ ì¼ \n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 6 | ì ìˆ˜: 18.7667 | ì¶œì²˜: í•œêµ­ê±´ê°•ê°€ì •ì§„í¥ì›_2025ë…„ ì•„ì´ëŒë´„ì¸ë ¥ ì¸ì ì„± ê²€ì‚¬ ì •ë³´ì‹œìŠ¤í…œ ìš´ì˜.pdf\n",
      "- 38 - ë³´í˜¸ ë° ì§€ì›ì— ê´€í•œ ë²•ë¥ ì œ2ì¡°ì— ë”°ë¥¸ ì†Œìƒê³µì¸ìœ¼ë¡œì„œì¤‘ì†Œ ê¸°ì—… ë²”ìœ„ ë° í™•ì¸ì— ê´€í•œ ê·œì •ì— ë”°ë¼ ë°œê¸‰ëœ ì¤‘ì†Œê¸°ì—… ì†Œìƒê³µì¸ í™•ì¸ì„œë¥¼ ì†Œì§€í•œ ì—…ì²´ì…ì°° ì°¸ê°€ ë§ˆê°ì¼ ì „ì¼ê¹Œì§€ ë°œ ê¸‰ëœ ê²ƒìœ¼ë¡œ ìœ íš¨ê¸°ê°„ ë‚´ì— í•œí•¨ á„‹ ì¤‘ì†Œê¸°ì—…ì œí’ˆ êµ¬ë§¤ì´‰ì§„ ë° íŒë¡œì§€ì›ì— ê´€í•œ ë²•ë¥ ì— ì˜í•œ ì¤‘ì†Œê¸° ì—…ìë¡œì„œì¤‘ì†Œê¸°ì—…ìê°„ ê²½ìŸì œí’ˆ ì§ì ‘ìƒì‚° í™•ì¸ê¸°ì¤€ì¤‘ì†Œë²¤ì²˜ ê¸°ì—…ë¶€ ê³ ì‹œì— ë”°ë¼ ì§ì ‘ìƒì‚°í™•ì¸ì¦ëª…ì„œì •ë³´ì‹œìŠ¤í…œìœ ì§€ê´€ë¦¬ì„œ ë¹„ìŠ¤,ì„¸ë¶€í’ˆëª…ë²ˆí˜¸ 8111189901ë¥¼ ì†Œì§€í•œ ì—…ì²´ì…ì°°ì°¸ê°€ë“±ë¡ ë§ˆê°ì¼ ì´ì „ ë°œí–‰ëœ ê²ƒìœ¼ë¡œ ìœ íš¨ê¸°ê°„ ë‚´ì— ìˆì–´ì•¼ í•¨ á„‹ ìƒí˜¸ì¶œìì œí•œê¸°ì—…ì§‘ë‹¨ ì†Œì†ê¸°ì—… \n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 7 | ì ìˆ˜: 18.6964 | ì¶œì²˜: í•œêµ­ë†ì–´ì´Œê³µì‚¬_ì•„ì„¸ì•ˆ+3 ì‹ëŸ‰ì•ˆë³´ì •ë³´ì‹œìŠ¤í…œ(AFSIS) 3ë‹¨ê³„ í˜‘ë ¥(ìº„ë³´ë””ì•„.pdf\n",
      "- 65 - 2 íšŒì‚¬ ìœ ì‚¬ì‚¬ì—… ìˆ˜í–‰ì‹¤ì  5ì  ì‹¤ì ì¸ì •ë²”ìœ„ ê³µê³ ì¼ ê¸°ì¤€ ìµœê·¼ 20ë…„ ì´ë‚´ì™„ë£Œí•œ ì‹¤ì  - ì§„í–‰ ì¤‘ì¸ ì‚¬ì—… ì‹¤ì  ë¶ˆì¸ì • - ì‹¤ì ì¦ëª…ì„œ ë¯¸ì œì¶œ ì‹œ ì‹¤ì  ë¶ˆì¸ì • ê³µë™ìœ¼ë¡œ ìˆ˜í–‰í•œ ì‹¤ì ì˜ ê²½ìš°, ì œì•ˆ ì—…ì²´ì˜ ì°¸ì—¬ì§€ë¶„ìœ¨ì„ ê³±í•˜ì—¬ ì‚°ì •í•œ ê¸ˆì•¡ë˜ëŠ” ë¶„ë‹´ë¶€ë¶„ì— í•´ë‹¹ë˜ëŠ” ê¸ˆì•¡ì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ì—¬ì•¼ í•¨ ê³µë™ìˆ˜ê¸‰ì²´ êµ¬ì„± ì‹œ êµ¬ì„±ì›ë³„ ìˆ˜í–‰ ì‹¤ì ì— ì œì•ˆ ì—…ì²´ì˜ ì‚¬ì—… ì°¸ì—¬ ì§€ë¶„ ìœ¨ì„ê³±í•˜ì—¬ ì‚°ì •í•œ í›„, ì´ë¥¼ í•©ì‚°í•˜ì—¬ í‰ê°€ ìœ ì‚¬ì‚¬ì—… 1ë…„ ì´ìƒ í”„ë¡œì íŠ¸ì„± í•´ì™¸ì‚¬ì—…ìœ¼ë¡œì„œ ì•„ë˜ ì¡°ê±´ ì¤‘ ìµœì†Œ í•œ ê°€ì§€ë¥¼ ë§Œì¡±í•˜ëŠ” ì‚¬ì—… - ì •ë³´ì‹œìŠ¤í…œì‚¬ì—…, ìˆ˜ì¹˜ì§€ë„ì œì‘ì—…, ì†Œí”„íŠ¸\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 8 | ì ìˆ˜: 18.3382 | ì¶œì²˜: ê²½ìƒë¶ë„ ë´‰í™”êµ°_ë´‰í™”êµ° ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ ê³ ë„í™” ì‚¬ì—…(í˜‘ìƒ)(ê¸´ê¸‰).pdf\n",
      "- 59 - ë³„ì§€ì„œì‹ 2í˜¸ ì… ì°° ì°¸ ê°€ ì‹  ì²­ ì„œ ì… ì°° ì…ì°°ê³µê³ ë²ˆí˜¸ ë´‰í™”êµ° ê³µê³  ì œ20 - í˜¸ ì… ì°° ì¼ ì 20 . . . ì… ì°° ê±´ ëª… ì… ì°° ë³´ ì¦ ê¸ˆ ë³´ì¦ê¸ˆì•¡ ê¸ˆ ì›ì • ì› ì‚¬ ìš© ì¸ ê° ë³¸ ê±´ì˜ ì…ì°° ë° ê³„ì•½ì— ì‚¬ìš©í•  ì¸ê°ì„ ë‹¤ìŒê³¼ ê°™ì´ ì‹ ê³ í•©ë‹ˆë‹¤. ë³´ì¦ê¸ˆìœ¨ ì…ì°°ê¸ˆì•¡ì˜ 5100 ì´ìƒ ë‚©ë¶€ë©´ì œ ë° ì§€ê¸‰í™•ì•½ ë³¸ì¸ì€ ë‚™ì°° í›„ ê³„ì•½ ë¯¸ì²´ê²°ì‹œ ë‚™ì°°ê¸ˆì•¡ì— í•´ë‹¹í•˜ëŠ” ì†Œì •ì˜ ì…ì°°ë³´ì¦ê¸ˆì„ í˜„ê¸ˆìœ¼ë¡œ ë‚©ë¶€í•  ê²ƒì„ í™•ì•½í•¨ ëŒ€ ë¦¬ ì¸ ë³¸ ì…ì°°ì— ê´€í•œ ì¼ì²´ ê¶Œí•œì„ ë‹¤ìŒì˜ ìì—ê²Œ ìœ„ì„í•©ë‹ˆë‹¤. ì†Œì† ì „í™”ë²ˆí˜¸ ì„±ëª… ìƒë…„ì›”ì¼ 20 ë…„ ì›” ì¼ìë¡œ ê³µê³ í•œ \n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 9 | ì ìˆ˜: 18.1726 | ì¶œì²˜: í•œêµ­ìˆ˜ì¶œì…ì€í–‰_(ê¸´ê¸‰) ëª¨ì ë¹„í¬ ë§ˆí‘¸í†  ì§€ëŠ¥í˜•êµí†µì‹œìŠ¤í…œ(ITS) êµ¬ì¶•ì‚¬ì—….pdf\n",
      "- 61 - ì„œì‹ 1 ì… ì°° ì°¸ ê°€ ì‹  ì²­ ì„œ ì‹  ì²­ ì¸ ìƒí˜¸ ë° ë²•ì¸ëª…ì¹­ ë²•ì¸ë“±ë¡ë²ˆí˜¸ ì£¼ ì†Œ ì „ í™” ë²ˆ í˜¸ ëŒ€ í‘œ ì ìƒ ë…„ ì›” ì¼ ì…ì°° ê°œìš” ì…ì°°ê³µê³ ì§€ëª… ë²ˆí˜¸ - ì… ì°° ì¼ ì ì… ì°° ê±´ ëª… ì‚¬ ì—… ëª…FS ìš©ì—­ ì… ì°° ë³´ ì¦ ê¸ˆ ë‚© ë¶€ ë³´ ì¦ ì•¡ ì…ì°°ê¸ˆì•¡ì˜ 1000ë¶„ì˜ 25ì´ìƒ ë³´ì¦ê¸ˆë‚©ë¶€ë°©ë²• ì‘ì„±ì˜ˆì‹œ ì…ì°°ë³´ì¦ê¸ˆ ì§€ê¸‰ê°ì„œ ì œì¶œ ë‚© ë¶€ ë©´ ì œ ë° ì§€ ê¸‰ í™• ì•½ ì‘ì„± ì˜ˆì‹œ, ë¶ˆí•„ìš”ì‹œ ì‚­ì œ ìš”ë§ ë³¸ì¸ì€ ë‚™ì°° í›„ ê³„ì•½ ë¯¸ì²´ê²°ì‹œ ê·€ ì€í–‰ì— ì…ì°°ë³´ì¦ê¸ˆì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ì„ í˜„ê¸ˆìœ¼ë¡œ ë‚©ì…í•  ê²ƒì„ í™•ì•½í•©ë‹ˆë‹¤. ì…ì°° ì°¸ì—¬ëŒ€ë¦¬ì¸ì‚¬ìš©ì¸ê° ë³¸ ì…ì°°ì— ê´€í•œ\n",
      "----------------------------------------\n",
      "BM25 ë¬¸ì„œ 10 | ì ìˆ˜: 18.0688 | ì¶œì²˜: í•œêµ­ë³´ìœ¡ì§„í¥ì›_ì—°ì°¨ë³„ ììœ¨ í’ˆì§ˆê´€ë¦¬ ì‹œìŠ¤í…œ ê¸°ëŠ¥ê°œì„ .pdf\n",
      "- 75 - ë³„í‘œ 2 ë³´ì•ˆ ìœ„ì•½ê¸ˆ ë¶€ê³¼ ê¸°ì¤€ ë³´ì•ˆ ìœ„ì•½ê¸ˆ ë¶€ê³¼ ê¸°ì¤€ 1. ìœ„ê·œ ìˆ˜ì¤€ë³„ë¡œ AD ë“±ê¸‰ìœ¼ë¡œ ì°¨ë“± ë¶€ê³¼ êµ¬ë¶„ ìœ„ê·œ ìˆ˜ì¤€ Aê¸‰ Bê¸‰ Cê¸‰ Dê¸‰ ìœ„ê·œ ì‹¬ê° 1ê±´ ì¤‘ëŒ€ 1ê±´ ì´ìƒ ë¯¸í¡ 2ê±´ ì´ìƒ ê²½ë¯¸ 3ê±´ ì´ìƒ ì œì¬ ë° ìœ„ì•½ê¸ˆ ë¶€ì •ë‹¹ì—…ì ë“±ë¡ ì‚¬ì—…ê¸ˆì•¡ì˜ 0.027 ì‚¬ì—…ê¸ˆì•¡ì˜ 0.021 ì‚¬ì—…ê¸ˆì•¡ì˜ 0.015 ìœ„ì•½ê¸ˆì€ ë§¤ ì ê²€ ë˜ëŠ” ë³´ì•ˆ ì‚¬ê³  ì ë°œ, ë³´ì•ˆ ì‚¬ê³  ë°œìƒ ë³„ë¡œ ë¶€ê³¼ ìœ„ê·œ ìˆ˜ì¤€ì€ ë³„í‘œ1 ì°¸ê³  2. ë³´ì•ˆ ìœ„ì•½ê¸ˆì€ ë‹¤ë¥¸ ìš”ì¸ì— ì˜í•´ ìƒì‡„, ì‚­ê°ì´ ë˜ì§€ ì•Šë„ë¡ ë¶€ê³¼ ë³´ì•ˆì‚¬ê³ ì‹¬ê°ëŠ” 1íšŒì˜ ì‚¬ê³ ë§Œìœ¼ë¡œë„ ê·¸ íŒŒê¸‰ë ¥ì´ í° ê²ƒì„ ê°ì•ˆí•˜ì—¬\n",
      "----------------------------------------\n",
      "ğŸ” ì„¸ì¢…í…Œí¬ë…¸íŒŒí¬_ì„¸ì¢…í…Œí¬ë…¸íŒŒí¬ ì¸ì‚¬ì •ë³´ ì „ì‚°ì‹œìŠ¤í…œ êµ¬ì¶• ìš©ì—­ ì…ì°°ê³µ.pdf | Chunk Unknown_88_ì„¸ì¢…í…Œí¬ë…¸íŒŒí¬_ì¸ì‚¬ì •ë³´_ì „ì‚°ì‹œìŠ¤í…œ_êµ¬ì¶•_ìš©ì—­_ì…ì°°ê³µê³ [ê¸´ê¸‰].json::page::48::type::text | BM25: 10.00 | Rerank: 9.83 | Combined: 9.88\n",
      "ğŸ” ê²½ìƒë¶ë„ ë´‰í™”êµ°_ë´‰í™”êµ° ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ ê³ ë„í™” ì‚¬ì—…(í˜‘ìƒ)(ê¸´ê¸‰).pdf | Chunk 20240430896_ë´‰í™”êµ°_ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ_ê³ ë„í™”_ì‚¬ì—…(í˜‘ìƒ)(ê¸´ê¸‰).json::page::68::type::text | BM25: 7.99 | Rerank: 10.00 | Combined: 9.40\n",
      "ğŸ” í•œêµ­ê±´ê°•ê°€ì •ì§„í¥ì›_2025ë…„ ì•„ì´ëŒë´„ì¸ë ¥ ì¸ì ì„± ê²€ì‚¬ ì •ë³´ì‹œìŠ¤í…œ ìš´ì˜.pdf | Chunk 20241218257_2025ë…„_ì•„ì´ëŒë´„ì¸ë ¥_ì¸ì ì„±_ê²€ì‚¬_ì •ë³´ì‹œìŠ¤í…œ_ìš´ì˜.json::page::40::type::text | BM25: 7.91 | Rerank: 9.75 | Combined: 9.20\n",
      "ğŸ” ì¶•ì‚°ë¬¼í’ˆì§ˆí‰ê°€ì›_ì¶•ì‚°ë¬¼ì´ë ¥ê´€ë¦¬ì‹œìŠ¤í…œ ê°œì„ (ì •ë³´í™” ì‚¬ì—…).pdf | Chunk 20240523741_ì¶•ì‚°ë¬¼ì´ë ¥ê´€ë¦¬ì‹œìŠ¤í…œ_ê°œì„ (ì •ë³´í™”_ì‚¬ì—…).json::page::48::type::text | BM25: 8.26 | Rerank: 7.36 | Combined: 7.63\n",
      "ğŸ” ê²½ìƒë¶ë„ ë´‰í™”êµ°_ë´‰í™”êµ° ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ ê³ ë„í™” ì‚¬ì—…(í˜‘ìƒ)(ê¸´ê¸‰).pdf | Chunk 20240430896_ë´‰í™”êµ°_ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ_ê³ ë„í™”_ì‚¬ì—…(í˜‘ìƒ)(ê¸´ê¸‰).json::page::63::type::text | BM25: 7.73 | Rerank: 7.56 | Combined: 7.61\n",
      "ğŸ” ë‚¨ì„œìš¸ëŒ€í•™êµ_[í˜ì‹ -êµ­ê³ ] ë‚¨ì„œìš¸ëŒ€í•™êµ ìŠ¤ë§ˆíŠ¸ ì •ë³´ì‹œìŠ¤í…œ í™œì„±í™”(í•™ì‚¬.pdf | Chunk 20241015084_[í˜ì‹ -êµ­ê³ ]_ë‚¨ì„œìš¸ëŒ€í•™êµ_ìŠ¤ë§ˆíŠ¸_ì •ë³´ì‹œìŠ¤í…œ_í™œì„±í™”(í•™ì‚¬í–‰ì •_ì•”í˜¸í™”)_ê°œë°œ_ìš©ì—­_ì…ì°°.json::page::17::type::text | BM25: 8.14 | Rerank: 7.35 | Combined: 7.59\n",
      "ğŸ” í•œêµ­ìˆ˜ì¶œì…ì€í–‰_(ê¸´ê¸‰) ëª¨ì ë¹„í¬ ë§ˆí‘¸í†  ì§€ëŠ¥í˜•êµí†µì‹œìŠ¤í…œ(ITS) êµ¬ì¶•ì‚¬ì—….pdf | Chunk 20240925413_(ê¸´ê¸‰)_ëª¨ì ë¹„í¬_ë§ˆí‘¸í† _ì§€ëŠ¥í˜•êµí†µì‹œìŠ¤í…œ(ITS)_êµ¬ì¶•ì‚¬ì—…_ì‚¬ì—…íƒ€ë‹¹ì„±ì¡°ì‚¬(F_S)_ìš©ì—­.json::page::63::type::text | BM25: 7.66 | Rerank: 7.50 | Combined: 7.55\n",
      "ğŸ” í•œêµ­ë†ì–´ì´Œê³µì‚¬_ì•„ì„¸ì•ˆ+3 ì‹ëŸ‰ì•ˆë³´ì •ë³´ì‹œìŠ¤í…œ(AFSIS) 3ë‹¨ê³„ í˜‘ë ¥(ìº„ë³´ë””ì•„.pdf | Chunk R25BK00601569_ì•„ì„¸ì•ˆ+3_ì‹ëŸ‰ì•ˆë³´ì •ë³´ì‹œìŠ¤í…œ(AFSIS)_3ë‹¨ê³„_í˜‘ë ¥(ìº„ë³´ë””ì•„)ì‚¬ì—…_PMC_ìš©ì—­.json::page::68::type::text | BM25: 7.88 | Rerank: 7.36 | Combined: 7.52\n",
      "ğŸ” í•œêµ­ë³´ìœ¡ì§„í¥ì›_ì—°ì°¨ë³„ ììœ¨ í’ˆì§ˆê´€ë¦¬ ì‹œìŠ¤í…œ ê¸°ëŠ¥ê°œì„ .pdf | Chunk 20240429895_ì—°ì°¨ë³„_ììœ¨_í’ˆì§ˆê´€ë¦¬_ì‹œìŠ¤í…œ_ê¸°ëŠ¥ê°œì„ .json::page::77::type::text | BM25: 7.62 | Rerank: 7.42 | Combined: 7.48\n",
      "ğŸ” í•œêµ­ë³´ìœ¡ì§„í¥ì›_ì—°ì°¨ë³„ ììœ¨ í’ˆì§ˆê´€ë¦¬ ì‹œìŠ¤í…œ ê¸°ëŠ¥ê°œì„ .pdf | Chunk 20240429895_ì—°ì°¨ë³„_ììœ¨_í’ˆì§ˆê´€ë¦¬_ì‹œìŠ¤í…œ_ê¸°ëŠ¥ê°œì„ .json::page::38::type::text | BM25: 0.00 | Rerank: 9.79 | Combined: 6.85\n",
      "ğŸ” ìˆ˜í˜‘ì¤‘ì•™íšŒ_ê°•ë¦‰ì–´ì„ ì•ˆì „ì¡°ì—…êµ­ ìƒí™©ê´€ì œì‹œìŠ¤í…œ êµ¬ì¶•.pdf | Chunk R25BK00632248_ê°•ë¦‰ì–´ì„ ì•ˆì „ì¡°ì—…êµ­_ìƒí™©ê´€ì œì‹œìŠ¤í…œ_êµ¬ì¶•.json::page::61::type::text | BM25: 9.19 | Rerank: 4.94 | Combined: 6.21\n",
      "ğŸ” í•œêµ­í•´ì–‘ì¡°ì‚¬í˜‘íšŒ_2024ë…„ í•­í•´ìš© ê°„í–‰ë¬¼ í’ˆì§ˆê´€ë¦¬ ì—…ë¬´ë³´ì¡° ì‹œìŠ¤í…œ êµ¬ì¶•.pdf | Chunk 20240612475_2024ë…„_í•­í•´ìš©_ê°„í–‰ë¬¼_í’ˆì§ˆê´€ë¦¬_ì—…ë¬´ë³´ì¡°_ì‹œìŠ¤í…œ_êµ¬ì¶•.json::page::60::type::text | BM25: 0.00 | Rerank: 7.58 | Combined: 5.31\n",
      "ğŸ” ì„œìš¸ì‹œë¦½ëŒ€í•™êµ_[ì‚¬ì „ê³µê°œ] í•™ì—…ì„±ì·¨ë„ ë‹¤ì°¨ì› ì¢…ë‹¨ë¶„ì„ í†µí•©ì‹œìŠ¤í…œ 1ì°¨.pdf | Chunk Unknown_12_[ì‚¬ì „ê³µê°œ]_í•™ì—…ì„±ì·¨ë„_ë‹¤ì°¨ì›_ì¢…ë‹¨ë¶„ì„_í†µí•©ì‹œìŠ¤í…œ_1ì°¨_ê³ ë„í™”_ìš©ì—­.json::page::1::type::text | BM25: 0.00 | Rerank: 7.47 | Combined: 5.23\n",
      "ğŸ” (ì‚¬)ë²¤ì²˜ê¸°ì—…í˜‘íšŒ_2024ë…„ ë²¤ì²˜í™•ì¸ì¢…í•©ê´€ë¦¬ì‹œìŠ¤í…œ ê¸°ëŠ¥ ê³ ë„í™” ìš©ì—­ì‚¬ì—… .pdf | Chunk 20240330003_2024ë…„_ë²¤ì²˜í™•ì¸ì¢…í•©ê´€ë¦¬ì‹œìŠ¤í…œ_ê¸°ëŠ¥_ê³ ë„í™”_ìš©ì—­ì‚¬ì—…_ì…ì°°ê³µê³ .json::page::4::type::text | BM25: 0.00 | Rerank: 5.12 | Combined: 3.58\n",
      "ğŸ” í•œêµ­ìƒì‚°ê¸°ìˆ ì—°êµ¬ì›_EIP3.0 ê³ ì••ê°€ìŠ¤ ì•ˆì „ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶• ìš©ì—­.pdf | Chunk 20240827859_EIP3.0_ê³ ì••ê°€ìŠ¤_ì•ˆì „ê´€ë¦¬_ì‹œìŠ¤í…œ_êµ¬ì¶•_ìš©ì—­.json::page::15::type::text | BM25: 0.00 | Rerank: 5.01 | Combined: 3.51\n",
      "ğŸ” êµ­ë¦½ì¤‘ì•™ì˜ë£Œì›_(ê¸´ê¸‰)ã€Œ2024ë…„ë„ ì°¨ì„¸ëŒ€ ì‘ê¸‰ì˜ë£Œ ìƒí™©ê´€ë¦¬ì‹œìŠ¤í…œ êµ¬ì¶•.pdf | Chunk 20240531542_(ê¸´ê¸‰)ã€Œ2024ë…„ë„_ì°¨ì„¸ëŒ€_ì‘ê¸‰ì˜ë£Œ_ìƒí™©ê´€ë¦¬ì‹œìŠ¤í…œ_êµ¬ì¶•ã€_ìœ„íƒìš©ì—­.json::page::7::type::text | BM25: 0.00 | Rerank: 4.94 | Combined: 3.46\n",
      "ğŸ” êµ­ë¯¼ì—°ê¸ˆê³µë‹¨_ì‚¬ì—…ì¥ ì‚¬íšŒë³´í—˜ë£Œ ì§€ì› ê³ ì‹œ ê°œì •ì— ë”°ë¥¸ ì •ë³´ì‹œìŠ¤í…œ ë³´.pdf | Chunk Unknown_49_ì‚¬ì—…ì¥_ì‚¬íšŒë³´í—˜ë£Œ_ì§€ì›_ê³ ì‹œ_ê°œì •ì—_ë”°ë¥¸_ì •ë³´ì‹œìŠ¤í…œ_ë³´ì™„_ê°œë°œ.json::page::79::type::text | BM25: 0.00 | Rerank: 2.60 | Combined: 1.82\n",
      "ğŸ” ì¶•ì‚°ë¬¼í’ˆì§ˆí‰ê°€ì›_ì¶•ì‚°ë¬¼ì´ë ¥ê´€ë¦¬ì‹œìŠ¤í…œ ê°œì„ (ì •ë³´í™” ì‚¬ì—…).pdf | Chunk 20240523741_ì¶•ì‚°ë¬¼ì´ë ¥ê´€ë¦¬ì‹œìŠ¤í…œ_ê°œì„ (ì •ë³´í™”_ì‚¬ì—…).json::page::12::type::text | BM25: 0.00 | Rerank: 0.14 | Combined: 0.10\n",
      "ğŸ” í•œêµ­ë³´ìœ¡ì§„í¥ì›_ì—°ì°¨ë³„ ììœ¨ í’ˆì§ˆê´€ë¦¬ ì‹œìŠ¤í…œ ê¸°ëŠ¥ê°œì„ .pdf | Chunk 20240429895_ì—°ì°¨ë³„_ììœ¨_í’ˆì§ˆê´€ë¦¬_ì‹œìŠ¤í…œ_ê¸°ëŠ¥ê°œì„ .json::page::2::type::text | BM25: 0.00 | Rerank: 0.03 | Combined: 0.02\n",
      "ğŸ” êµ­ë°©ê³¼í•™ì—°êµ¬ì†Œ_ëŒ€ìš©ëŸ‰ ìë£Œì „ì†¡ì‹œìŠ¤í…œ ê³ ë„í™”.pdf | Chunk 20240821893_ëŒ€ìš©ëŸ‰_ìë£Œì „ì†¡ì‹œìŠ¤í…œ_ê³ ë„í™”.json::page::2::type::text | BM25: 0.00 | Rerank: 0.00 | Combined: 0.00\n",
      "\n",
      "ğŸ“ˆ ìµœì¢… ê²°ê³¼:\n",
      "ë¬¸ì„œ 1 | ì¶œì²˜: Unknown_88_ì„¸ì¢…í…Œí¬ë…¸íŒŒí¬_ì¸ì‚¬ì •ë³´_ì „ì‚°ì‹œìŠ¤í…œ_êµ¬ì¶•_ìš©ì—­_ì…ì°°ê³µê³ [ê¸´ê¸‰].json::page::48::type::text\n",
      "ğŸ”¹ BM25 ì ìˆ˜: 10.00 | ğŸ”¹ Rerank ì ìˆ˜: 9.83 | ğŸ”¹ Combined: 9.88\n",
      "- 45 - ìƒˆë¡œìš´ ì‹ ìš©í‰ê°€ë“±ê¸‰ì´ ì—†ëŠ” ê²½ìš°ì—ëŠ” í•©ë³‘ ëŒ€ìƒì—…ì²´ ì¤‘ ê°€ì¥ ë‚®ì€ ì‹ ìš©í‰ê°€ë“±ê¸‰ì„ ë°›ì€ ì—…ì²´ì˜ ì‹ ìš©í‰ê°€ë“±ê¸‰ìœ¼ë¡œ í‰ê°€ 2 ìœ ì‚¬ì‚¬ì—… ìˆ˜í–‰ì‹¤ì  í‰ê°€ ë°°ì  ê¸°ì¤€ ë° ìœ ì‚¬ìš©ì—­ ê¸°ì¤€ì€ ì•„ë˜ì™€ ê°™ìŒ í•­ëª© ê³„ì‚° ë°©ë²• ë°°ì í•œë„ ê¸° ì¤€ ë°°ì  ìœ ì‚¬ ì‚¬ì—… ì‹¤ì  ê±´ìˆ˜ ì¤€ê³µì‹¤ì  ê±´ìˆ˜ 4 A. ì‚¬ì—…ìˆ˜í–‰ 5ê±´ ì´ìƒ 4 B. ì‚¬ì—…ìˆ˜í–‰ 4ê±´ ì´ìƒ 3 C. ì‚¬ì—…ìˆ˜í–‰ 3ê±´ ì´ìƒ 2 D. ì‚¬ì—…ìˆ˜í–‰ 2ê±´ ì´ìƒ 1 í•­ëª© ê³„ì‚° ë°©ë²• ë°°ì í•œë„ ê¸° ì¤€ ë°°ì  ìœ ì‚¬ ì‚¬ì—… ì‹¤ì  ê¸ˆì•¡ ë³¸ì‚¬ì—…ë¹„ ì¤€ê³µì‹¤ì ê¸ˆì•¡ 3 A. 200ì´ìƒ 3 B. 100ì´ìƒ - 200ë¯¸ë§Œ 2 C. 100ë¯¸ë§Œ 1 1 ìœ ì‚¬ìš©ì—­ ì¸ì • ê¸°ì¤€ ê²½ì˜ì •ë³´ì‹œìŠ¤í…œERP êµ¬ì¶• ë° ê³ ë„í™” ì‚¬ì—… 2 ìµœê·¼ 3ë…„ê³µê³ ì¼ ê¸°ì¤€ ì´ë‚´ ì¤€ê³µí•œ, ë‹¨ì¼ì‚¬ì—…ë¹„ 1ì–µì› ì´ìƒ ì‹¤ì VAT í¬í•¨ë§Œì„ ì¸ì • í•˜ë©°, ì¦ëª…ì„œì˜ ë‚´ìš©ê¸ˆì•¡ ë“±ì„ ê¸°ì´ˆë¡œ í‰ê°€ì§„í–‰ ì¤‘ì¸ ìš©ì—­ì€ ì œì™¸ - ì…ì°° ê³µê³ ì¼ì„ 2019.11.01.ë¡œ ê°€ì •ì‹¤ì œ ê³µê³ ì¼ í™•ì¸í•  ê²½ìš° ìš©ì—­ ì¤€ê³µì¼ì°¨ìˆ˜ ì¤€ê³µ ì¸ì •, ê¸°ì„±ì‹¤ì  ë¯¸ì¸ì •ì´ 2016.11.01\n",
      "{'ì‚¬ì—… ê¸ˆì•¡': 90000000, 'ì…ì°° ì°¸ì—¬ ì‹œì‘ì¼': 'ë¯¸ì •', 'ì…ì°° ì°¸ì—¬ ë§ˆê°ì¼': 'ë¯¸ì •', 'page': 48, 'ê³µê°œ ì¼ì': '2021-10-08 00:00:00', 'chunk_id': 'Unknown_88_ì„¸ì¢…í…Œí¬ë…¸íŒŒí¬_ì¸ì‚¬ì •ë³´_ì „ì‚°ì‹œìŠ¤í…œ_êµ¬ì¶•_ìš©ì—­_ì…ì°°ê³µê³ [ê¸´ê¸‰].json::page::48::type::text', 'ê³µê³  ì°¨ìˆ˜': -1, 'ì‚¬ì—…ëª…': 'ì„¸ì¢…í…Œí¬ë…¸íŒŒí¬ ì¸ì‚¬ì •ë³´ ì „ì‚°ì‹œìŠ¤í…œ êµ¬ì¶• ìš©ì—­ ì…ì°°ê³µê³ [ê¸´ê¸‰]', 'ì‚¬ì—… ìš”ì•½': '- ì‚¬ì—…ê°œìš”: ì„¸ì¢…í…Œí¬ë…¸íŒŒí¬ ì¸ì‚¬ì •ë³´ ì „ì‚°ì‹œìŠ¤í…œ êµ¬ì¶•\\n- ì¶”ì§„ë°°ê²½: ì¸ì‚¬ì •ë³´ê´€ë¦¬ì˜ ì „ì‚°í™” ê²°ì—¬ë¡œ ì¸í•œ ì—…ë¬´ ë¶€ë‹´ê³¼ ì •ë³´ì˜ í†µí•© ë¶€ì¡±\\n- ì‚¬ì—…ë²”ìœ„: ì¸ì‚¬ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶•, ê·¼íƒœê´€ë¦¬ ê³ ë„í™”, ì¸ì‚¬ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶•\\n- ê¸°ëŒ€íš¨ê³¼: ì¸ì‚¬ì—…ë¬´ ì²˜ë¦¬ íš¨ìœ¨ì„± ì œê³ , ì •ë³´ì˜ í†µí•© ë° í˜‘ì—… ì²´ê³„ ê°•í™”\\n- ì¶”ì§„ëª©í‘œ: ì¸ì‚¬ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶•, ë¶„ì‚°ëœ ì¸ì‚¬ì—…ë¬´ í†µí•©, ì—°ê³„ ê¸°ê´€ ë° ë°ì´í„° ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥ì„± í™•ë³´', 'íŒŒì¼í˜•ì‹': 'pdf', 'íŒŒì¼ëª…': 'ì„¸ì¢…í…Œí¬ë…¸íŒŒí¬_ì„¸ì¢…í…Œí¬ë…¸íŒŒí¬ ì¸ì‚¬ì •ë³´ ì „ì‚°ì‹œìŠ¤í…œ êµ¬ì¶• ìš©ì—­ ì…ì°°ê³µ.pdf', 'ë°œì£¼ ê¸°ê´€': 'ì„¸ì¢…í…Œí¬ë…¸íŒŒí¬', 'ê³µê³  ë²ˆí˜¸': 'Unknown_88'}\n",
      "==================================================\n",
      "ë¬¸ì„œ 2 | ì¶œì²˜: 20240430896_ë´‰í™”êµ°_ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ_ê³ ë„í™”_ì‚¬ì—…(í˜‘ìƒ)(ê¸´ê¸‰).json::page::68::type::text\n",
      "ğŸ”¹ BM25 ì ìˆ˜: 7.99 | ğŸ”¹ Rerank ì ìˆ˜: 10.00 | ğŸ”¹ Combined: 9.40\n",
      "- 64 - ë³„ì§€ì„œì‹ 7í˜¸ ì‚¬ì—…ìˆ˜í–‰ ì‹¤ì ì¦ëª…ì„œ ì‹  ì²­ ì¸ ì—…ì²´ëª… ëŒ€ í‘œ ì ì˜ì—…ì†Œì¬ì§€ ì „í™”ë²ˆí˜¸ ì‚¬ì—…ìë²ˆí˜¸ ë²•ì¸ë“±ë¡ë²ˆí˜¸ ì¦ëª…ì„œ ìš©ë„ ì…ì°° ë° ì œì•ˆì„œ ì‹¬ì‚¬ ì œì¶œìš© ì œ ì¶œ ì²˜ êµ­ê°€ê¸°ê´€, ì§€ë°©ìì¹˜ë‹¨ì²´ ë° ê³µê³µê¸°ê´€ ì‚¬ì—…ì´í–‰ ì‹¤ì ë‚´ìš© ì‚¬ ì—… ëª… êµ¬ ë¶„ ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œ ìœ ì§€ê´€ë¦¬ìš´ì˜ìœ„íƒ ì •ë³´í†µì‹  ê¸°íƒ€ ì‚¬ì—…ê°œìš” ì‚¬ì—…ê¸ˆì•¡ VAT í¬í•¨ ê³„ì•½ì¼ìê³„ì•½ê¸°ê°„ ê³„ì•½ê¸ˆì•¡ VAT í¬í•¨ ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œ ë¶„ì•¼ ìš©ì—­ì´í–‰ ì‹¤ì  ì™„ë£Œì¼ì ë¹„ìœ¨ ì‹¤ì ì› ì¦ ëª… ì„œ ë°œê¸‰ê¸°ê´€ ìœ„ ì‚¬ì‹¤ì„ ì¦ëª…í•¨. ë…„ ì›” ì¼ ê¸°ê´€ëª… ì¸ ì „í™”ë²ˆí˜¸ ì£¼ ì†Œ ë°œê¸‰ë¶€ì„œ ë‹´ë‹¹ì ì „í™”ë²ˆí˜¸ ì‚¬ì—…ìˆ˜í–‰ì‹¤ì ì€ ì…ì°°ê³µê³ ì¼ ê¸°ì¤€ ì‚¬ì—… ì™„ë£Œì¼ìê°€ ìµœê·¼ 5ë…„ ì´ë‚´ ì‚¬ì—… ì‹¤ì ì— í•œí•œë‹¤. ì‚¬ì—…ê°œìš”ì—ëŠ” ë³¸ ì‚¬ì—…ê³¼ ë™ë“± ì´ìƒ ì‚¬ì—…ì„ì„ ì•Œ ìˆ˜ ìˆëŠ” ë‚´ìš©ì„ ê¸°ì¬í•œë‹¤. ê³µë™ê³„ì•½ìœ¼ë¡œ ì´í–‰í•˜ì˜€ì„ ê²½ìš° ì‚¬ì—…ê¸ˆì•¡ì—ëŠ” ì´ì‚¬ì—…ê¸ˆì•¡ì„ ì§€ì¬í•˜ê³ , ê³„ì•½ê¸ˆì•¡ì—ëŠ” í•´ ë‹¹ ìˆ˜í–‰ì‚¬ì˜ ì§€ë¶„ìœ¨ì— í•´ë‹¹í•˜ëŠ” ê¸ˆì•¡ì„ ê¸°ì¬í•œë‹¤. ì´í–‰ ì‹¤ì ë€ì€ ê¸°ì¬ í›„ íˆ¬ëª…ì ‘ì°©í…Œì´í”„ë¥¼ ë¶™ì—¬ ì¦ëª…ì„ ë°œê¸‰ ë°›ì•„ì•¼ í•˜ë©°, ê¸°ê´€ëª…ì¸ ì´ ì—†ëŠ” ê²ƒì€ ë¬´\n",
      "{'ê³µê³  ë²ˆí˜¸': '20240430896', 'íŒŒì¼ëª…': 'ê²½ìƒë¶ë„ ë´‰í™”êµ°_ë´‰í™”êµ° ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ ê³ ë„í™” ì‚¬ì—…(í˜‘ìƒ)(ê¸´ê¸‰).pdf', 'chunk_id': '20240430896_ë´‰í™”êµ°_ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ_ê³ ë„í™”_ì‚¬ì—…(í˜‘ìƒ)(ê¸´ê¸‰).json::page::68::type::text', 'ì…ì°° ì°¸ì—¬ ë§ˆê°ì¼': '2024-04-30 17:00:00', 'ì…ì°° ì°¸ì—¬ ì‹œì‘ì¼': '2024-04-26 09:00:00', 'ê³µê³  ì°¨ìˆ˜': 0.0, 'ì‚¬ì—…ëª…': 'ë´‰í™”êµ° ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ ê³ ë„í™” ì‚¬ì—…(í˜‘ìƒ)(ê¸´ê¸‰)', 'ê³µê°œ ì¼ì': '2024-04-18 16:33:28', 'ì‚¬ì—… ê¸ˆì•¡': 900000000, 'page': 68, 'ë°œì£¼ ê¸°ê´€': 'ê²½ìƒë¶ë„ ë´‰í™”êµ°', 'ì‚¬ì—… ìš”ì•½': '- ì‚¬ì—…ëª…: ë´‰í™”êµ° ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ ê³ ë„í™” ì‚¬ì—…\\n- ì‚¬ì—…ê°œìš”: ê³µë™ìˆ˜ê¸‰(ê³µë™ì´í–‰ë°©ì‹)ì„ í—ˆìš©í•˜ëŠ” ê³ ë„í™” ì‚¬ì—…\\n- ì¶”ì§„ë°°ê²½: ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œì˜ ê³ ë„í™” í•„ìš”ì„±\\n- ì‚¬ì—…ë²”ìœ„: ìê°€ì§„ë‹¨í‘œ ë¶„ì•¼ì— ëŒ€í•œ ì‚¬ì—…ìˆ˜í–‰ì‹¤ì  í‰ê°€í‘œ\\n- ê¸°ëŒ€íš¨ê³¼: ê³µë™ìˆ˜ê¸‰í‘œì¤€í˜‘ì •ì„œë¥¼ í™œìš©í•œ íš¨ê³¼ì ì¸ ì‚¬ì—…ìˆ˜í–‰\\n- ì¶”ì§„ëª©í‘œ: ë´‰í™”êµ° ì¬ë‚œí†µí•©ê´€ë¦¬ì‹œìŠ¤í…œì˜ ê³ ë„í™” ë° ê°œì„ ', 'íŒŒì¼í˜•ì‹': 'pdf'}\n",
      "==================================================\n",
      "ë¬¸ì„œ 3 | ì¶œì²˜: 20241218257_2025ë…„_ì•„ì´ëŒë´„ì¸ë ¥_ì¸ì ì„±_ê²€ì‚¬_ì •ë³´ì‹œìŠ¤í…œ_ìš´ì˜.json::page::40::type::text\n",
      "ğŸ”¹ BM25 ì ìˆ˜: 7.91 | ğŸ”¹ Rerank ì ìˆ˜: 9.75 | ğŸ”¹ Combined: 9.20\n",
      "- 38 - ë³´í˜¸ ë° ì§€ì›ì— ê´€í•œ ë²•ë¥ ì œ2ì¡°ì— ë”°ë¥¸ ì†Œìƒê³µì¸ìœ¼ë¡œì„œì¤‘ì†Œ ê¸°ì—… ë²”ìœ„ ë° í™•ì¸ì— ê´€í•œ ê·œì •ì— ë”°ë¼ ë°œê¸‰ëœ ì¤‘ì†Œê¸°ì—… ì†Œìƒê³µì¸ í™•ì¸ì„œë¥¼ ì†Œì§€í•œ ì—…ì²´ì…ì°° ì°¸ê°€ ë§ˆê°ì¼ ì „ì¼ê¹Œì§€ ë°œ ê¸‰ëœ ê²ƒìœ¼ë¡œ ìœ íš¨ê¸°ê°„ ë‚´ì— í•œí•¨ á„‹ ì¤‘ì†Œê¸°ì—…ì œí’ˆ êµ¬ë§¤ì´‰ì§„ ë° íŒë¡œì§€ì›ì— ê´€í•œ ë²•ë¥ ì— ì˜í•œ ì¤‘ì†Œê¸° ì—…ìë¡œì„œì¤‘ì†Œê¸°ì—…ìê°„ ê²½ìŸì œí’ˆ ì§ì ‘ìƒì‚° í™•ì¸ê¸°ì¤€ì¤‘ì†Œë²¤ì²˜ ê¸°ì—…ë¶€ ê³ ì‹œì— ë”°ë¼ ì§ì ‘ìƒì‚°í™•ì¸ì¦ëª…ì„œì •ë³´ì‹œìŠ¤í…œìœ ì§€ê´€ë¦¬ì„œ ë¹„ìŠ¤,ì„¸ë¶€í’ˆëª…ë²ˆí˜¸ 8111189901ë¥¼ ì†Œì§€í•œ ì—…ì²´ì…ì°°ì°¸ê°€ë“±ë¡ ë§ˆê°ì¼ ì´ì „ ë°œí–‰ëœ ê²ƒìœ¼ë¡œ ìœ íš¨ê¸°ê°„ ë‚´ì— ìˆì–´ì•¼ í•¨ á„‹ ìƒí˜¸ì¶œìì œí•œê¸°ì—…ì§‘ë‹¨ ì†Œì†ê¸°ì—… ë° ëŒ€ê¸°ì—… ì°¸ì—¬ì œí•œ ì‚¬í•­ - ì†Œí”„íŠ¸ì›¨ì–´ ì§„í¥ë²• ì œ48ì¡° ì œ4í•­ì— ë”°ë¼ ìƒí˜¸ì¶œìì œí•œê¸°ì—… ì§‘ë‹¨ì— ì†í•˜ëŠ” íšŒì‚¬ëŠ” ì…ì°°ì— ì°¸ì—¬ ë¶ˆê°€ - ë³¸ ì‚¬ì—…ì€ 20ì–µ ë¯¸ë§Œì˜ ì‚¬ì—…ìœ¼ë¡œì¨, ì†Œí”„íŠ¸ì›¨ì–´ ì§„í¥ë²• ì œ48ì¡° ì œ2í•­ ë° ëŒ€ê¸°ì—…ì¸ ì†Œí”„íŠ¸ì›¨ì–´ ì‚¬ì—…ìê°€ ì°¸ì—¬í•  ìˆ˜ ìˆëŠ” ì‚¬ì—…ê¸ˆ ì•¡ì˜ í•˜í•œê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ì— ì˜ê±° ëŒ€ê¸°ì—… ë° ì¤‘ê²¬ê¸°ì—…ì¸ ì†Œ í”„íŠ¸ì›¨ì–´ ì‚¬ì—…ìì˜ ì…ì°° ì°¸ì—¬ ì œí•œì¤‘ì†Œê¸°ì—…ìë§Œ\n",
      "{'ë°œì£¼ ê¸°ê´€': 'í•œêµ­ê±´ê°•ê°€ì •ì§„í¥ì›', 'ê³µê°œ ì¼ì': '2024-12-10 17:43:31', 'íŒŒì¼ëª…': 'í•œêµ­ê±´ê°•ê°€ì •ì§„í¥ì›_2025ë…„ ì•„ì´ëŒë´„ì¸ë ¥ ì¸ì ì„± ê²€ì‚¬ ì •ë³´ì‹œìŠ¤í…œ ìš´ì˜.pdf', 'ì‚¬ì—… ê¸ˆì•¡': 172700000, 'page': 40, 'ê³µê³  ë²ˆí˜¸': '20241218257', 'ì‚¬ì—… ìš”ì•½': '- ì¶”ì§„ë°°ê²½: êµ­ì •ê³¼ì œì¸ ì•„ë™ëŒë´„ì²´ê³„ ê°•í™”ì™€ ê°œì¸ì •ë³´ë³´í˜¸ë²• ì¤€ìˆ˜ë¥¼ ìœ„í•´ ì•„ì´ëŒë´„ì¸ë ¥ ì¸ì ì„± ê²€ì‚¬ ì •ë³´ì‹œìŠ¤í…œ ìš´ì˜ í•„ìš”\\n- ì‚¬ì—…ê°œìš”: 2025ë…„ê¹Œì§€ ì•„ì´ëŒë´„ì¸ë ¥ ì¸ì ì„± ê²€ì‚¬ ì •ë³´ì‹œìŠ¤í…œ ìš´ì˜ ë° ìœ ì§€ë³´ìˆ˜\\n- ì‚¬ì—…ë²”ìœ„: ì¸-ì ì„± í”„ë¡œê·¸ë¨ ê¸°ëŠ¥ ìˆ˜ì • ë° ì•ˆì •í™”, ì •ë³´ì‹œìŠ¤í…œ ìœ ì§€ê´€ë¦¬, ê°œì¸ì •ë³´ë³´í˜¸ ë° ì •ë³´ë³´ì•ˆ ê°•í™”\\n- ê¸°ëŒ€íš¨ê³¼: ì•ˆì „í•œ ëŒë´„ í™˜ê²½ ì¡°ì„±, íš¨ìœ¨ì„± ì œê³ , ì •ì±…ì§€ì› ë° ì œë„ê°œì„  ì§€ì›, ëŒë´„ì¸ë ¥ ê´€ë¦¬ ê°•í™”', 'ì…ì°° ì°¸ì—¬ ë§ˆê°ì¼': '2024-12-23 10:00:00', 'ê³µê³  ì°¨ìˆ˜': 0.0, 'íŒŒì¼í˜•ì‹': 'pdf', 'chunk_id': '20241218257_2025ë…„_ì•„ì´ëŒë´„ì¸ë ¥_ì¸ì ì„±_ê²€ì‚¬_ì •ë³´ì‹œìŠ¤í…œ_ìš´ì˜.json::page::40::type::text', 'ì‚¬ì—…ëª…': '2025ë…„ ì•„ì´ëŒë´„ì¸ë ¥ ì¸ì ì„± ê²€ì‚¬ ì •ë³´ì‹œìŠ¤í…œ ìš´ì˜', 'ì…ì°° ì°¸ì—¬ ì‹œì‘ì¼': '2024-12-10 18:00:00'}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ê²€ìƒ‰ ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ)\n",
    "\n",
    "#query_text = \"ì…ì°°ì‹œì‘ì¼ì´ 2024ë…„ 8ì›” ì´í›„ ê³µê³  ì°¾ì•„ì¤˜\"\n",
    "query_text = \"ì‚¬ì—…ê¸ˆì•¡ 100ì–µì´ìƒ ê³µê³  ì•Œë ¤ì¤˜\"\n",
    "logging.info(f\"\\n[ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì‹¤í–‰] ì§ˆë¬¸: {query_text}\")\n",
    "\n",
    "\n",
    "tokenized_query = retriever.tokenizer.tokenize_korean(query_text)\n",
    "print(f\"\\nğŸ” BM25 í‚¤ì›Œë“œ í† í°: {tokenized_query}\")\n",
    "\n",
    "results = retriever.smart_search(\n",
    "    query=query_text,\n",
    "    top_k=3,\n",
    "    candidate_size=10,\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥ (ê¸°ì¡´ ë¡œì§ 100% ìœ ì§€)\n",
    "print(\"\\nğŸ“ˆ ìµœì¢… ê²°ê³¼:\")\n",
    "\n",
    "if results and isinstance(results[0], dict):\n",
    "    # ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼\n",
    "    for i, record in enumerate(results):\n",
    "        print(f\"\\nğŸ“„ ë¬¸ì„œ {i+1}\")\n",
    "        for key, value in record.items():\n",
    "            print(f\"ğŸ”¹ {key}: {value}\")\n",
    "        print(\"=\" * 50)\n",
    "else:\n",
    "    # ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼\n",
    "    for i, doc in enumerate(results):\n",
    "        key = retriever.get_doc_key(doc)\n",
    "        scores = retriever.last_scores.get(key, {})\n",
    "        bm25 = scores.get(\"bm25\", 0.0)\n",
    "        rerank = scores.get(\"rerank\", 0.0)\n",
    "        combined = scores.get(\"combined\", 0.0)\n",
    "\n",
    "        print(f\"ë¬¸ì„œ {i+1} | ì¶œì²˜: {doc.metadata.get('chunk_id')}\")\n",
    "        print(f\"ğŸ”¹ BM25 ì ìˆ˜: {bm25:.2f} | ğŸ”¹ Rerank ì ìˆ˜: {rerank:.2f} | ğŸ”¹ Combined: {combined:.2f}\")\n",
    "        print(doc.page_content[:500])\n",
    "        print(doc.metadata)\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37160cc-c9a7-446d-9eef-3351096d944f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
