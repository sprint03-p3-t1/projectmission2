{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a651ae-8534-4ee5-a3a4-5006df064791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Set, Tuple\n",
    "def minmax_scale(scores: Dict[str, float], scale_min=0.0, scale_max=10.0) -> Dict[str, float]:\n",
    "    values = list(scores.values())\n",
    "    min_val, max_val = min(values), max(values)\n",
    "    if min_val == max_val:\n",
    "        return {k: scale_min for k in scores}  # 모든 점수가 같으면 최소값으로 고정\n",
    "\n",
    "    return {\n",
    "        k: scale_min + (v - min_val) / (max_val - min_val) * (scale_max - scale_min)\n",
    "        for k, v in scores.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68a1f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import hashlib\n",
    "import pickle\n",
    "from typing import List, Dict\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "class RerankModel:\n",
    "    def __init__(self, model_name: str, cache_dir: str, device: str = \"cuda\"):\n",
    "        \"\"\"모델과 토크나이저를 로드하여 초기화\"\"\"\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(device)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.device = device\n",
    "        self.cache_dir = cache_dir\n",
    "        os.makedirs(self.cache_dir, exist_ok=True)\n",
    "\n",
    "    def _get_cache_path(self, text: str) -> str:\n",
    "        \"\"\"텍스트를 기반으로 캐시 파일 경로 생성\"\"\"\n",
    "        key = hashlib.md5(text.encode()).hexdigest()\n",
    "        return os.path.join(self.cache_dir, f\"{key}.pkl\")\n",
    "\n",
    "    def _load_embedding_from_cache(self, text: str) -> torch.Tensor:\n",
    "        \"\"\"캐시에서 임베딩 로드\"\"\"\n",
    "        path = self._get_cache_path(text)\n",
    "        if os.path.exists(path):\n",
    "            with open(path, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        return None\n",
    "\n",
    "    def _save_embedding_to_cache(self, text: str, embedding: torch.Tensor):\n",
    "        \"\"\"임베딩을 캐시에 저장\"\"\"\n",
    "        path = self._get_cache_path(text)\n",
    "        with open(path, \"wb\") as f:\n",
    "            pickle.dump(embedding.cpu(), f)\n",
    "\n",
    "    def _embed(self, text: str) -> torch.Tensor:\n",
    "        \"\"\"텍스트를 의미 벡터로 변환\"\"\"\n",
    "        inputs = self.tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            hidden = self.model(**inputs).last_hidden_state\n",
    "            mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "            pooled = (hidden * mask).sum(dim=1) / mask.sum(dim=1)\n",
    "        return pooled[0]\n",
    "\n",
    "    def _get_embedding(self, text: str, is_query: bool = False) -> torch.Tensor:\n",
    "        \"\"\"임베딩 반환 (문서는 캐싱, 쿼리는 계산)\"\"\"\n",
    "        if is_query:\n",
    "            return self._embed(text)\n",
    "\n",
    "        cached = self._load_embedding_from_cache(text)\n",
    "        if cached is not None:\n",
    "            return cached.to(self.device)\n",
    "\n",
    "        emb = self._embed(text)\n",
    "        self._save_embedding_to_cache(text, emb)\n",
    "        return emb\n",
    "\n",
    "    def rerank(self, query: str, documents: List[str]) -> Dict[str, float]:\n",
    "        \"\"\"쿼리와 문서들의 유사도를 계산해 점수 반환\"\"\"\n",
    "        query_embedding = self._get_embedding(query, is_query=True).unsqueeze(0)\n",
    "        doc_embeddings = [self._get_embedding(doc).unsqueeze(0) for doc in documents]\n",
    "        doc_tensor = torch.cat(doc_embeddings, dim=0)\n",
    "\n",
    "        cos_scores = torch.nn.functional.cosine_similarity(query_embedding, doc_tensor)\n",
    "        return {doc: score.item() for doc, score in zip(documents, cos_scores)}\n",
    "\n",
    "    def cache_embeddings(self, texts: List[str], max_length: int = 512):\n",
    "        \"\"\"전체 문서에 대해 의미 임베딩 캐싱\"\"\"\n",
    "        skipped, cached = 0, 0\n",
    "        for text in texts:\n",
    "            text = text[:max_length]\n",
    "            path = self._get_cache_path(text)\n",
    "            if os.path.exists(path):\n",
    "                skipped += 1\n",
    "                continue\n",
    "            emb = self._embed(text)\n",
    "            self._save_embedding_to_cache(text, emb)\n",
    "            cached += 1\n",
    "        print(f\"✅ 의미 임베딩 캐싱 완료 | 새로 캐싱: {cached}개 | 스킵: {skipped}개\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a56105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TokenizerWrapper:\n",
    "    def __init__(self, engine=\"kiwi\"):\n",
    "        if engine == \"kiwi\":\n",
    "            from kiwipiepy import Kiwi\n",
    "            self.tokenizer = Kiwi()\n",
    "            self.mode = \"kiwi\"\n",
    "        elif engine == \"okt\":\n",
    "            from konlpy.tag import Okt\n",
    "            self.tokenizer = Okt()\n",
    "            self.mode = \"okt\"\n",
    "        else:\n",
    "            raise ValueError(f\"지원되지 않는 분석기: {engine}\")\n",
    "\n",
    "    def tokenize_korean(self, text: str, use_bigrams: bool = True) -> List[str]:\n",
    "        # ✅ 명사만 추출\n",
    "        if self.mode == \"kiwi\":\n",
    "            tokens = [token.form for token in self.tokenizer.tokenize(text) if token.tag.startswith(\"NN\")]\n",
    "        elif self.mode == \"okt\":\n",
    "            tokens = self.tokenizer.nouns(text)\n",
    "\n",
    "        # ✅ 불용어 제거\n",
    "        stopwords = {\"에서\", \"는\", \"은\", \"이\", \"가\", \"하\", \"어야\", \"에\", \"을\", \"를\", \"도\", \"로\", \"과\", \"와\", \"의\", \"?\", \"다\"}\n",
    "        tokens = [t for t in tokens if t not in stopwords]\n",
    "\n",
    "        # ✅ 바이그램 추가\n",
    "        if use_bigrams:\n",
    "            bigrams = [tokens[i] + tokens[i+1] for i in range(len(tokens) - 1)]\n",
    "            tokens += bigrams\n",
    "\n",
    "        return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8445f74-137a-40f0-a936-eb80f8bfc5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "from typing import List, Dict, Set, Tuple\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from rank_bm25 import BM25Okapi \n",
    "from more_itertools import chunked\n",
    "\n",
    "import aiofiles\n",
    "\n",
    "# 로컬 임포트\n",
    "# 로깅 설정\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "class RetrieverError(Exception):\n",
    "    \"\"\"Retriever에서 발생하는 예외를 위한 기본 클래스\"\"\"\n",
    "    pass\n",
    "\n",
    "class ChunkLoadingError(RetrieverError):\n",
    "    \"\"\"JSON 청크 로딩 실패 시 발생하는 예외\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class Retriever:\n",
    "    def __init__(self,\n",
    "                 meta_df=None,\n",
    "                 embedder=None,\n",
    "                 reranker: RerankModel =None,\n",
    "                 tokenizer=None,\n",
    "                 persist_directory=None,\n",
    "                 rerank_max_length=512,\n",
    "                 bm25_weight=0.5,\n",
    "                 rerank_weight=0.5,\n",
    "                 bm25_path=\"bm25_index.pkl\",\n",
    "                 debug_mode=False\n",
    "                 ):\n",
    "        self.meta_df = meta_df\n",
    "        self.embedder = embedder\n",
    "        self.reranker = reranker\n",
    "        self.tokenizer = tokenizer or TokenizerWrapper(\"kiwi\")\n",
    "        self.persist_directory = persist_directory\n",
    "        self.rerank_max_length = rerank_max_length\n",
    "\n",
    "        self.bm25_weight = bm25_weight\n",
    "        self.rerank_weight = rerank_weight\n",
    "\n",
    "        self.db = None\n",
    "        self.bm25 = None\n",
    "        self.bm25_ready = False\n",
    "        self.bm25_path = bm25_path\n",
    "        self.documents = []\n",
    "        self.debug_mode = debug_mode\n",
    "\n",
    "        self.last_scores = {}\n",
    "\n",
    "    def set_weights(self, bm25_weight: float, rerank_weight: float):\n",
    "        self.bm25_weight = bm25_weight\n",
    "        self.rerank_weight = rerank_weight\n",
    "        logging.info(f\"🔧 가중치 설정됨 | BM25: {bm25_weight} | Rerank: {rerank_weight}\")\n",
    "\n",
    "    def get_doc_key(self, doc: Document) -> str:\n",
    "        chunk_id = doc.metadata.get(\"chunk_id\")\n",
    "        if chunk_id:\n",
    "            return chunk_id\n",
    "        return str(hash(doc.page_content.strip()))\n",
    "\n",
    "    def save_bm25_index(self):\n",
    "        os.makedirs(os.path.dirname(self.bm25_path), exist_ok=True)\n",
    "        with open(self.bm25_path, \"wb\") as f:\n",
    "            pickle.dump(self.bm25, f)\n",
    "        logging.info(f\"✅ BM25 인덱스 저장 완료: {self.bm25_path}\")\n",
    "\n",
    "    def load_bm25_index(self):\n",
    "        path = self.bm25_path\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                with open(path, \"rb\") as f:\n",
    "                    self.bm25 = pickle.load(f)\n",
    "                self.bm25_ready = True\n",
    "                logging.info(f\"✅ BM25 인덱스 로드 완료: {path}\")\n",
    "            except Exception as e:\n",
    "                self.bm25_ready = False\n",
    "                logging.warning(f\"❌ BM25 인덱스 로드 실패: {e}\")\n",
    "        else:\n",
    "            self.bm25_ready = False\n",
    "            logging.warning(f\"❌ BM25 인덱스 파일 없음: {path}\")\n",
    "\n",
    "    def deduplicate_documents(self, documents: List[Document]) -> List[Document]:\n",
    "        seen = set()\n",
    "        unique_docs = []\n",
    "        for doc in documents:\n",
    "            chunk_id = doc.metadata.get(\"chunk_id\")\n",
    "            if chunk_id and chunk_id not in seen:\n",
    "                seen.add(chunk_id)\n",
    "                unique_docs.append(doc)\n",
    "        removed = len(documents) - len(unique_docs)\n",
    "        logging.info(f\"🧹 중복 제거: {removed}개 제거됨\")\n",
    "        return unique_docs\n",
    "\n",
    "    \n",
    "    async def load_or_cache_json_docs(self, folder_path: str, cache_path: str) -> List[Document]:\n",
    "        # 캐시 디렉토리 자동 생성\n",
    "        os.makedirs(os.path.dirname(cache_path), exist_ok=True)\n",
    "    \n",
    "        if os.path.exists(cache_path):\n",
    "            with open(cache_path, \"rb\") as f:\n",
    "                logging.info(\"📦 캐시된 JSON 문서 로드 중...\")\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            logging.info(\"📂 JSON 폴더에서 문서 로딩 중...\")\n",
    "            docs = await self.async_load_chunks_from_folder(folder_path)\n",
    "            with open(cache_path, \"wb\") as f:\n",
    "                pickle.dump(docs, f)\n",
    "            logging.info(\"✅ JSON 캐시 저장 완료\")\n",
    "            return docs\n",
    "\n",
    "    async def async_load_chunks_from_folder(self, folder_path: str) -> List[Document]:\n",
    "        if not os.path.isdir(folder_path):\n",
    "            raise ChunkLoadingError(f\"❌ 폴더 경로가 존재하지 않음: {folder_path}\")\n",
    "\n",
    "        file_list = sorted([f for f in os.listdir(folder_path) if f.endswith(\".json\")])\n",
    "        existing_sources = self.get_existing_chunk_ids()\n",
    "        logging.info(f\"📁 기존 DB에 저장된 source 수: {len(existing_sources)}\")\n",
    "\n",
    "        tasks = []\n",
    "        for filename in file_list:\n",
    "            if filename in existing_sources:\n",
    "                logging.info(f\"⏩ 이미 처리된 파일 건너뜀: {filename}\")\n",
    "                continue\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            tasks.append(self._load_single_file(file_path, filename))\n",
    "\n",
    "        # ✅ 고급 tqdm 적용: 실제 완료 기준으로 진행률 표시\n",
    "        all_chunks = []\n",
    "        for coro in tqdm_asyncio.as_completed(tasks, desc=\"📂 파일 처리 중\", total=len(tasks)):\n",
    "            result = await coro\n",
    "            all_chunks.append(result)\n",
    "\n",
    "        documents = [doc for sublist in all_chunks for doc in sublist]\n",
    "        logging.info(f\"✅ 새로 로드된 문서 수: {len(documents)}\")\n",
    "\n",
    "        documents = self.deduplicate_documents(documents)\n",
    "        logging.info(f\"🧹 중복 제거 후 문서 수: {len(documents)}\")\n",
    "        return documents\n",
    "\n",
    "    \n",
    "    async def _load_single_file(self, file_path: str, filename: str) -> list[Document]:\n",
    "        try:\n",
    "            async with aiofiles.open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = await f.read()\n",
    "                data = json.loads(content)\n",
    "    \n",
    "            metadata_base = data.get(\"csv_metadata\", {})\n",
    "            docs = []\n",
    "    \n",
    "            for idx, page in enumerate(data.get(\"pdf_data\", [])):\n",
    "                page_num = page.get(\"page\", idx)\n",
    "                text = page.get(\"text\", \"\").strip()\n",
    "    \n",
    "                if text:\n",
    "                    metadata = metadata_base.copy()\n",
    "                    metadata[\"chunk_id\"] = f\"{filename}::page::{page_num}::type::text\"\n",
    "                    metadata[\"page\"] = page_num\n",
    "    \n",
    "                    docs.append(Document(page_content=text, metadata=metadata))\n",
    "    \n",
    "            return docs\n",
    "    \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"⚠️ 파일 로딩 실패: {filename} | 오류: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_all_documents_from_db(self) -> List[Document]:\n",
    "        if self.db is None:\n",
    "            raise ValueError(\"Vector DB가 초기화되지 않았습니다.\")\n",
    "\n",
    "        all_docs = []\n",
    "        collection = self.db._collection\n",
    "        count = collection.count()\n",
    "        offset = 0\n",
    "        limit = 1000\n",
    "\n",
    "        while offset < count:\n",
    "            results = collection.get(\n",
    "                limit=limit,\n",
    "                offset=offset,\n",
    "                include=[\"metadatas\", \"documents\"]\n",
    "            )\n",
    "            for doc, meta in zip(results[\"documents\"], results[\"metadatas\"]):\n",
    "                if not meta.get(\"chunk_id\"):\n",
    "                    logging.warning(\"⚠️ chunk_id 누락된 문서 발견\")\n",
    "                all_docs.append(Document(page_content=doc, metadata=meta))\n",
    "            offset += limit\n",
    "\n",
    "        return all_docs\n",
    "\n",
    "\n",
    "    def load_or_build_vector_db(self, documents: List[Document], force_rebuild: bool = False):\n",
    "        \"\"\"Vector DB와 BM25 인덱스를 로드하거나 새로 구축합니다.\"\"\"\n",
    "        \n",
    "        # 1단계: Vector DB 초기화 (로드 또는 생성)\n",
    "        self._initialize_vector_db(documents, force_rebuild)\n",
    "        \n",
    "        # 2단계: 새 문서가 있다면 DB에 추가\n",
    "        new_docs = self._update_db_with_new_docs(documents)\n",
    "        \n",
    "        # 3단계: BM25 인덱스 동기화 (새 문서 추가 여부에 따라 처리)\n",
    "        self.documents = self.get_all_documents_from_db()\n",
    "        self._synchronize_bm25_index(was_db_updated=(len(new_docs) > 0))\n",
    "        \n",
    "        # 4단계: 리랭커 임베딩 캐싱\n",
    "        self._cache_reranker_embeddings()\n",
    "        logging.info(\"🚀 모든 DB 및 인덱스 준비 완료.\")\n",
    "    \n",
    "\n",
    "    def _initialize_vector_db(self, documents: List[Document], force_rebuild: bool):\n",
    "        \"\"\"Vector DB를 생성하거나 로드합니다.\"\"\"\n",
    "        if force_rebuild or not self._db_exists():\n",
    "            logging.info(\"🆕 벡터 DB 생성 중...\")\n",
    "            wrapped_docs = list(tqdm(documents, desc=\"🔄 문서 임베딩 중\"))\n",
    "            self.db = Chroma.from_documents(wrapped_docs, self.embedder, persist_directory=self.persist_directory)\n",
    "            logging.info(\"✅ 새 DB 구축 완료.\")\n",
    "        else:\n",
    "            logging.info(\"✅ 기존 벡터 DB 로드 중...\")\n",
    "            self.load_vector_db()\n",
    "    \n",
    "    def _update_db_with_new_docs(self, documents: List[Document]) -> List[Document]:\n",
    "        \"\"\"새로운 문서를 필터링하여 DB에 추가합니다.\"\"\"\n",
    "        new_docs = self._filter_new_documents(documents)\n",
    "        if not new_docs:\n",
    "            logging.info(\"⏩ 새 문서 없음, DB 추가 생략\")\n",
    "            return []\n",
    "    \n",
    "        logging.info(f\"➕ 새 문서 {len(new_docs)}개 추가 중...\")\n",
    "        batch_size = 100\n",
    "        total_batches = (len(new_docs) + batch_size - 1) // batch_size\n",
    "        \n",
    "        for batch in tqdm(chunked(new_docs, batch_size), desc=\"📦 배치 추가 중\", total=total_batches):\n",
    "            self.db.add_documents(batch)\n",
    "            \n",
    "        return new_docs\n",
    "    \n",
    "    def _synchronize_bm25_index(self, was_db_updated: bool):\n",
    "        \"\"\"DB 상태에 따라 BM25 인덱스를 생성하거나 로드합니다.\"\"\"\n",
    "        # 새 문서가 추가됐다면 BM25 인덱스는 무조건 새로 만들어야 함\n",
    "        if was_db_updated:\n",
    "            logging.info(\"🔧 새 문서 추가됨, BM25 인덱스 재생성...\")\n",
    "            self.build_bm25_index()\n",
    "            self.save_bm25_index()\n",
    "            logging.info(\"✅ BM25 인덱싱 완료.\")\n",
    "            return\n",
    "    \n",
    "        # 새 문서가 없다면, 기존 인덱스를 로드해보고 없으면 생성\n",
    "        if not hasattr(self, \"bm25_ready\") or not self.bm25_ready:\n",
    "            self.load_bm25_index()\n",
    "            if not self.bm25_ready:\n",
    "                logging.info(\"📚 기존 BM25 인덱스 없음, 새로 구축 시작...\")\n",
    "                self.build_bm25_index()\n",
    "                self.save_bm25_index()\n",
    "                logging.info(\"✅ BM25 인덱싱 완료.\")\n",
    "    \n",
    "    def _cache_reranker_embeddings(self):\n",
    "        \"\"\"리랭커 모델을 위한 임베딩을 캐싱합니다.\"\"\"\n",
    "        if not self.documents:\n",
    "            logging.warning(\"⚠️ 캐싱할 문서가 없습니다.\")\n",
    "            return\n",
    "            \n",
    "        logging.info(\"💡 리랭커 임베딩 캐싱 중...\")\n",
    "        texts = [doc.page_content[:self.rerank_max_length] for doc in self.documents]\n",
    "        self.reranker.cache_embeddings(texts, max_length=self.rerank_max_length)\n",
    "        logging.info(\"✅ 리랭커 캐싱 완료.\")\n",
    "\n",
    "    def load_vector_db(self):\n",
    "        if not self.persist_directory or not os.path.exists(self.persist_directory):\n",
    "            raise ValueError(\"저장된 DB가 없거나 persist_directory가 잘못 설정되었습니다.\")\n",
    "        self.db = Chroma(persist_directory=self.persist_directory, embedding_function=self.embedder)\n",
    "\n",
    "    def _db_exists(self) -> bool:\n",
    "        if not self.persist_directory:\n",
    "            return False\n",
    "        required_files = [\"chroma.sqlite3\"]\n",
    "        return all(os.path.exists(os.path.join(self.persist_directory, f)) for f in required_files)\n",
    "\n",
    "    def get_existing_chunk_ids(self) -> Set[str]:\n",
    "        if self.db is None:\n",
    "            try:\n",
    "                self.load_vector_db()\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"⚠️ DB 로드 실패: {e}\")\n",
    "                self.db = None\n",
    "                return set()\n",
    "\n",
    "        try:\n",
    "            result = self.db.get(include=[\"metadatas\"])\n",
    "            chunk_ids = set()\n",
    "            for i, meta in enumerate(result.get(\"metadatas\", [])):\n",
    "                cid = meta.get(\"chunk_id\")\n",
    "                if not cid:\n",
    "                    logging.warning(f\"⚠️ chunk_id 누락된 문서 발견 (index={i})\")\n",
    "                    continue\n",
    "                chunk_ids.add(cid)\n",
    "            return chunk_ids\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"⚠️ chunk_id 목록 추출 실패: {e}\")\n",
    "            return set()\n",
    "\n",
    "\n",
    "    def _filter_new_documents(self, documents: List[Document]) -> List[Document]:\n",
    "        existing_chunk_ids  = self.get_existing_chunk_ids()\n",
    "        new_docs = []\n",
    "        for doc in documents:\n",
    "            chunk_id  = doc.metadata.get(\"chunk_id\")\n",
    "            if chunk_id  and chunk_id  not in existing_chunk_ids :\n",
    "                new_docs.append(doc)\n",
    "        return new_docs\n",
    "\n",
    "    # ✅ BM25 관련 함수 추가\n",
    "    def build_bm25_index(self):\n",
    "        if self.bm25 is not None:\n",
    "            logging.info(\"⏩ BM25 인덱스 이미 존재함, 재생성 생략\")\n",
    "            return\n",
    "        if not self.documents:\n",
    "            raise ValueError(\"BM25 인덱스를 생성할 문서가 없습니다.\")\n",
    "\n",
    "        tokenized_corpus = [self.tokenizer.tokenize_korean(doc.page_content) \n",
    "                            for doc in tqdm(self.documents, desc=\"🧠 문서 토큰화 중\")]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        self.bm25_ready = True\n",
    "        logging.info(\"✅ BM25 인덱스 생성 완료\")\n",
    "\n",
    "    def _debug_print_bm25_scores(self, top_docs: List[Tuple[float, Document]]):\n",
    "        \"\"\"BM25 점수 디버그 출력 전용 함수\"\"\"\n",
    "        print(\"\\n📈 BM25 상위 문서 및 점수:\")\n",
    "        for i, (score, doc) in enumerate(top_docs):\n",
    "            print(f\"BM25 문서 {i+1} | 점수: {score:.4f} | 출처: {doc.metadata.get('파일명')}\")\n",
    "            print(doc.page_content[:300])\n",
    "            print(\"-\" * 40)\n",
    "        \n",
    "    def bm25_search(self, query: str, k: int = 5, filter: Dict = None, debug: bool = False) -> List[Tuple[float, Document]]:\n",
    "        if not self.bm25_ready:\n",
    "            raise ValueError(\"BM25 인덱스가 준비되지 않았습니다.\")\n",
    "\n",
    "        tokenized_query = self.tokenizer.tokenize_korean(query)\n",
    "        doc_scores = self.bm25.get_scores(tokenized_query)\n",
    "           \n",
    "        # ✅ 필터링 적용\n",
    "        filtered_docs = []\n",
    "        for score, doc in zip(doc_scores, self.documents):\n",
    "            if filter:\n",
    "                match = all(doc.metadata.get(k) == v for k, v in filter.items())\n",
    "                if not match:\n",
    "                    continue\n",
    "            filtered_docs.append((score, doc))\n",
    "\n",
    "        top_docs = sorted(filtered_docs, key=lambda x: x[0], reverse=True)[:k]\n",
    "\n",
    "        if self.debug_mode:\n",
    "            self._debug_print_bm25_scores(top_docs)\n",
    "            \n",
    "        return top_docs\n",
    "\n",
    "    def rerank_documents(self, query: str, documents: List[Document]) -> Dict[str, float]:\n",
    "        \"\"\"쿼리와 문서들의 유사도를 계산하여 재순위화 점수 반환\"\"\"\n",
    "        if not self.reranker:\n",
    "            logging.warning(\"⚠️ 재순위화 모델이 로드되지 않았습니다. 점수가 0으로 반환됩니다.\")\n",
    "            return {self.get_doc_key(doc): 0.0 for doc in documents}\n",
    "        \n",
    "        texts_to_rerank = [doc.page_content[:self.rerank_max_length] for doc in documents]\n",
    "        base_scores = self.reranker.rerank(query, texts_to_rerank)\n",
    "    \n",
    "        query_tokens = self.tokenizer.tokenize_korean(query)\n",
    "        bonus_weight = 1.0\n",
    "    \n",
    "        final_scores = {}\n",
    "        for doc, base_score in zip(documents, base_scores.values()):\n",
    "            bonus = 0\n",
    "            if query in doc.page_content:\n",
    "                bonus += 2.0\n",
    "            bonus += sum(1 for token in query_tokens if token in doc.page_content) * bonus_weight\n",
    "    \n",
    "            key = self.get_doc_key(doc)\n",
    "            final_scores[key] = base_score + bonus\n",
    "    \n",
    "        logging.info(\"🧠 재순위화 점수 계산 완료 (보너스 포함)\")\n",
    "        return final_scores\n",
    "    \n",
    "    def _calculate_combined_scores(self, documents: List[Document], query: str, \n",
    "                                 bm25_scores: Dict[str, float], rerank_scores: Dict[str, float]) -> List[Tuple[float, Document]]:\n",
    "        \"\"\"문서들에 대한 BM25 + 재순위화 점수를 계산하여 반환\"\"\"\n",
    "        final_scored = []\n",
    "        self.last_scores= {}\n",
    "\n",
    "        # 1. 점수 정규화\n",
    "        scaled_bm25 = minmax_scale(bm25_scores)\n",
    "        scaled_rerank = minmax_scale(rerank_scores)\n",
    "\n",
    "        for doc in documents:\n",
    "            key = self.get_doc_key(doc)\n",
    "            bm25 = scaled_bm25.get(key, 0.0)\n",
    "            rerank = scaled_rerank.get(key, 0.0)\n",
    "            combined = self.bm25_weight * bm25 + self.rerank_weight * rerank\n",
    "            \n",
    "            self.last_scores[key] = {\n",
    "                \"bm25\": bm25,\n",
    "                \"rerank\": rerank,\n",
    "                \"combined\": combined\n",
    "            }\n",
    "            final_scored.append((combined, doc))\n",
    "    \n",
    "        return final_scored\n",
    "\n",
    "    def _debug_print_scores(self, documents: List[Document], search_type: str):\n",
    "        \"\"\"디버그 모드일 때 점수 정보 출력\"\"\"\n",
    "        if not self.debug_mode:\n",
    "            return\n",
    "            \n",
    "        logging.info(f\"{search_type} 점수 정보\")\n",
    "        for doc in documents:\n",
    "            key = self.get_doc_key(doc)\n",
    "            scores = self.last_scores.get(key, {})\n",
    "            bm25 = scores.get(\"bm25\", 0.0)\n",
    "            rerank = scores.get(\"rerank\", 0.0)\n",
    "            combined = scores.get(\"combined\", 0.0)\n",
    "\n",
    "            source = doc.metadata.get(\"파일명\", \"❓\")\n",
    "            chunk_index = doc.metadata.get(\"chunk_id\", \"❓\")\n",
    "            print(f\"🔍 {source} | Chunk {chunk_index} | BM25: {bm25:.2f} | Rerank: {rerank:.2f} | Combined: {combined:.2f}\")\n",
    "\n",
    "        \n",
    "    def _merge_search_results(self, vector_results: List[Document], bm25_results: List[Tuple[float, Document]]) -> Tuple[List[Document], Dict[str, float]]:\n",
    "        \"\"\"벡터와 BM25 검색 결과를 병합하고 점수 딕셔너리 반환\"\"\"\n",
    "        merged = {}\n",
    "        bm25_scores = {}\n",
    "        \n",
    "        # BM25 결과 우선 추가\n",
    "        for score, doc in bm25_results:\n",
    "            key = self.get_doc_key(doc)\n",
    "            merged[key] = doc\n",
    "            bm25_scores[key] = score\n",
    "        \n",
    "        # 벡터 결과에서 새로운 문서만 추가\n",
    "        for doc in vector_results:\n",
    "            key = self.get_doc_key(doc)\n",
    "            if key not in merged:\n",
    "                merged[key] = doc\n",
    "                bm25_scores[key] = 0.0\n",
    "        \n",
    "        return list(merged.values()), bm25_scores\n",
    "    \n",
    "    def hybrid_search(self, query: str, top_k: int = 3, candidate_size: int = 10,\n",
    "                      filter_dict: Dict = None, candidate_filenames: List[str] = None) -> List[Document]:\n",
    "        \"\"\"하이브리드 검색: 벡터 + BM25 + 재순위화 + 필터링\"\"\"\n",
    "        if self.db is None:\n",
    "            raise ValueError(\"Vector DB가 초기화되지 않았습니다.\")\n",
    "        if not self.bm25_ready:\n",
    "            raise ValueError(\"BM25 인덱스가 준비되지 않았습니다.\")\n",
    "    \n",
    "        if filter_dict:\n",
    "            logging.info(f\"🔍 하이브리드 필터 적용: {filter_dict}\")\n",
    "    \n",
    "        # 1. 단순 필터 (=)만 추출\n",
    "        simple_filter = {\n",
    "            key: val[\"value\"]\n",
    "            for key, val in filter_dict.items()\n",
    "            if val.get(\"operator\") == \"=\" and key != \"사업 요약\"\n",
    "        } or None\n",
    "    \n",
    "        # 2. 벡터 + BM25 검색\n",
    "        vector_results = self.db.similarity_search(query, k=candidate_size, filter=simple_filter)\n",
    "        bm25_results = self.bm25_search(query, k=candidate_size, filter=simple_filter)\n",
    "        \n",
    "        # 3. 파일명 기반 후보 제한 (metadata 쿼리일 때만 적용됨)\n",
    "        if candidate_filenames:\n",
    "            vector_results = [doc for doc in vector_results if doc.metadata.get(\"파일명\") in candidate_filenames]\n",
    "            bm25_results = [(score, doc) for score, doc in bm25_results if doc.metadata.get(\"파일명\") in candidate_filenames]\n",
    "            logging.info(f\"📁 파일명 기반 후보 제한 적용됨: {len(candidate_filenames)}개\")\n",
    "\n",
    "        # 4. 결과 병합\n",
    "        merged_docs, bm25_scores = self._merge_search_results(vector_results, bm25_results)\n",
    "    \n",
    "        # 5. 고급 조건 필터링 (>, < 등)\n",
    "        filtered_docs = [doc for doc in merged_docs if check_filter_match(doc.metadata, filter_dict)]\n",
    "        logging.info(f\"✅ 고급 필터링 후 문서 수: {len(filtered_docs)}\")\n",
    "    \n",
    "        final_docs_to_score = filtered_docs if filtered_docs else merged_docs\n",
    "        if not filtered_docs:\n",
    "            logging.warning(f\"⚠️ 필터링 결과 없음 → 원본 결과에서 상위 {top_k}개 반환\")\n",
    "    \n",
    "        # 6. 재순위화\n",
    "        rerank_scores = self.rerank_documents(query, final_docs_to_score)\n",
    "    \n",
    "        # 7. 최종 점수 계산 및 정렬\n",
    "        scored_docs = self._calculate_combined_scores(final_docs_to_score, query, bm25_scores, rerank_scores)\n",
    "        final_results = sorted(scored_docs, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "        if self.debug_mode:\n",
    "            self._debug_print_scores([doc for _, doc in final_results], \"하이브리드 검색\")\n",
    "    \n",
    "        logging.info(f\"📊 하이브리드 검색 완료: {len(final_results)} → {top_k}개 반환\")\n",
    "        return [doc for _, doc in final_results[:top_k]]\n",
    "\n",
    "\n",
    "    def detect_query_type(self, query: str, filters: Dict[str, Dict]) -> str:\n",
    "        normalized_query = query.replace(\" \", \"\").lower()\n",
    "        \n",
    "        explicit_summary_keywords = normalize_keywords([\n",
    "            \"사업요약\", \"공고요약\", \"사업개요\", \"공고개요\"\n",
    "        ])\n",
    "        \n",
    "        metadata_keywords = normalize_keywords([\n",
    "            \"사업금액\",  \"입찰일\", \"입찰시작일\", \"참여시작일\",\n",
    "            \"입찰마감일\", \"참여마감일\", \"공고번호\", \"공개일자\", \"입찰공고일\"\n",
    "        ])\n",
    "\n",
    "        if any(k in normalized_query for k in explicit_summary_keywords):\n",
    "            return \"metadata\"\n",
    "        if any(filters for field in metadata_keywords):\n",
    "            return \"metadata\"\n",
    "        return \"semantic\"\n",
    "\n",
    "    \n",
    "    def smart_search(self, query: str, top_k: int = 5, candidate_size: int = 10) -> List[Document]:\n",
    "        \"\"\"스마트 검색: 필터 추출 + 쿼리 유형 판단 + 하이브리드 검색\"\"\"\n",
    "        if self.db is None or not self.bm25_ready:\n",
    "            raise ValueError(\"❌ Vector DB 또는 BM25 인덱스가 준비되지 않았습니다.\")\n",
    "    \n",
    "        # 1. 필터 추출\n",
    "        filters = extract_filters(query, self.meta_df, self.tokenizer)\n",
    "        logging.info(f\"🧠 추출된 필터: {filters}\")\n",
    "    \n",
    "        # 2. 쿼리 유형 판단\n",
    "        query_type = self.detect_query_type(query, filters)\n",
    "    \n",
    "        # 3. 발주기관 키워드 제거\n",
    "        if filters.get(\"발주 기관\"):\n",
    "            agency_name = filters[\"발주 기관\"][\"value\"]\n",
    "            query = re.sub(rf\"\\b{re.escape(agency_name)}\\b\", \"\", query).strip()\n",
    "            logging.info(f\"🧹 쿼리에서 발주기관 키워드 제거됨: '{agency_name}'\")\n",
    "    \n",
    "        # 4. 메타데이터 기반 필터링 (metadata 쿼리일 때만)\n",
    "        matched_records = []\n",
    "        candidate_filenames = None\n",
    "        if query_type == \"metadata\" and self.meta_df is not None:\n",
    "            matched_df = self.meta_df[\n",
    "                self.meta_df.apply(lambda row: check_filter_match(row, filters), axis=1)\n",
    "            ]\n",
    "            logging.info(f\"📊 메타데이터 필터링 완료: {len(matched_df)}개\")\n",
    "    \n",
    "            if not matched_df.empty:\n",
    "                matched_records = matched_df.head(10).to_dict(orient=\"records\")\n",
    "                candidate_filenames = matched_df[\"파일명\"].dropna().unique().tolist()\n",
    "                logging.info(f\"📁 의미 검색 대상 제한됨 (파일명 기준): {len(candidate_filenames)}개\")\n",
    "            else:\n",
    "                logging.warning(\"⚠️ 메타데이터 필터링 결과 없음 → 전체 문서 대상으로 검색\")\n",
    "    \n",
    "        # 5. 하이브리드 검색 실행\n",
    "        logging.info(\"🔍 의미 기반 하이브리드 검색 실행\")\n",
    "        semantic_docs = self.hybrid_search(\n",
    "            query=query,\n",
    "            top_k=top_k,\n",
    "            candidate_size=candidate_size,\n",
    "            filter_dict=filters,\n",
    "            candidate_filenames=candidate_filenames\n",
    "        )\n",
    "        \n",
    "        return matched_records, semantic_docs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63000065-4e46-47c1-80ac-47e907cdc907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Union, Any, Optional\n",
    "\n",
    "FILTER_MAPPER = {\n",
    "    \"사업금액\": {\n",
    "        \"field\": \"사업 금액\", \n",
    "        \"type\": int,\n",
    "        \"pattern\": r\"(사업\\s?금액)?\\s*(\\d+[억만천백조]+)\\s*(이상|이하|초과|미만)?\"\n",
    "    },\n",
    "    \"입찰시작일\": {\n",
    "        \"field\": \"입찰 참여 시작일\",\n",
    "        \"type\": \"date\",\n",
    "        \"pattern\": r\"(입찰\\s?시작일|참여\\s?시작일)[^\\d]*(\\d{4})[년\\s]*(\\d{1,2})?[월]?\"\n",
    "    },\n",
    "    \"입찰마감일\": {\n",
    "        \"field\": \"입찰 참여 마감일\",\n",
    "        \"type\": \"date\",\n",
    "        \"pattern\": r\"(입찰\\s?마감일|참여\\s?마감일)[^\\d]*(\\d{4})[년\\s]*(\\d{1,2})?[월]?\"\n",
    "    },\n",
    "    \"입찰공고일\": {\n",
    "        \"field\": \"공개 일자\",\n",
    "        \"type\": \"date\",\n",
    "        \"pattern\": r\"(입찰\\s?공고일)[^\\d]*(\\d{4})[년\\s]*(\\d{1,2})?[월]?\"\n",
    "    },\n",
    "    \"발주기관\": {\n",
    "        \"field\": \"발주 기관\",  \n",
    "        \"type\": str,\n",
    "        \"pattern\": r\"(한국농어촌공사|조달청|도로공사|[가-힣]{2,})\"\n",
    "    },\n",
    "    \"공고번호\": {\n",
    "        \"field\": \"공고 번호\", \n",
    "        \"type\": str,\n",
    "        \"pattern\": r\"(공고번호\\s?\\d{4}-?\\d{3,})\"\n",
    "    },\n",
    "}\n",
    "def normalize_keywords(keywords: list[str]) -> set[str]:\n",
    "    \"\"\"키워드 리스트를 정규화하여 비교 가능하게 변환\"\"\"\n",
    "    return {k.replace(\" \", \"\").lower() for k in keywords}\n",
    "\n",
    "def safe_parse_date(value: str) -> Optional[datetime]:\n",
    "    if not isinstance(value, str):\n",
    "        return None\n",
    "    try:\n",
    "        parts = [int(p) for p in re.findall(r\"\\d+\", value)]\n",
    "        if len(parts) >= 2:\n",
    "            year, month = parts[0], parts[1]\n",
    "            day = parts[2] if len(parts) > 2 else 1\n",
    "            return datetime(year, month, day)\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"❌ 날짜 파싱 실패: {value} → {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_korean_number(text: str) -> int:\n",
    "    unit_values = {\n",
    "        \"십\": 10,\n",
    "        \"백\": 100,\n",
    "        \"천\": 1000,\n",
    "        \"만\": 10_000,\n",
    "        \"억\": 100_000_000,\n",
    "        \"조\": 1_000_000_000_000\n",
    "    }\n",
    "\n",
    "    # 정규화\n",
    "    text = text.replace(\",\", \"\").replace(\"억원\", \"억\").replace(\"백만원\", \"백만\") \\\n",
    "               .replace(\"천만원\", \"천만\").replace(\"만원\", \"만\").replace(\"원\", \"\").strip()\n",
    "    print(\"🌸 처리전 text:\", text)\n",
    "\n",
    "    # 단위별 블록 추출\n",
    "    blocks = re.findall(r\"(\\d+)([십백천만억조]+)\", text)\n",
    "\n",
    "    total = 0\n",
    "    current_block = 0\n",
    "    last_big_unit = 1\n",
    "\n",
    "    for num_str, unit_str in blocks:\n",
    "        num = int(num_str)\n",
    "        small_unit = 1\n",
    "        big_unit = 1\n",
    "\n",
    "        for char in unit_str:\n",
    "            if char in [\"십\", \"백\", \"천\"]:\n",
    "                small_unit *= unit_values[char]\n",
    "            elif char in [\"만\", \"억\", \"조\"]:\n",
    "                big_unit = unit_values[char]\n",
    "\n",
    "        current_block += num * small_unit\n",
    "\n",
    "        # 큰 단위가 붙었으면 전체 블록에 곱해서 total에 더함\n",
    "        if big_unit > 1:\n",
    "            total += current_block * big_unit\n",
    "            current_block = 0\n",
    "\n",
    "    total += current_block\n",
    "    print(\"🌸 처리완료후:\", total)\n",
    "    return total\n",
    "\n",
    "\n",
    "# 예시:\n",
    "# parse_korean_number(\"5천만원\")        # 50000000\n",
    "# parse_korean_number(\"1억 2천만원\")    # 120000000\n",
    "# parse_korean_number(\"2천만\")         # 20000000\n",
    "# parse_korean_number(\"3백억\")         # 30000000000\n",
    "# parse_korean_number(\"456백만\")       # 456000000\n",
    "\n",
    "\n",
    "def convert_value(raw: str, value_type):\n",
    "    \"\"\"필터 추출용 값 변환\"\"\"\n",
    "    if value_type in (\"int\", int):\n",
    "        return parse_korean_number(raw)\n",
    "    elif value_type in (\"date\", datetime):\n",
    "        return safe_parse_date(raw)\n",
    "    elif value_type in (\"float\", float):\n",
    "        try:\n",
    "            return float(str(raw).replace(\",\", \"\").strip())\n",
    "        except ValueError:\n",
    "            return None\n",
    "    else:\n",
    "        return raw.strip()\n",
    "\n",
    "\n",
    "OPERATOR_FUNC = {\n",
    "    \">=\": lambda v, t: v >= t,\n",
    "    \"<=\": lambda v, t: v <= t,\n",
    "    \">\":  lambda v, t: v > t,\n",
    "    \"<\":  lambda v, t: v < t,\n",
    "    \"=\":  lambda v, t: v == t,\n",
    "    \"~\":  lambda v, t: abs(v - t) <= t * 0.1\n",
    "}\n",
    "\n",
    "def extract_operator(text: str, context: str = \"\") -> str:\n",
    "    full_text = text + \" \" + context\n",
    "    if \"이후\" in full_text or \"부터\" in full_text or \"최소\" in full_text or \"이상\" in full_text:\n",
    "        return \">=\"\n",
    "    elif \"이전\" in full_text or \"까지\" in full_text or \"최대\" in full_text or \"이하\" in full_text:\n",
    "        return \"<=\"\n",
    "    elif \"초과\" in full_text:\n",
    "        return \">\"\n",
    "    elif \"미만\" in full_text:\n",
    "        return \"<\"\n",
    "    elif \"약\" in full_text or \"정도\" in full_text:\n",
    "        return \"~\"\n",
    "    return \"=\"\n",
    "\n",
    "\n",
    "# 🚨 기관명/파일명 필터링 시 제거할 잡음 단어 목록\n",
    "NOISE_WORDS = {\n",
    "     # 날짜/시점 관련\n",
    "    \"년\", \"월\", \"일\", \"년도\", \"2024\", \"2025\",\n",
    "\n",
    "    # 입찰/공고 관련\n",
    "    \"입찰\", \"공고\", \"재공고\", \"긴급\", \"협상\", \"사전공개\",\n",
    "\n",
    "    # 금액 관련\n",
    "    \"원\", \"예산\",\n",
    "\n",
    "}\n",
    "\n",
    "def extract_field_filter_by_tokens(\n",
    "    query: str,\n",
    "    field_values: List[str],\n",
    "    tokenizer,\n",
    "    field_name: str,\n",
    "    use_exact_match: bool = True,\n",
    "    threshold: float = 0.5\n",
    ") -> Optional[Dict[str, Dict]]:\n",
    "    \n",
    "    query_tokens = set(tokenizer.tokenize_korean(query, use_bigrams=False)) - NOISE_WORDS\n",
    "    print(\"❤️query_tokens\", query_tokens)\n",
    "    logging.debug(f\"🧹 필터링용 토큰셋: {query_tokens}\")\n",
    "\n",
    "    # 1️⃣ 정확 매칭 우선\n",
    "    if use_exact_match:\n",
    "        for value in field_values:\n",
    "            if value and value in query:\n",
    "                return {field_name: {\"value\": value, \"operator\": \"=\"}}\n",
    "\n",
    "    # 유사도 기반 매칭\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    for value in field_values:\n",
    "        match_count = sum(1 for token in query_tokens if token in value)\n",
    "        score = match_count / len(query_tokens) if query_tokens else 0\n",
    "        if score > best_score and score > threshold:\n",
    "            best_match = value\n",
    "            best_score = score\n",
    "           \n",
    "    if best_match:\n",
    "        print(\"❤️best_match\", best_match, best_score)\n",
    "        return {field_name: {\"value\": best_match, \"operator\": \"=\"}}\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_filters(query: str, meta_df: pd.DataFrame, tokenizer) -> Dict[str, Dict]:\n",
    "    filters = {}\n",
    "    \n",
    "    # 3️⃣ 정규식 기반 필터 추출\n",
    "    for keyword, filter_info in FILTER_MAPPER.items():\n",
    "        field_name = filter_info.get(\"field\")\n",
    "    \n",
    "        # ✅ 기관명/파일명은 정규식으로 추출하지 않음\n",
    "        if field_name in filters or field_name in [\"발주 기관\", \"파일명\"]:\n",
    "            continue\n",
    "            \n",
    "        match = re.search(filter_info['pattern'], query)\n",
    "        if match:\n",
    "            value_type = filter_info.get('type')\n",
    "            if value_type == \"date\":\n",
    "                year = match.group(2)\n",
    "                month = match.group(3) if match.lastindex and match.lastindex >= 3 and match.group(3) else \"1\"\n",
    "                raw_value = f\"{year}년 {month}월\"\n",
    "            elif value_type == int:\n",
    "                raw_value = match.group(2)\n",
    "                condition = match.group(3) or \"\"\n",
    "                operator = extract_operator(condition, query)\n",
    "            else:\n",
    "                raw_value = match.group(1)\n",
    "                operator = \"=\"\n",
    "    \n",
    "            value = convert_value(raw_value, value_type)\n",
    "            operator = extract_operator(raw_value, query) if value_type in [\"date\", int] else \"=\"\n",
    "            if value is not None:\n",
    "                filters[field_name] = {\"value\": value, \"operator\": operator}\n",
    "                logging.info(f\"📌 {field_name} 필터 적용됨: {value} ({operator})\")\n",
    "\n",
    "    # 발주 기관 필터링\n",
    "    agency_filter_applied = False\n",
    "    if \"발주 기관\" in meta_df.columns:\n",
    "        agency_list = meta_df[\"발주 기관\"].dropna().unique().tolist()\n",
    "        agency_filter = extract_field_filter_by_tokens(\n",
    "            query=query,\n",
    "            field_values=agency_list,\n",
    "            tokenizer=tokenizer,\n",
    "            field_name=\"발주 기관\",\n",
    "            use_exact_match=True,\n",
    "            threshold=0.5\n",
    "        )\n",
    "        \n",
    "        print(\"❤️agency_filter : \", agency_filter)\n",
    "        if agency_filter:\n",
    "            filters.update(agency_filter)\n",
    "            agency_filter_applied = True\n",
    "            logging.info(f\"🏢 발주 기관 필터 적용됨: {agency_filter['발주 기관']['value']}\")\n",
    "   \n",
    "    # 파일명 보조 필터링 (기관 필터 없을 때만)\n",
    "    if not agency_filter_applied and \"파일명\" in meta_df.columns:\n",
    "        filename_list = meta_df[\"파일명\"].dropna().unique().tolist()\n",
    "        print(\"❤️파일필터작동 \")\n",
    "        filename_filter = extract_field_filter_by_tokens(\n",
    "            query=query,\n",
    "            field_values=filename_list,\n",
    "            tokenizer=tokenizer,\n",
    "            field_name=\"파일명\",\n",
    "            use_exact_match=True,\n",
    "            threshold=0.5  # ✅ 더 유연하게\n",
    "        )\n",
    "        print(\"❤️file_filter : \", filename_filter)\n",
    "        if filename_filter:\n",
    "            filters.update(filename_filter)\n",
    "            logging.info(f\"📁 파일명 필터 적용됨: {filename_filter['파일명']['value']}\")\n",
    "\n",
    "    return filters\n",
    "\n",
    "\n",
    "def is_valid_value(value):\n",
    "    \"\"\"값이 유효한지 확인하는 헬퍼 함수\"\"\"\n",
    "    if value is None or str(value).strip() in [\"\", \"미정\", \"nan\"]:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_filter_match(data: Union[Dict, Any], filters: Dict[str, Dict]) -> bool:\n",
    "    for field, condition in filters.items():\n",
    "        raw_value = data.get(field)\n",
    "\n",
    "        if not is_valid_value(raw_value):\n",
    "            return False\n",
    "\n",
    "        target = condition[\"value\"]\n",
    "        operator = condition[\"operator\"]\n",
    "\n",
    "        # ✅ raw_value가 target과 같은 타입인지 확인\n",
    "        try:\n",
    "            if isinstance(target, int):\n",
    "                value = int(str(raw_value).replace(\",\", \"\").strip())\n",
    "            elif isinstance(target, float):\n",
    "                value = float(str(raw_value).replace(\",\", \"\").strip())\n",
    "            elif isinstance(target, datetime):\n",
    "                value = safe_parse_date(str(raw_value))\n",
    "            else:\n",
    "                value = str(raw_value).strip()\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "        compare_func = OPERATOR_FUNC.get(operator)\n",
    "        if not compare_func:\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            return compare_func(value, target)\n",
    "        except TypeError:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# 예시: '사업금액 5천만원 이상인 공고 찾아줘'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06380fd1-e56e-4af7-b466-66cb19745fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "def merge_docs_to_text(docs):\n",
    "    \"\"\"\n",
    "    의미 기반 검색 결과(Document 리스트)를 받아서\n",
    "    LLM context로 합치는 함수.\n",
    "    (문서 전체 내용을 합침, 잘라내기 제한 없음)\n",
    "    \"\"\"\n",
    "    if not docs:\n",
    "        return \"\"\n",
    "\n",
    "    merged = []\n",
    "    for doc in docs:\n",
    "        text = doc.page_content.strip()\n",
    "        merged.append(f\"[출처: {doc.metadata.get('파일명', '❓')}]\\n{text}\")\n",
    "\n",
    "    return \"\\n\\n\".join(merged)\n",
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY, \n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=1,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "다음은 사용자의 질문과 관련된 검색 결과입니다:\n",
    "\n",
    "{context}\n",
    "\n",
    "위 내용을 바탕으로 사용자의 질문에 대해 간결하고 정확하게 답변해주세요:\n",
    "질문: {question}\n",
    "\"\"\")\n",
    "\n",
    "qa_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fb5a1f7-d943-4969-9959-50aec34c0e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 08:41:54,096 - INFO - Load pretrained SentenceTransformer: nlpai-lab/KURE-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 디바이스: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 08:41:58,396 - INFO - 📦 캐시된 JSON 문서 로드 중...\n",
      "2025-09-26 08:41:58,492 - INFO - 🔧 가중치 설정됨 | BM25: 0.3 | Rerank: 0.7\n",
      "2025-09-26 08:41:58,493 - INFO - ✅ 기존 벡터 DB 로드 중...\n",
      "2025-09-26 08:41:59,400 - INFO - ⏩ 새 문서 없음, DB 추가 생략\n",
      "2025-09-26 08:42:01,306 - INFO - ✅ BM25 인덱스 로드 완료: /home/spai0320/projectmission2/data/cache/bm25_index.pkl\n",
      "2025-09-26 08:42:01,307 - INFO - 💡 리랭커 임베딩 캐싱 중...\n",
      "2025-09-26 08:42:01,387 - INFO - ✅ 리랭커 캐싱 완료.\n",
      "2025-09-26 08:42:01,390 - INFO - 🚀 모든 DB 및 인덱스 준비 완료.\n",
      "2025-09-26 08:42:01,390 - INFO - \n",
      "[스마트 검색 실행] 질문: 서울특별시 공공데이터 개방이나 연계 관련해서 어떤 요구사항이 있어?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 의미 임베딩 캐싱 완료 | 새로 캐싱: 0개 | 스킵: 7569개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 08:42:03,095 - INFO - 🏢 발주 기관 필터 적용됨: 서울특별시\n",
      "2025-09-26 08:42:03,098 - INFO - 🧠 추출된 필터: {'발주 기관': {'value': '서울특별시', 'operator': '='}}\n",
      "2025-09-26 08:42:03,100 - INFO - 🧹 쿼리에서 발주기관 키워드 제거됨: '서울특별시'\n",
      "2025-09-26 08:42:03,103 - INFO - 📊 메타데이터 필터링 완료: 1개\n",
      "2025-09-26 08:42:03,106 - INFO - 📁 의미 검색 대상 제한됨 (파일명 기준): 1개\n",
      "2025-09-26 08:42:03,107 - INFO - 🔍 의미 기반 하이브리드 검색 실행\n",
      "2025-09-26 08:42:03,107 - INFO - 🔍 하이브리드 필터 적용: {'발주 기관': {'value': '서울특별시', 'operator': '='}}\n",
      "2025-09-26 08:42:03,218 - INFO - 📁 파일명 기반 후보 제한 적용됨: 1개\n",
      "2025-09-26 08:42:03,220 - INFO - ✅ 고급 필터링 후 문서 수: 13\n",
      "2025-09-26 08:42:03,239 - INFO - 🧠 재순위화 점수 계산 완료 (보너스 포함)\n",
      "2025-09-26 08:42:03,241 - INFO - 하이브리드 검색 점수 정보\n",
      "2025-09-26 08:42:03,242 - INFO - 📊 하이브리드 검색 완료: 13 → 3개 반환\n",
      "2025-09-26 08:42:03,242 - INFO - 🧠 LLM 응답 생성 시작중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 BM25 키워드 토큰: ['서울특별시', '공공', '데이터', '개방', '연계', '관련', '요구', '사항', '서울특별시공공', '공공데이터', '데이터개방', '개방연계', '연계관련', '관련요구', '요구사항']\n",
      "❤️query_tokens {'공공', '사항', '데이터', '개방', '요구', '서울특별시', '관련', '연계'}\n",
      "❤️agency_filter :  {'발주 기관': {'value': '서울특별시', 'operator': '='}}\n",
      "\n",
      "📈 BM25 상위 문서 및 점수:\n",
      "BM25 문서 1 | 점수: 32.0440 | 출처: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "- 34 - 요구사항번호 DAR-009 요구사항 명 데이터 관리체계 수립 요구사항 분류 데이터 품질 상세 설명 정의 데이터 관리체계 수립 세부 내용 데이터 관리체계 정의 - 표준, 구조, 연계 등 데이터 핵심 요소의 지속적인 관리를 위한 조직과 역할을 정의하여야 함 - 데이터 값의 진단 및 개선 등 품질관리 조직과 역할을 정의하여야 함 - 데이터 값 진단 방안기능, 진단 프로그램 등을 제시하여야 함 - 데이터 표준단어용어도메인코드의 추가, 변경, 삭제 절차를 수립하여야 함. - 데이터 구조논리물리와 관련된 추가, 변경, 삭제 절차를\n",
      "----------------------------------------\n",
      "BM25 문서 2 | 점수: 17.1946 | 출처: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "- 18 - 3. 제안요청 내용 가. 요구사항 구성 요구사항 분류 설 명 요구사항 번호ID부여 규칙 요 구 사항수 시스템 장비구성ECR Equipment Composition Requirement - 목표시스템의 구성을 위해 필요한 하드웨어, 소프트웨어, 네트워크 등의 도입 장비 내역 등 시스템 장비 구성에 대한 요구사항 1 기능SFR System Function Requirement - 목표시스템이 반드시 수행해야 하거나 목표시스템을 이용하여 사용자가 반드시 수행할 수 있어야 하는 기능동작 개발 요구사항 14 성능PER PErfo\n",
      "----------------------------------------\n",
      "BM25 문서 3 | 점수: 16.1662 | 출처: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "- 46 - 요구사항번호 COR-010 요구사항 명 웹사이트홈페이지, 모바일웹앱 서비스 이용현황 분석시스템 활용 요구사항 분류 제약사항 상세 설명 정의 서울시 통합 웹앱로그 분석시스템 활용에 관한 사항 세부 내용 서울시 웹앱서비스 신규 구축 및 리뉴얼 시 통합 웹앱 로그 분석시스템을 활용하여 방문자의 이용현황 분석을 실시해야 함 실시간 웹앱로그 수집 및 분석을 위해 뉴미디어담당관홈페이지팀에서 제공하는 가이 드에 따라 스크립트SDK 적용 작업 실시 - 신규 서비스 오픈 전 또는 콘텐츠 추가변경 시 모든 페이지에 필수 적용 - PC용웹\n",
      "----------------------------------------\n",
      "BM25 문서 4 | 점수: 15.8963 | 출처: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "- 30 - 요구사항번호 UIR-001 요구사항 명 매력서울지도 UI 구성 요구사항 분류 인터페이스 요구사항 상세 설명 정의 사용자 특성을 고려하되 스마트서울맵과 통일성 있는 지도 화면UI 설계 세부 내용 m 매력서울지도 화면UI 구성 - 구글, 네이버 등 주요 시민 대상 지도 서비스 UI 동향 조사4종 이상 - 스마트서울맵과 통일된 지도 기능으로 구현하되 사용자 특성을 고려한 설계 - 스마트폰과 PC에서 이질감 없는 UI 제공 - 다국어 자동 번역에도 공통활용 가능한 GUI 채택 산출정보 m 국내외 지도 서비스 UI 동향 조사서,\n",
      "----------------------------------------\n",
      "BM25 문서 5 | 점수: 15.1356 | 출처: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "- 44 - 요구사항번호 COR-005 요구사항 명 웹사이트홈페이지, 모바일웹 웹접근성 준수 요구사항 분류 제약사항 상세 설명 정의 웹사이트 장애인 웹접근성 준수 의무에 관한 사항 세부 내용 웹사이트 웹접근성을 준수하여 사업을 추진해야 하며 아래 항목을 이행하여야 함. - 과학기술정보통신부 웹접근성 품질마크 인증 기준에 맞게 구축하여야 함. 한국지능정보사회진흥원 웹접근성 연구소httpwww.wah.or.kr의 웹콘텐츠 제작기법 참고 - 웹접근성 준수 증빙 서류 제출 제출주기 상호협의 후 최소 반기별 제출 제출서식 웹접근성 진단 체크\n",
      "----------------------------------------\n",
      "BM25 문서 6 | 점수: 14.8698 | 출처: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "- 26 - 요구사항번호 SFR-010 요구사항 명 매력서울지도사진정보를 활용한 지오태깅으로 매력서울 이미지 아카이빙 맵 구축 요구사항 분류 기능 요구사항 상세 설명 정의 스마트기술 활용 여행객 맞춤 매력서울지도 다국어 서비스 구축 세부 내용 m 이미지 지오태깅 기술 적용 - 사용자 사진 등록 시 사진정보EXIF를 활용한 지오태깅 기능 구현 사진정보EXIF가 없는 이미지는 등록자가 지도에서 위치 등록 - 사진 로딩속도 및 안정적 시스템 자원 운용을 위한 해상도 기준 마련 및 업로드 이미지 리사이징 기술 적용 - 이미지 외 URL 링\n",
      "----------------------------------------\n",
      "BM25 문서 7 | 점수: 13.3344 | 출처: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "- 138 - 구 분 항 목 적용계획결과 부분적용 미 적용시 사유 및 대체기술 적용 부분 적용 미 적용 해당 없음 하여야 하며 그렇지 못한 경우에는 행정기관등의 장이 그 사유를 행정안전부장관에게 보고하고 행정안전부의행정기관의 코드표 준화 추진지침에 따라 코드체계 및 코드를 생성하여 행정안전부장 관에게 표준 등록을 요청하여야 한다. o 패키지소프트웨어는 타 패키지소프트웨어 또는 타 정보시스템과의 연계를 위해 데이터베이스 사용이 투명해야 하며 다양한 유형의 인터페이스를 지원하여야 한다. 세부 기술 지침 관련규정 o 공공기관의 데이터베이\n",
      "----------------------------------------\n",
      "BM25 문서 8 | 점수: 13.0853 | 출처: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "- 100 - 구 분 항 목 적용계획결과 부분적용 미 적용시 사유 및 대체기술 적용 부분 적용 미 적용 해당 없음 o 행정정보의 공동활용에 필요한 행정코드는 행정표준코드를 준수 하여야 하며 그렇지 못한 경우에는 행정기관등의 장이 그 사유를 행정안전부장관에게 보고하고 행정안전부의행정기관의 코드표 준화 추진지침에 따라 코드체계 및 코드를 생성하여 행정안전부장 관에게 표준 등록을 요청하여야 한다. O o 패키지소프트웨어는 타 패키지소프트웨어 또는 타 정보시스템과의 연계를 위해 데이터베이스 사용이 투명해야 하며 다양한 유형의 인터페이스를 \n",
      "----------------------------------------\n",
      "BM25 문서 9 | 점수: 12.6239 | 출처: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "- 42 - 9 제약사항 요구사항번호 COR-001 요구사항 명 사업관련 공통 규정 준수 요구사항 분류 제약사항 상세 설명 정의 정보화사업 추진 시 기본규정 준수에 관한 사항 세부 내용 m 사업 추진 시 행정기관 및 공공기관 정보시스템 구축운영 지침행정안전부 고시 에 규정된 사항을 준수하여야 함 m 사업 추진 기간 내 적용 법령 및 규정, 적용 표준 등에 변경사항 발생 시 반영하여 사업 추진하여야 함. 변경 사항의 적용시점을 고려하여 발주기관과 협의하여 적용 요구사항번호 COR-002 요구사항 명 사업관련 공통 기술표준 준수 요구사\n",
      "----------------------------------------\n",
      "BM25 문서 10 | 점수: 12.5702 | 출처: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "- 40 - 요구사항번호 SER-004 요구사항 명 개인정보의 처리단계별 보호조치 요구사항 분류 보안 요구사항 상세 설명 정의 개인정보의 안전성 확보를 위한 처리단계별 조치사항 세부 내용 m 개인정보 수집 및 이용 대한 동의 개인정보 보호법 제15조제18조 - 개발 혹은 구축하려는 시스템이 개인정보 수집이용에 대한 동의가 필요한 경우 홈페이지 회원가입, 게시판 이용 시 개인정보 수집 등, 안전하게 발주자가 정보주체 로부터 개인정보를 수집이용하기 위한 환경을 고려하여 개발구축하여야 함 고유식별정보 또는 민감정보를 포함하여 수집할 경우\n",
      "----------------------------------------\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::19::type::text | BM25: 10.00 | Rerank: 10.00 | Combined: 10.00\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::25::type::text | BM25: 5.05 | Rerank: 7.12 | Combined: 6.50\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::17::type::text | BM25: 4.96 | Rerank: 7.12 | Combined: 6.47\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::11::type::text | BM25: 5.37 | Rerank: 5.73 | Combined: 5.62\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::15::type::text | BM25: 4.64 | Rerank: 5.60 | Combined: 5.31\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::22::type::text | BM25: 3.92 | Rerank: 5.69 | Combined: 5.16\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::23::type::text | BM25: 3.94 | Rerank: 5.64 | Combined: 5.13\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::50::type::text | BM25: 0.00 | Rerank: 7.09 | Combined: 4.96\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::24::type::text | BM25: 4.72 | Rerank: 4.29 | Combined: 4.42\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::69::type::text | BM25: 0.00 | Rerank: 5.65 | Combined: 3.95\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::71::type::text | BM25: 4.16 | Rerank: 2.86 | Combined: 3.25\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::52::type::text | BM25: 4.08 | Rerank: 2.88 | Combined: 3.24\n",
      "🔍 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf | Chunk 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::70::type::text | BM25: 0.00 | Rerank: 0.00 | Combined: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 08:42:08,957 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-26 08:42:08,971 - INFO - 🧠 LLM 응답 생성 완료 (소요 시간: 5.73초)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧠 LLM 응답 생성 응답:\n",
      "서울특별시 공공데이터 개방 및 연계 관련 요구사항은 다음과 같습니다:\n",
      "\n",
      "1. **개방 데이터 관리체계**:\n",
      "   - 개방 데이터 서비스의 연속성을 확보하고, 관련 개방 데이터 목록을 식별해야 합니다.\n",
      "   - 공공데이터 제공 및 이용 활성화를 위한 법률 및 조례를 준수하며, 개방대상 데이터에 대해 시스템 DB 연계 등 관련 업무를 지원해야 합니다.\n",
      "\n",
      "2. **연계 데이터 관리체계**:\n",
      "   - 제공기관과 활용기관 간의 연계 데이터 정합성을 유지하기 위한 방안을 제시해야 하며, 메타데이터를 작성하고 표준화해야 합니다.\n",
      "   - 연계 데이터 품질 확보를 위해 협의체를 구성하고 정기적인 데이터 정합성 검증을 실시해야 합니다.\n",
      "\n",
      "3. **데이터 표준화 및 관리**:\n",
      "   - 데이터 표준 원칙 및 가이드를 수립하고, 범정부 및 서울시 표준을 준수해야 합니다.\n",
      "   - 데이터 표준 관리 방안을 마련하여 메타데이터 관리 시스템 등을 통해 변경 이력을 효과적으로 관리해야 합니다.\n",
      "\n",
      "이와 같은 요구사항을 충족함으로써 서울특별시의 공공데이터 개방과 연계 체계를 효과적으로 구축할 수 있습니다.\n",
      "\n",
      "📈 반환 문서 내용:\n",
      "\n",
      "📊 메타데이터 필터링 결과 (최대 10개):\n",
      "\n",
      "📄 문서 1\n",
      "🔹 공고 번호: 20240404154\n",
      "🔹 공고 차수: 0.0\n",
      "🔹 사업명: 2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용역\n",
      "🔹 사업 금액: 493763000\n",
      "🔹 발주 기관: 서울특별시\n",
      "🔹 공개 일자: 2024-04-02 15:49:39\n",
      "🔹 입찰 참여 시작일: 2024-04-19 09:00:00\n",
      "🔹 입찰 참여 마감일: 2024-04-23 16:00:00\n",
      "🔹 사업 요약: - 사업개요: 2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 구축\n",
      "- 추진배경 및 필요성: 외래관광객 유치, 개인화 및 로컬화된 관광 트렌드에 맞는 서비스 필요\n",
      "- 사업범위: 매력서울지도 다국어 서비스 구축, 지도정보 플랫폼 고도화, 시각화 서비스 및 주소-좌표 변환 기능 고도화\n",
      "- 기대효과: 소통행정 혁신, 외국인 관광객 편의 서비스 확대, 동행매력특별시 서울 정책 홍보, 다양한 지도 시각화 기능 제공\n",
      "🔹 파일형식: pdf\n",
      "🔹 파일명: 서울특별시_2024년 지도정보 플랫폼 및 전문활용 연계 시스템 고도화 용.pdf\n",
      "🔹 공고번호_결측: False\n",
      "🔹 공고차수_결측: False\n",
      "🔹 입찰참여시작일_결측: False\n",
      "🔹 입찰참여마감일_결측: False\n",
      "🔹 사업금액_결측: False\n",
      "==================================================\n",
      "문서 1 | 출처: 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::19::type::text\n",
      "🔹 BM25 점수: 10.00 | 🔹 Rerank 점수: 10.00 | 🔹 Combined: 10.00\n",
      "- 34 - 요구사항번호 DAR-009 요구사항 명 데이터 관리체계 수립 요구사항 분류 데이터 품질 상세 설명 정의 데이터 관리체계 수립 세부 내용 데이터 관리체계 정의 - 표준, 구조, 연계 등 데이터 핵심 요소의 지속적인 관리를 위한 조직과 역할을 정의하여야 함 - 데이터 값의 진단 및 개선 등 품질관리 조직과 역할을 정의하여야 함 - 데이터 값 진단 방안기능, 진단 프로그램 등을 제시하여야 함 - 데이터 표준단어용어도메인코드의 추가, 변경, 삭제 절차를 수립하여야 함. - 데이터 구조논리물리와 관련된 추가, 변경, 삭제 절차를 수립하여야 함 - 데이터 연계목록 및 항목의 추가, 변경, 삭제 절차의 정의 절차를 수립하여야 함. 연계 시스템 도입 시 시스템과 연계된 체계 수립 - 오류 데이터의 진단 및 개선 절차를 제시하여야 함 산출정보 데이터표준, 구조, 연계, 품질 관리 체계서 요구사항번호 DAR-010 요구사항 명 연계 데이터 관리체계 수립 요구사항 분류 데이터 품질 상세 설\n",
      "==================================================\n",
      "문서 2 | 출처: 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::25::type::text\n",
      "🔹 BM25 점수: 5.05 | 🔹 Rerank 점수: 7.12 | 🔹 Combined: 6.50\n",
      "- 46 - 요구사항번호 COR-010 요구사항 명 웹사이트홈페이지, 모바일웹앱 서비스 이용현황 분석시스템 활용 요구사항 분류 제약사항 상세 설명 정의 서울시 통합 웹앱로그 분석시스템 활용에 관한 사항 세부 내용 서울시 웹앱서비스 신규 구축 및 리뉴얼 시 통합 웹앱 로그 분석시스템을 활용하여 방문자의 이용현황 분석을 실시해야 함 실시간 웹앱로그 수집 및 분석을 위해 뉴미디어담당관홈페이지팀에서 제공하는 가이 드에 따라 스크립트SDK 적용 작업 실시 - 신규 서비스 오픈 전 또는 콘텐츠 추가변경 시 모든 페이지에 필수 적용 - PC용웹모바일웹모바일앱 유형에 따라 특성에 맞는 스크립트SDK 적용 통합 웹앱로그 분석시스템 결과를 활용하여 웹앱사이트 개선 및 이용활성화 방안 마 련에 활용 - 실시간 분석 결과 및 방문자 이동경로 분석 등 자료 활용 산출정보 관련요구사항 - 요구사항번호 COR-011 요구사항 명 감리 대응 요구사항 분류 제약사항 상세 설명 정의 감리 대응에 관한 사항 세부 내\n",
      "==================================================\n",
      "문서 3 | 출처: 20240404154_2024년_지도정보_플랫폼_및_전문활용_연계_시스템_고도화_용역.json::page::17::type::text\n",
      "🔹 BM25 점수: 4.96 | 🔹 Rerank 점수: 7.12 | 🔹 Combined: 6.47\n",
      "- 30 - 요구사항번호 UIR-001 요구사항 명 매력서울지도 UI 구성 요구사항 분류 인터페이스 요구사항 상세 설명 정의 사용자 특성을 고려하되 스마트서울맵과 통일성 있는 지도 화면UI 설계 세부 내용 m 매력서울지도 화면UI 구성 - 구글, 네이버 등 주요 시민 대상 지도 서비스 UI 동향 조사4종 이상 - 스마트서울맵과 통일된 지도 기능으로 구현하되 사용자 특성을 고려한 설계 - 스마트폰과 PC에서 이질감 없는 UI 제공 - 다국어 자동 번역에도 공통활용 가능한 GUI 채택 산출정보 m 국내외 지도 서비스 UI 동향 조사서, 화면UI정의서 관련요구사항 SFR-007 5 데이터 요구사항 요구사항번호 DAR-001 요구사항 명 데이터 표준화 요구사항 분류 데이터 품질 상세 설명 정의 데이터 표준 원칙 및 가이드 수립 세부 내용 데이터 표준 원칙 및 가이드 수립 - 구축되는 시스템의 데이터 특성을 고려하여 표준화 관리체계데이터 표준화 지침 및 가이드 등를 개선정비하여야 함. 범정부\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import logging\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from config import Config\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 설정 로드\n",
    "    cfg = Config()\n",
    "    \n",
    "    # 기본 설정\n",
    "    LOAD_MODE = \"json\"\n",
    "    TOKENIZER = \"kiwi\"\n",
    "    \n",
    "    # 메타데이터 로드\n",
    "    meta_df = pd.read_csv(cfg.meta_csv_path)\n",
    "    \n",
    "    # 디바이스 설정\n",
    "    import torch\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"✅ 디바이스: {device}\")\n",
    "    \n",
    "    # 모델 초기화 (외부에서 로드하여 캐시화)\n",
    "    embedder = HuggingFaceEmbeddings(\n",
    "        model_name=cfg.embedder_model,\n",
    "        model_kwargs={\"device\": device}\n",
    "    )\n",
    "\n",
    "    reranker = RerankModel(\n",
    "        model_name=cfg.reranker_model,\n",
    "        cache_dir=cfg.rerank_cache_dir,\n",
    "        device=device\n",
    "    )\n",
    "        \n",
    "    tokenizer = TokenizerWrapper(TOKENIZER)\n",
    "    \n",
    "    # Retriever 초기화 \n",
    "    retriever = Retriever(\n",
    "        meta_df=meta_df,\n",
    "        embedder=embedder,\n",
    "        reranker=reranker,\n",
    "        tokenizer=tokenizer,\n",
    "        persist_directory=cfg.chroma_db_path,\n",
    "        rerank_max_length=cfg.rerank_max_length,\n",
    "        bm25_path=cfg.bm25_path,\n",
    "        debug_mode=True\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # 문서 로딩 (기존 로직 100% 보존)\n",
    "        if LOAD_MODE == \"json\":\n",
    "            docs = await retriever.load_or_cache_json_docs(\n",
    "                cfg.json_dir, \n",
    "                cache_path=cfg.cached_json_path\n",
    "            )\n",
    "        \n",
    "        # 가중치 설정 및 벡터 DB 구축 (기존과 동일)\n",
    "        retriever.set_weights(bm25_weight=0.3, rerank_weight=0.7)\n",
    "        retriever.load_or_build_vector_db(docs)\n",
    "        \n",
    "        # 검색 실행\n",
    "        query_text = \"서울특별시 공공데이터 개방이나 연계 관련해서 어떤 요구사항이 있어?\"\n",
    "        logging.info(f\"\\n[스마트 검색 실행] 질문: {query_text}\")\n",
    "        \n",
    "        tokenized_query = retriever.tokenizer.tokenize_korean(query_text)\n",
    "        print(f\"\\n🔍 BM25 키워드 토큰: {tokenized_query}\")\n",
    "        \n",
    "        matched_records, semantic_docs = retriever.smart_search(\n",
    "            query=query_text,\n",
    "            top_k=3,\n",
    "            candidate_size=10,\n",
    "        )\n",
    "\n",
    "        # LLM 응답 생성\n",
    "        logging.info(\"🧠 LLM 응답 생성 시작중...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        merged_text = merge_docs_to_text(semantic_docs)\n",
    "        response = qa_chain.invoke({\n",
    "            \"context\": merged_text,\n",
    "            \"question\": query_text\n",
    "        })\n",
    "       \n",
    "        final_answer = response.get(\"text\", \"\").strip()      \n",
    "        print(\"\\n🧠 LLM 응답 생성 응답:\")\n",
    "        print(final_answer)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        logging.info(f\"🧠 LLM 응답 생성 완료 (소요 시간: {elapsed:.2f}초)\")\n",
    "        \n",
    "        print(\"\\n📈 반환 문서 내용:\")\n",
    "        \n",
    "        # 참고용 메타데이터 출력 (최대 10개)\n",
    "        if matched_records:\n",
    "            print(\"\\n📊 메타데이터 필터링 결과 (최대 10개):\")\n",
    "            for i, record in enumerate(matched_records, 1):\n",
    "                print(f\"\\n📄 문서 {i}\")\n",
    "                for key, value in record.items():\n",
    "                    print(f\"🔹 {key}: {value}\")\n",
    "                print(\"=\" * 50)\n",
    "        \n",
    "        # 의미 기반 검색 결과\n",
    "        for i, doc in enumerate(results, 1):\n",
    "            key = retriever.get_doc_key(doc)\n",
    "            scores = retriever.last_scores.get(key, {})\n",
    "            bm25 = scores.get(\"bm25\", 0.0)\n",
    "            rerank = scores.get(\"rerank\", 0.0)\n",
    "            combined = scores.get(\"combined\", 0.0)\n",
    "    \n",
    "            print(f\"문서 {i} | 출처: {doc.metadata.get('chunk_id')}\")\n",
    "            print(f\"🔹 BM25 점수: {bm25:.2f} | 🔹 Rerank 점수: {rerank:.2f} | 🔹 Combined: {combined:.2f}\")\n",
    "            print(doc.page_content[:500])\n",
    "            print(\"=\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"오류: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd974b48-b167-414e-b255-14412b7d25bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-26 02:43:04,582 - INFO - \n",
      "[스마트 검색 실행] 질문: 사업금액 100억이상 공고 알려줘\n",
      "2025-09-26 02:43:04,587 - INFO - 📌 사업 금액 필터 적용됨: 10000000000 (>=)\n",
      "2025-09-26 02:43:04,592 - INFO - 🧠 추출된 필터: {'사업 금액': {'value': 10000000000, 'operator': '>='}}\n",
      "2025-09-26 02:43:04,594 - INFO - 🔍 의미 기반 하이브리드 검색 실행\n",
      "2025-09-26 02:43:04,595 - INFO - 🔍 하이브리드 필터 적용: {'사업 금액': {'value': 10000000000, 'operator': '>='}}\n",
      "2025-09-26 02:43:04,671 - INFO - ✅ 고급 필터링 후 문서 수: 0\n",
      "2025-09-26 02:43:04,673 - WARNING - ⚠️ 필터링 결과가 없습니다. 원본 결과에서 상위 {top_k}개 반환합니다.\n",
      "2025-09-26 02:43:04,724 - INFO - 🧠 재순위화 점수 계산 완료 (보너스 포함)\n",
      "2025-09-26 02:43:04,725 - INFO - 하이브리드 검색 점수 정보\n",
      "2025-09-26 02:43:04,726 - INFO - 📊 하이브리드 검색 완료: 20 → 3개 반환\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 BM25 키워드 토큰: ['사업', '금액', '이상', '공고', '사업금액', '금액이상', '이상공고']\n",
      "🌸 처리전 text: 100억\n",
      "🌸 처리완료후: 10000000000\n",
      "❤️query_tokens {'금액', '사업', '이상'}\n",
      "❤️agency_filter :  None\n",
      "❤️파일필터작동 \n",
      "❤️query_tokens {'금액', '사업', '이상'}\n",
      "❤️file_filter :  None\n",
      "\n",
      "📈 BM25 상위 문서 및 점수:\n",
      "BM25 문서 1 | 점수: 23.7156 | 출처: 세종테크노파크_세종테크노파크 인사정보 전산시스템 구축 용역 입찰공.pdf\n",
      "- 45 - 새로운 신용평가등급이 없는 경우에는 합병 대상업체 중 가장 낮은 신용평가등급을 받은 업체의 신용평가등급으로 평가 2 유사사업 수행실적 평가 배점 기준 및 유사용역 기준은 아래와 같음 항목 계산 방법 배점한도 기 준 배점 유사 사업 실적 건수 준공실적 건수 4 A. 사업수행 5건 이상 4 B. 사업수행 4건 이상 3 C. 사업수행 3건 이상 2 D. 사업수행 2건 이상 1 항목 계산 방법 배점한도 기 준 배점 유사 사업 실적 금액 본사업비 준공실적금액 3 A. 200이상 3 B. 100이상 - 200미만 2 C. 100미\n",
      "----------------------------------------\n",
      "BM25 문서 2 | 점수: 21.7840 | 출처: 수협중앙회_강릉어선안전조업국 상황관제시스템 구축.pdf\n",
      "- 59 - 별첨 1 기술평가객관적 평가기준 및 채점표 평 가 위 원 성 명 서명 제안업체명 가. 경영상태 평가항목 평 가 요 소 배점 기준 경영상태 회사채에 대한 신용평가등급 AAA 5.0 AA, AA0, AA- 4.5 A, A0, A- 4.0 BBB 3.5 BBB0, BBB- 3.0 BB, BB0 2.5 BB- 2.0 B, B0 1.5 B- 1.0 CCC 이하 0.5 나. 유사용역실적 평가항목 평 가 요 소 배점 기준 유사 분야에서의 유지보수 경험 용역 또는 구축 경험실적 최근3년 유사사업 수행실적 총금액 12억 이상 10 유사\n",
      "----------------------------------------\n",
      "BM25 문서 3 | 점수: 19.5945 | 출처: 축산물품질평가원_축산물이력관리시스템 개선(정보화 사업).pdf\n",
      "- 45 - 본 사업 과업의 일부를 하도급 하려는 경우 입찰 및 계약체결 시 소 프트웨어사업 계약 및 관리감독에 관한 지침제19조에 따른 소프트웨 어 하도급 계획서를 제출하여야 함 하도급계약의 승인을 신청하는 경우, 소프트웨어사업 계약 및 관리감 독에 관한 지침제19조에 따른 하도급계약의 적정성판단 세부기준에 의거하여, 평가점수가 85점 이상인 경우에 한하여 하도급 계약을 승인 함. 다만, 85점 이상인 경우라 하더라도 하도급 계약의 세부 조건 등 으로 인하여 사업의 원활한 수행이 불가능하다고 인정되는 경우 그 사유를 기재하여 하도\n",
      "----------------------------------------\n",
      "BM25 문서 4 | 점수: 19.3042 | 출처: 남서울대학교_[혁신-국고] 남서울대학교 스마트 정보시스템 활성화(학사.pdf\n",
      "- 29 - 제안사는 종전의소프트웨어산업 진흥법제24조 등에 따라 최근년도 결산 신고된 소프트웨어사업자 신고확인서혹은 개정 법령소프트웨어 진흥법제58조제2항 및 같은 법 시행규칙 제17조에 따른 소프트웨어사업자 일반 현황 관리확인서를 제출하여야 함 상호출자제한기업집단 소속기업 및 대기업 참여제한 -소프트웨어 진흥법제48중소 소프트웨어사업자의 사업참여 지원 제4항에 따라 상호출자제한기업집단에 속하는 업체는 입찰 참여를제한함 - 본 사업은 20억 미만의 사업으로써,소프트웨어 진흥법제48조 중소 소프트웨어사업자의 사업참여 지원 제2항 및\n",
      "----------------------------------------\n",
      "BM25 문서 5 | 점수: 18.9402 | 출처: 경상북도 봉화군_봉화군 재난통합관리시스템 고도화 사업(협상)(긴급).pdf\n",
      "- 64 - 별지서식 7호 사업수행 실적증명서 신 청 인 업체명 대 표 자 영업소재지 전화번호 사업자번호 법인등록번호 증명서 용도 입찰 및 제안서 심사 제출용 제 출 처 국가기관, 지방자치단체 및 공공기관 사업이행 실적내용 사 업 명 구 분 소프트웨어개발 유지관리운영위탁 정보통신 기타 사업개요 사업금액 VAT 포함 계약일자계약기간 계약금액 VAT 포함 소프트웨어개발 분야 용역이행 실적 완료일자 비율 실적원 증 명 서 발급기관 위 사실을 증명함. 년 월 일 기관명 인 전화번호 주 소 발급부서 담당자 전화번호 사업수행실적은 입찰공고일 \n",
      "----------------------------------------\n",
      "BM25 문서 6 | 점수: 18.7667 | 출처: 한국건강가정진흥원_2025년 아이돌봄인력 인적성 검사 정보시스템 운영.pdf\n",
      "- 38 - 보호 및 지원에 관한 법률제2조에 따른 소상공인으로서중소 기업 범위 및 확인에 관한 규정에 따라 발급된 중소기업 소상공인 확인서를 소지한 업체입찰 참가 마감일 전일까지 발 급된 것으로 유효기간 내에 한함 ᄋ 중소기업제품 구매촉진 및 판로지원에 관한 법률에 의한 중소기 업자로서중소기업자간 경쟁제품 직접생산 확인기준중소벤처 기업부 고시에 따라 직접생산확인증명서정보시스템유지관리서 비스,세부품명번호 8111189901를 소지한 업체입찰참가등록 마감일 이전 발행된 것으로 유효기간 내에 있어야 함 ᄋ 상호출자제한기업집단 소속기업 \n",
      "----------------------------------------\n",
      "BM25 문서 7 | 점수: 18.6964 | 출처: 한국농어촌공사_아세안+3 식량안보정보시스템(AFSIS) 3단계 협력(캄보디아.pdf\n",
      "- 65 - 2 회사 유사사업 수행실적 5점 실적인정범위 공고일 기준 최근 20년 이내완료한 실적 - 진행 중인 사업 실적 불인정 - 실적증명서 미제출 시 실적 불인정 공동으로 수행한 실적의 경우, 제안 업체의 참여지분율을 곱하여 산정한 금액또는 분담부분에 해당되는 금액을 기준으로 하여야 함 공동수급체 구성 시 구성원별 수행 실적에 제안 업체의 사업 참여 지분 율을곱하여 산정한 후, 이를 합산하여 평가 유사사업 1년 이상 프로젝트성 해외사업으로서 아래 조건 중 최소 한 가지를 만족하는 사업 - 정보시스템사업, 수치지도제작업, 소프트\n",
      "----------------------------------------\n",
      "BM25 문서 8 | 점수: 18.3382 | 출처: 경상북도 봉화군_봉화군 재난통합관리시스템 고도화 사업(협상)(긴급).pdf\n",
      "- 59 - 별지서식 2호 입 찰 참 가 신 청 서 입 찰 입찰공고번호 봉화군 공고 제20 - 호 입 찰 일 자 20 . . . 입 찰 건 명 입 찰 보 증 금 보증금액 금 원정 원 사 용 인 감 본 건의 입찰 및 계약에 사용할 인감을 다음과 같이 신고합니다. 보증금율 입찰금액의 5100 이상 납부면제 및 지급확약 본인은 낙찰 후 계약 미체결시 낙찰금액에 해당하는 소정의 입찰보증금을 현금으로 납부할 것을 확약함 대 리 인 본 입찰에 관한 일체 권한을 다음의 자에게 위임합니다. 소속 전화번호 성명 생년월일 20 년 월 일자로 공고한 \n",
      "----------------------------------------\n",
      "BM25 문서 9 | 점수: 18.1726 | 출처: 한국수출입은행_(긴급) 모잠비크 마푸토 지능형교통시스템(ITS) 구축사업.pdf\n",
      "- 61 - 서식 1 입 찰 참 가 신 청 서 신 청 인 상호 및 법인명칭 법인등록번호 주 소 전 화 번 호 대 표 자 생 년 월 일 입찰 개요 입찰공고지명 번호 - 입 찰 일 자 입 찰 건 명 사 업 명FS 용역 입 찰 보 증 금 납 부 보 증 액 입찰금액의 1000분의 25이상 보증금납부방법 작성예시 입찰보증금 지급각서 제출 납 부 면 제 및 지 급 확 약 작성 예시, 불필요시 삭제 요망 본인은 낙찰 후 계약 미체결시 귀 은행에 입찰보증금에 해당하는 금액을 현금으로 납입할 것을 확약합니다. 입찰 참여대리인사용인감 본 입찰에 관한\n",
      "----------------------------------------\n",
      "BM25 문서 10 | 점수: 18.0688 | 출처: 한국보육진흥원_연차별 자율 품질관리 시스템 기능개선.pdf\n",
      "- 75 - 별표 2 보안 위약금 부과 기준 보안 위약금 부과 기준 1. 위규 수준별로 AD 등급으로 차등 부과 구분 위규 수준 A급 B급 C급 D급 위규 심각 1건 중대 1건 이상 미흡 2건 이상 경미 3건 이상 제재 및 위약금 부정당업자 등록 사업금액의 0.027 사업금액의 0.021 사업금액의 0.015 위약금은 매 점검 또는 보안 사고 적발, 보안 사고 발생 별로 부과 위규 수준은 별표1 참고 2. 보안 위약금은 다른 요인에 의해 상쇄, 삭감이 되지 않도록 부과 보안사고심각는 1회의 사고만으로도 그 파급력이 큰 것을 감안하여\n",
      "----------------------------------------\n",
      "🔍 세종테크노파크_세종테크노파크 인사정보 전산시스템 구축 용역 입찰공.pdf | Chunk Unknown_88_세종테크노파크_인사정보_전산시스템_구축_용역_입찰공고[긴급].json::page::48::type::text | BM25: 10.00 | Rerank: 9.83 | Combined: 9.88\n",
      "🔍 경상북도 봉화군_봉화군 재난통합관리시스템 고도화 사업(협상)(긴급).pdf | Chunk 20240430896_봉화군_재난통합관리시스템_고도화_사업(협상)(긴급).json::page::68::type::text | BM25: 7.99 | Rerank: 10.00 | Combined: 9.40\n",
      "🔍 한국건강가정진흥원_2025년 아이돌봄인력 인적성 검사 정보시스템 운영.pdf | Chunk 20241218257_2025년_아이돌봄인력_인적성_검사_정보시스템_운영.json::page::40::type::text | BM25: 7.91 | Rerank: 9.75 | Combined: 9.20\n",
      "🔍 축산물품질평가원_축산물이력관리시스템 개선(정보화 사업).pdf | Chunk 20240523741_축산물이력관리시스템_개선(정보화_사업).json::page::48::type::text | BM25: 8.26 | Rerank: 7.36 | Combined: 7.63\n",
      "🔍 경상북도 봉화군_봉화군 재난통합관리시스템 고도화 사업(협상)(긴급).pdf | Chunk 20240430896_봉화군_재난통합관리시스템_고도화_사업(협상)(긴급).json::page::63::type::text | BM25: 7.73 | Rerank: 7.56 | Combined: 7.61\n",
      "🔍 남서울대학교_[혁신-국고] 남서울대학교 스마트 정보시스템 활성화(학사.pdf | Chunk 20241015084_[혁신-국고]_남서울대학교_스마트_정보시스템_활성화(학사행정_암호화)_개발_용역_입찰.json::page::17::type::text | BM25: 8.14 | Rerank: 7.35 | Combined: 7.59\n",
      "🔍 한국수출입은행_(긴급) 모잠비크 마푸토 지능형교통시스템(ITS) 구축사업.pdf | Chunk 20240925413_(긴급)_모잠비크_마푸토_지능형교통시스템(ITS)_구축사업_사업타당성조사(F_S)_용역.json::page::63::type::text | BM25: 7.66 | Rerank: 7.50 | Combined: 7.55\n",
      "🔍 한국농어촌공사_아세안+3 식량안보정보시스템(AFSIS) 3단계 협력(캄보디아.pdf | Chunk R25BK00601569_아세안+3_식량안보정보시스템(AFSIS)_3단계_협력(캄보디아)사업_PMC_용역.json::page::68::type::text | BM25: 7.88 | Rerank: 7.36 | Combined: 7.52\n",
      "🔍 한국보육진흥원_연차별 자율 품질관리 시스템 기능개선.pdf | Chunk 20240429895_연차별_자율_품질관리_시스템_기능개선.json::page::77::type::text | BM25: 7.62 | Rerank: 7.42 | Combined: 7.48\n",
      "🔍 한국보육진흥원_연차별 자율 품질관리 시스템 기능개선.pdf | Chunk 20240429895_연차별_자율_품질관리_시스템_기능개선.json::page::38::type::text | BM25: 0.00 | Rerank: 9.79 | Combined: 6.85\n",
      "🔍 수협중앙회_강릉어선안전조업국 상황관제시스템 구축.pdf | Chunk R25BK00632248_강릉어선안전조업국_상황관제시스템_구축.json::page::61::type::text | BM25: 9.19 | Rerank: 4.94 | Combined: 6.21\n",
      "🔍 한국해양조사협회_2024년 항해용 간행물 품질관리 업무보조 시스템 구축.pdf | Chunk 20240612475_2024년_항해용_간행물_품질관리_업무보조_시스템_구축.json::page::60::type::text | BM25: 0.00 | Rerank: 7.58 | Combined: 5.31\n",
      "🔍 서울시립대학교_[사전공개] 학업성취도 다차원 종단분석 통합시스템 1차.pdf | Chunk Unknown_12_[사전공개]_학업성취도_다차원_종단분석_통합시스템_1차_고도화_용역.json::page::1::type::text | BM25: 0.00 | Rerank: 7.47 | Combined: 5.23\n",
      "🔍 (사)벤처기업협회_2024년 벤처확인종합관리시스템 기능 고도화 용역사업 .pdf | Chunk 20240330003_2024년_벤처확인종합관리시스템_기능_고도화_용역사업_입찰공고.json::page::4::type::text | BM25: 0.00 | Rerank: 5.12 | Combined: 3.58\n",
      "🔍 한국생산기술연구원_EIP3.0 고압가스 안전관리 시스템 구축 용역.pdf | Chunk 20240827859_EIP3.0_고압가스_안전관리_시스템_구축_용역.json::page::15::type::text | BM25: 0.00 | Rerank: 5.01 | Combined: 3.51\n",
      "🔍 국립중앙의료원_(긴급)「2024년도 차세대 응급의료 상황관리시스템 구축.pdf | Chunk 20240531542_(긴급)「2024년도_차세대_응급의료_상황관리시스템_구축」_위탁용역.json::page::7::type::text | BM25: 0.00 | Rerank: 4.94 | Combined: 3.46\n",
      "🔍 국민연금공단_사업장 사회보험료 지원 고시 개정에 따른 정보시스템 보.pdf | Chunk Unknown_49_사업장_사회보험료_지원_고시_개정에_따른_정보시스템_보완_개발.json::page::79::type::text | BM25: 0.00 | Rerank: 2.60 | Combined: 1.82\n",
      "🔍 축산물품질평가원_축산물이력관리시스템 개선(정보화 사업).pdf | Chunk 20240523741_축산물이력관리시스템_개선(정보화_사업).json::page::12::type::text | BM25: 0.00 | Rerank: 0.14 | Combined: 0.10\n",
      "🔍 한국보육진흥원_연차별 자율 품질관리 시스템 기능개선.pdf | Chunk 20240429895_연차별_자율_품질관리_시스템_기능개선.json::page::2::type::text | BM25: 0.00 | Rerank: 0.03 | Combined: 0.02\n",
      "🔍 국방과학연구소_대용량 자료전송시스템 고도화.pdf | Chunk 20240821893_대용량_자료전송시스템_고도화.json::page::2::type::text | BM25: 0.00 | Rerank: 0.00 | Combined: 0.00\n",
      "\n",
      "📈 최종 결과:\n",
      "문서 1 | 출처: Unknown_88_세종테크노파크_인사정보_전산시스템_구축_용역_입찰공고[긴급].json::page::48::type::text\n",
      "🔹 BM25 점수: 10.00 | 🔹 Rerank 점수: 9.83 | 🔹 Combined: 9.88\n",
      "- 45 - 새로운 신용평가등급이 없는 경우에는 합병 대상업체 중 가장 낮은 신용평가등급을 받은 업체의 신용평가등급으로 평가 2 유사사업 수행실적 평가 배점 기준 및 유사용역 기준은 아래와 같음 항목 계산 방법 배점한도 기 준 배점 유사 사업 실적 건수 준공실적 건수 4 A. 사업수행 5건 이상 4 B. 사업수행 4건 이상 3 C. 사업수행 3건 이상 2 D. 사업수행 2건 이상 1 항목 계산 방법 배점한도 기 준 배점 유사 사업 실적 금액 본사업비 준공실적금액 3 A. 200이상 3 B. 100이상 - 200미만 2 C. 100미만 1 1 유사용역 인정 기준 경영정보시스템ERP 구축 및 고도화 사업 2 최근 3년공고일 기준 이내 준공한, 단일사업비 1억원 이상 실적VAT 포함만을 인정 하며, 증명서의 내용금액 등을 기초로 평가진행 중인 용역은 제외 - 입찰 공고일을 2019.11.01.로 가정실제 공고일 확인할 경우 용역 준공일차수 준공 인정, 기성실적 미인정이 2016.11.01\n",
      "{'사업 금액': 90000000, '입찰 참여 시작일': '미정', '입찰 참여 마감일': '미정', 'page': 48, '공개 일자': '2021-10-08 00:00:00', 'chunk_id': 'Unknown_88_세종테크노파크_인사정보_전산시스템_구축_용역_입찰공고[긴급].json::page::48::type::text', '공고 차수': -1, '사업명': '세종테크노파크 인사정보 전산시스템 구축 용역 입찰공고[긴급]', '사업 요약': '- 사업개요: 세종테크노파크 인사정보 전산시스템 구축\\n- 추진배경: 인사정보관리의 전산화 결여로 인한 업무 부담과 정보의 통합 부족\\n- 사업범위: 인사정보시스템 구축, 근태관리 고도화, 인사정보 검색 시스템 구축\\n- 기대효과: 인사업무 처리 효율성 제고, 정보의 통합 및 협업 체계 강화\\n- 추진목표: 인사정보시스템 구축, 분산된 인사업무 통합, 연계 기관 및 데이터 모니터링 가능성 확보', '파일형식': 'pdf', '파일명': '세종테크노파크_세종테크노파크 인사정보 전산시스템 구축 용역 입찰공.pdf', '발주 기관': '세종테크노파크', '공고 번호': 'Unknown_88'}\n",
      "==================================================\n",
      "문서 2 | 출처: 20240430896_봉화군_재난통합관리시스템_고도화_사업(협상)(긴급).json::page::68::type::text\n",
      "🔹 BM25 점수: 7.99 | 🔹 Rerank 점수: 10.00 | 🔹 Combined: 9.40\n",
      "- 64 - 별지서식 7호 사업수행 실적증명서 신 청 인 업체명 대 표 자 영업소재지 전화번호 사업자번호 법인등록번호 증명서 용도 입찰 및 제안서 심사 제출용 제 출 처 국가기관, 지방자치단체 및 공공기관 사업이행 실적내용 사 업 명 구 분 소프트웨어개발 유지관리운영위탁 정보통신 기타 사업개요 사업금액 VAT 포함 계약일자계약기간 계약금액 VAT 포함 소프트웨어개발 분야 용역이행 실적 완료일자 비율 실적원 증 명 서 발급기관 위 사실을 증명함. 년 월 일 기관명 인 전화번호 주 소 발급부서 담당자 전화번호 사업수행실적은 입찰공고일 기준 사업 완료일자가 최근 5년 이내 사업 실적에 한한다. 사업개요에는 본 사업과 동등 이상 사업임을 알 수 있는 내용을 기재한다. 공동계약으로 이행하였을 경우 사업금액에는 총사업금액을 지재하고, 계약금액에는 해 당 수행사의 지분율에 해당하는 금액을 기재한다. 이행 실적란은 기재 후 투명접착테이프를 붙여 증명을 발급 받아야 하며, 기관명인 이 없는 것은 무\n",
      "{'공고 번호': '20240430896', '파일명': '경상북도 봉화군_봉화군 재난통합관리시스템 고도화 사업(협상)(긴급).pdf', 'chunk_id': '20240430896_봉화군_재난통합관리시스템_고도화_사업(협상)(긴급).json::page::68::type::text', '입찰 참여 마감일': '2024-04-30 17:00:00', '입찰 참여 시작일': '2024-04-26 09:00:00', '공고 차수': 0.0, '사업명': '봉화군 재난통합관리시스템 고도화 사업(협상)(긴급)', '공개 일자': '2024-04-18 16:33:28', '사업 금액': 900000000, 'page': 68, '발주 기관': '경상북도 봉화군', '사업 요약': '- 사업명: 봉화군 재난통합관리시스템 고도화 사업\\n- 사업개요: 공동수급(공동이행방식)을 허용하는 고도화 사업\\n- 추진배경: 재난통합관리시스템의 고도화 필요성\\n- 사업범위: 자가진단표 분야에 대한 사업수행실적 평가표\\n- 기대효과: 공동수급표준협정서를 활용한 효과적인 사업수행\\n- 추진목표: 봉화군 재난통합관리시스템의 고도화 및 개선', '파일형식': 'pdf'}\n",
      "==================================================\n",
      "문서 3 | 출처: 20241218257_2025년_아이돌봄인력_인적성_검사_정보시스템_운영.json::page::40::type::text\n",
      "🔹 BM25 점수: 7.91 | 🔹 Rerank 점수: 9.75 | 🔹 Combined: 9.20\n",
      "- 38 - 보호 및 지원에 관한 법률제2조에 따른 소상공인으로서중소 기업 범위 및 확인에 관한 규정에 따라 발급된 중소기업 소상공인 확인서를 소지한 업체입찰 참가 마감일 전일까지 발 급된 것으로 유효기간 내에 한함 ᄋ 중소기업제품 구매촉진 및 판로지원에 관한 법률에 의한 중소기 업자로서중소기업자간 경쟁제품 직접생산 확인기준중소벤처 기업부 고시에 따라 직접생산확인증명서정보시스템유지관리서 비스,세부품명번호 8111189901를 소지한 업체입찰참가등록 마감일 이전 발행된 것으로 유효기간 내에 있어야 함 ᄋ 상호출자제한기업집단 소속기업 및 대기업 참여제한 사항 - 소프트웨어 진흥법 제48조 제4항에 따라 상호출자제한기업 집단에 속하는 회사는 입찰에 참여 불가 - 본 사업은 20억 미만의 사업으로써, 소프트웨어 진흥법 제48조 제2항 및 대기업인 소프트웨어 사업자가 참여할 수 있는 사업금 액의 하한과학기술정보통신부에 의거 대기업 및 중견기업인 소 프트웨어 사업자의 입찰 참여 제한중소기업자만\n",
      "{'발주 기관': '한국건강가정진흥원', '공개 일자': '2024-12-10 17:43:31', '파일명': '한국건강가정진흥원_2025년 아이돌봄인력 인적성 검사 정보시스템 운영.pdf', '사업 금액': 172700000, 'page': 40, '공고 번호': '20241218257', '사업 요약': '- 추진배경: 국정과제인 아동돌봄체계 강화와 개인정보보호법 준수를 위해 아이돌봄인력 인적성 검사 정보시스템 운영 필요\\n- 사업개요: 2025년까지 아이돌봄인력 인적성 검사 정보시스템 운영 및 유지보수\\n- 사업범위: 인-적성 프로그램 기능 수정 및 안정화, 정보시스템 유지관리, 개인정보보호 및 정보보안 강화\\n- 기대효과: 안전한 돌봄 환경 조성, 효율성 제고, 정책지원 및 제도개선 지원, 돌봄인력 관리 강화', '입찰 참여 마감일': '2024-12-23 10:00:00', '공고 차수': 0.0, '파일형식': 'pdf', 'chunk_id': '20241218257_2025년_아이돌봄인력_인적성_검사_정보시스템_운영.json::page::40::type::text', '사업명': '2025년 아이돌봄인력 인적성 검사 정보시스템 운영', '입찰 참여 시작일': '2024-12-10 18:00:00'}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 검색 실행 (기존 로직 그대로)\n",
    "\n",
    "#query_text = \"입찰시작일이 2024년 8월 이후 공고 찾아줘\"\n",
    "query_text = \"사업금액 100억이상 공고 알려줘\"\n",
    "logging.info(f\"\\n[스마트 검색 실행] 질문: {query_text}\")\n",
    "\n",
    "\n",
    "tokenized_query = retriever.tokenizer.tokenize_korean(query_text)\n",
    "print(f\"\\n🔍 BM25 키워드 토큰: {tokenized_query}\")\n",
    "\n",
    "results = retriever.smart_search(\n",
    "    query=query_text,\n",
    "    top_k=3,\n",
    "    candidate_size=10,\n",
    ")\n",
    "\n",
    "# 결과 출력 (기존 로직 100% 유지)\n",
    "print(\"\\n📈 최종 결과:\")\n",
    "\n",
    "if results and isinstance(results[0], dict):\n",
    "    # 메타데이터 기반 검색 결과\n",
    "    for i, record in enumerate(results):\n",
    "        print(f\"\\n📄 문서 {i+1}\")\n",
    "        for key, value in record.items():\n",
    "            print(f\"🔹 {key}: {value}\")\n",
    "        print(\"=\" * 50)\n",
    "else:\n",
    "    # 의미 기반 검색 결과\n",
    "    for i, doc in enumerate(results):\n",
    "        key = retriever.get_doc_key(doc)\n",
    "        scores = retriever.last_scores.get(key, {})\n",
    "        bm25 = scores.get(\"bm25\", 0.0)\n",
    "        rerank = scores.get(\"rerank\", 0.0)\n",
    "        combined = scores.get(\"combined\", 0.0)\n",
    "\n",
    "        print(f\"문서 {i+1} | 출처: {doc.metadata.get('chunk_id')}\")\n",
    "        print(f\"🔹 BM25 점수: {bm25:.2f} | 🔹 Rerank 점수: {rerank:.2f} | 🔹 Combined: {combined:.2f}\")\n",
    "        print(doc.page_content[:500])\n",
    "        print(doc.metadata)\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37160cc-c9a7-446d-9eef-3351096d944f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
