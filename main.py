import os
import sys
import asyncio
import logging
import pandas as pd

from config import Config
from src.retrieval.hybrid_retriever import Retriever
from src.retrieval.tokenizer_wrapper import TokenizerWrapper
from langchain_huggingface import HuggingFaceEmbeddings
from sentence_transformers import CrossEncoder

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S"
)

async def main():
    # ì„¤ì • ë¡œë“œ
    cfg = Config()
    
    # ê¸°ë³¸ ì„¤ì •
    LOAD_MODE = "json"
    TOKENIZER = "kiwi"
    
    # ë©”íƒ€ë°ì´í„° ë¡œë“œ
    meta_df = pd.read_csv(cfg.meta_csv_path)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    import torch
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"âœ… ë””ë°”ì´ìŠ¤: {device}")
    
    # ëª¨ë¸ ì´ˆê¸°í™” (ì™¸ë¶€ì—ì„œ ë¡œë“œí•˜ì—¬ ìºì‹œí™”)
    embedder = HuggingFaceEmbeddings(
        model_name=cfg.embedder_model,
        model_kwargs={"device": device}
    )
    
    reranker = CrossEncoder(
        cfg.reranker_model,
        device=device,
        max_length=cfg.rerank_max_length
    )
    
    tokenizer = TokenizerWrapper(TOKENIZER)
    
    # Retriever ì´ˆê¸°í™” (ëª¨ë“  ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
    retriever = Retriever(
        meta_df=meta_df,
        embedder=embedder,
        reranker=reranker,
        tokenizer=tokenizer,
        persist_directory=cfg.chroma_db_path,
        rerank_max_length=cfg.rerank_max_length,
        bm25_path=cfg.bm25_path,
        debug_mode=True
    )
    
    try:
        # ë¬¸ì„œ ë¡œë”© (ê¸°ì¡´ ë¡œì§ 100% ë³´ì¡´)
        if LOAD_MODE == "json":
            docs = await retriever.load_or_cache_json_docs(
                cfg.processed_dir, 
                cache_path=cfg.cached_json_path
            )
        
        # ê°€ì¤‘ì¹˜ ì„¤ì • ë° ë²¡í„° DB êµ¬ì¶• (ê¸°ì¡´ê³¼ ë™ì¼)
        retriever.set_weights(bm25_weight=0.5, rerank_weight=0.5)
        retriever.load_or_build_vector_db(docs)
        
        # ê²€ìƒ‰ ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§ ê·¸ëŒ€ë¡œ)
        query_text = "êµ­ë¦½ì¸ì²œí•´ì–‘ë°•ë¬¼ê´€ ìµœì¢…ê²€ìˆ˜ ê¸°ê°„ì€"
        logging.info(f"\n[ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì‹¤í–‰] ì§ˆë¬¸: {query_text}")
        
        tokenized_query = retriever.tokenize_korean(query_text)
        print(f"\nğŸ” BM25 í‚¤ì›Œë“œ í† í°: {tokenized_query}")
        
        results = retriever.smart_search(
            query=query_text,
            top_k=3,
            candidate_size=10,
        )
        
        # ê²°ê³¼ ì¶œë ¥ (ê¸°ì¡´ ë¡œì§ 100% ìœ ì§€)
        print("\nğŸ“ˆ ìµœì¢… ê²°ê³¼:")
        
        if results and isinstance(results[0], dict):
            # ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼
            for i, record in enumerate(results):
                print(f"\nğŸ“„ ë¬¸ì„œ {i+1}")
                for key, value in record.items():
                    print(f"ğŸ”¹ {key}: {value}")
                print("=" * 50)
        else:
            # ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ ê²°ê³¼
            for i, doc in enumerate(results):
                key = retriever.get_doc_key(doc)
                scores = retriever.last_scores.get(key, {})
                bm25 = scores.get("bm25", 0.0)
                rerank = scores.get("rerank", 0.0)
                combined = scores.get("combined", 0.0)
        
                print(f"ë¬¸ì„œ {i+1} | ì¶œì²˜: {doc.metadata.get('chunk_id')}")
                print(f"ğŸ”¹ BM25 ì ìˆ˜: {bm25:.2f} | ğŸ”¹ Rerank ì ìˆ˜: {rerank:.2f} | ğŸ”¹ Combined: {combined:.2f}")
                print(doc.page_content[:500])
                print("=" * 50)

    except Exception as e:
        logging.error(f"ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    asyncio.run(main())
